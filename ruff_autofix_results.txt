warning: The top-level linter settings are deprecated in favour of their counterparts in the `lint` section. Please update the following options in `ruff.toml`:
  - 'isort' -> 'lint.isort'
  - 'mccabe' -> 'lint.mccabe'
N999 Invalid module name: 'AdaptiveMind_Local_Compat'
--> AdaptiveMind_Local_Compat/__init__.py:1:1

E501 Line too long (92 > 88)
  --> AdaptiveMind_Local_Compat/__init__.py:19:89
   |
17 | """Compatibility shim for legacy Jarvis_Local imports.
18 |
19 | This module maintains backward compatibility by re-exporting the AdaptiveMind_Local package.
   |                                                                                         ^^^^
20 | Code importing `Jarvis_Local` will receive a deprecation warning and should migrate to
21 | `apps.AdaptiveMind_Local`.
   |

F401 `types.ModuleType` imported but unused
  --> AdaptiveMind_Local_Compat/__init__.py:27:19
   |
25 | import importlib
26 | import warnings
27 | from types import ModuleType
   |                   ^^^^^^^^^^
28 |
29 | warnings.warn(
   |
help: Remove unused import: `types.ModuleType`

W291 Trailing whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:18:78
   |
17 | Tier 1: BitNet Architecture Selector - Analyzes tasks and selects optimal architecture
18 | Tier 2: Polymorphic Swarm Factory - Executes tasks with selected architecture  
   |                                                                              ^^
19 | Tier 3: Smart Cloud Escalation - Decides when to escalate to cloud resources
   |
help: Remove trailing whitespace

W293 Blank line contains whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:44:1
   |
42 | class AdaptiveSwarmResult:
43 |     """Complete result from the adaptive swarm system."""
44 |     
   | ^^^^
45 |     # Task execution results
46 |     final_output: Any
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:48:1
   |
46 |     final_output: Any
47 |     success: bool
48 |     
   | ^^^^
49 |     # Tier 1 results (Architecture Selection)
50 |     task_analysis: TaskAnalysis
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:51:1
   |
49 |     # Tier 1 results (Architecture Selection)
50 |     task_analysis: TaskAnalysis
51 |     
   | ^^^^
52 |     # Tier 2 results (Swarm Execution) 
53 |     swarm_result: SwarmExecutionResult
   |
help: Remove whitespace from blank line

W291 Trailing whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:52:39
   |
50 |     task_analysis: TaskAnalysis
51 |     
52 |     # Tier 2 results (Swarm Execution) 
   |                                       ^
53 |     swarm_result: SwarmExecutionResult
   |
help: Remove trailing whitespace

W293 Blank line contains whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:54:1
   |
52 |     # Tier 2 results (Swarm Execution) 
53 |     swarm_result: SwarmExecutionResult
54 |     
   | ^^^^
55 |     # Tier 3 results (Cloud Escalation)
56 |     escalation_analysis: EscalationAnalysis
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:57:1
   |
55 |     # Tier 3 results (Cloud Escalation)
56 |     escalation_analysis: EscalationAnalysis
57 |     
   | ^^^^
58 |     # System performance metrics
59 |     total_execution_time: float
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:63:1
   |
61 |     total_cost: float
62 |     system_efficiency: float
63 |     
   | ^^^^
64 |     # Final recommendations
65 |     recommendations: List[str]
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:72:1
   |
70 |     """
71 |     Complete Dynamically Adaptive Swarm System.
72 |     
   | ^^^^
73 |     This system intelligently routes tasks through the optimal architecture
74 |     based on scientific scaling laws, maximizing performance while
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:77:1
   |
75 |     minimizing error amplification and costs.
76 |     """
77 |     
   | ^^^^
78 |     def __init__(self):
79 |         """Initialize the complete adaptive swarm system."""
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:80:1
   |
78 |     def __init__(self):
79 |         """Initialize the complete adaptive swarm system."""
80 |         
   | ^^^^^^^^
81 |         # Initialize all three tiers
82 |         self.tier1_optimizer = BitNetOptimizer()
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:85:1
   |
83 |         self.tier2_factory = LocalSwarmFactory()
84 |         self.tier3_escalation = CloudEscalationManager()
85 |         
   | ^^^^^^^^
86 |         # System configuration
87 |         self.config = {
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
  --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:94:1
   |
92 |             "performance_monitoring": True
93 |         }
94 |         
   | ^^^^^^^^
95 |         # Performance tracking
96 |         self.execution_history = []
   |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:104:1
    |
102 |             "average_cost_savings": 0.0
103 |         }
104 |         
    | ^^^^^^^^
105 |         logger.info("ðŸš€ Dynamically Adaptive Swarm System initialized")
106 |         logger.info("âœ… Tier 1: BitNet Architecture Selector ready")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:109:1
    |
107 |         logger.info("âœ… Tier 2: Polymorphic Swarm Factory ready")
108 |         logger.info("âœ… Tier 3: Smart Cloud Escalation ready")
109 |     
    | ^^^^
110 |     def process_request(
111 |         self,
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:118:1
    |
116 |         """
117 |         Process a user request through the complete adaptive swarm system.
118 |         
    | ^^^^^^^^
119 |         Args:
120 |             user_query: The user's request to process
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:123:1
    |
121 |             context: Optional context information
122 |             user_preferences: User preferences (local/cloud, budget, etc.)
123 |             
    | ^^^^^^^^^^^^
124 |         Returns:
125 |             AdaptiveSwarmResult with complete execution details
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:128:1
    |
126 |         """
127 |         start_time = time.time()
128 |         
    | ^^^^^^^^
129 |         logger.info(f"ðŸ§  Processing request: {user_query[:100]}...")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:130:1
    |
129 |         logger.info(f"ðŸ§  Processing request: {user_query[:100]}...")
130 |         
    | ^^^^^^^^
131 |         try:
132 |             # ========== TIER 1: ARCHITECTURE SELECTION ==========
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:134:1
    |
132 |             # ========== TIER 1: ARCHITECTURE SELECTION ==========
133 |             logger.info("ðŸ” TIER 1: Analyzing task and selecting architecture...")
134 |             
    | ^^^^^^^^^^^^
135 |             task_analysis = self.tier1_optimizer.select_optimal_architecture(
136 |                 user_query, 
    |
help: Remove whitespace from blank line

W291 Trailing whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:136:28
    |
135 |             task_analysis = self.tier1_optimizer.select_optimal_architecture(
136 |                 user_query, 
    |                            ^
137 |                 agent_capabilities=None  # Use defaults
138 |             )
    |
help: Remove trailing whitespace

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:139:1
    |
137 |                 agent_capabilities=None  # Use defaults
138 |             )
139 |             
    | ^^^^^^^^^^^^
140 |             logger.info(f"   Selected architecture: {task_analysis.selected_architecture}")
141 |             logger.info(f"   Confidence: {task_analysis.confidence:.1%}")
    |
help: Remove whitespace from blank line

E501 Line too long (91 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:140:89
    |
138 |             )
139 |             
140 |             logger.info(f"   Selected architecture: {task_analysis.selected_architecture}")
    |                                                                                         ^^^
141 |             logger.info(f"   Confidence: {task_analysis.confidence:.1%}")
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:142:1
    |
140 |             logger.info(f"   Selected architecture: {task_analysis.selected_architecture}")
141 |             logger.info(f"   Confidence: {task_analysis.confidence:.1%}")
142 |             
    | ^^^^^^^^^^^^
143 |             # ========== TIER 2: SWARM EXECUTION ==========
144 |             logger.info("âš¡ TIER 2: Executing with selected architecture...")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:145:1
    |
143 |             # ========== TIER 2: SWARM EXECUTION ==========
144 |             logger.info("âš¡ TIER 2: Executing with selected architecture...")
145 |             
    | ^^^^^^^^^^^^
146 |             swarm_result = self.tier2_factory.create_swarm(
147 |                 architecture_type=task_analysis.selected_architecture,
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:152:1
    |
150 |                 max_agents=5
151 |             )
152 |             
    | ^^^^^^^^^^^^
153 |             logger.info(f"   Swarm execution: {'âœ… Success' if swarm_result.success else 'âŒ Failed'}")
154 |             logger.info(f"   Efficiency: {swarm_result.efficiency:.3f}")
    |
help: Remove whitespace from blank line

E501 Line too long (103 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:153:88
    |
151 |             )
152 |             
153 |             logger.info(f"   Swarm execution: {'âœ… Success' if swarm_result.success else 'âŒ Failed'}")
    |                                                                                         ^^^^^^^^^^^^^^^
154 |             logger.info(f"   Efficiency: {swarm_result.efficiency:.3f}")
155 |             logger.info(f"   Error amplification: {swarm_result.error_amplification:.1f}x")
    |

E501 Line too long (91 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:155:89
    |
153 |             logger.info(f"   Swarm execution: {'âœ… Success' if swarm_result.success else 'âŒ Failed'}")
154 |             logger.info(f"   Efficiency: {swarm_result.efficiency:.3f}")
155 |             logger.info(f"   Error amplification: {swarm_result.error_amplification:.1f}x")
    |                                                                                         ^^^
156 |             
157 |             # ========== TIER 3: CLOUD ESCALATION DECISION ==========
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:156:1
    |
154 |             logger.info(f"   Efficiency: {swarm_result.efficiency:.3f}")
155 |             logger.info(f"   Error amplification: {swarm_result.error_amplification:.1f}x")
156 |             
    | ^^^^^^^^^^^^
157 |             # ========== TIER 3: CLOUD ESCALATION DECISION ==========
158 |             logger.info("â˜ï¸ TIER 3: Analyzing escalation decision...")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:159:1
    |
157 |             # ========== TIER 3: CLOUD ESCALATION DECISION ==========
158 |             logger.info("â˜ï¸ TIER 3: Analyzing escalation decision...")
159 |             
    | ^^^^^^^^^^^^
160 |             # Extract task complexity from analysis
161 |             task_complexity = task_analysis.complexity
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:162:1
    |
160 |             # Extract task complexity from analysis
161 |             task_complexity = task_analysis.complexity
162 |             
    | ^^^^^^^^^^^^
163 |             # Get user preferences
164 |             user_preference = user_preferences.get("execution_preference") if user_preferences else None
    |
help: Remove whitespace from blank line

E501 Line too long (104 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:164:89
    |
163 |             # Get user preferences
164 |             user_preference = user_preferences.get("execution_preference") if user_preferences else None
    |                                                                                         ^^^^^^^^^^^^^^^^
165 |             budget_constraints = user_preferences.get("budget_constraints") if user_preferences else None
    |

E501 Line too long (105 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:165:89
    |
163 |             # Get user preferences
164 |             user_preference = user_preferences.get("execution_preference") if user_preferences else None
165 |             budget_constraints = user_preferences.get("budget_constraints") if user_preferences else None
    |                                                                                         ^^^^^^^^^^^^^^^^^
166 |             
167 |             escalation_analysis = self.tier3_escalation.should_escalate_to_cloud(
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:166:1
    |
164 |             user_preference = user_preferences.get("execution_preference") if user_preferences else None
165 |             budget_constraints = user_preferences.get("budget_constraints") if user_preferences else None
166 |             
    | ^^^^^^^^^^^^
167 |             escalation_analysis = self.tier3_escalation.should_escalate_to_cloud(
168 |                 swarm_result=swarm_result,
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:173:1
    |
171 |                 budget_constraints=budget_constraints
172 |             )
173 |             
    | ^^^^^^^^^^^^
174 |             logger.info(f"   Escalation decision: {escalation_analysis.decision.upper()}")
175 |             logger.info(f"   Reason: {escalation_analysis.reason.value}")
    |
help: Remove whitespace from blank line

E501 Line too long (90 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:174:89
    |
172 |             )
173 |             
174 |             logger.info(f"   Escalation decision: {escalation_analysis.decision.upper()}")
    |                                                                                         ^^
175 |             logger.info(f"   Reason: {escalation_analysis.reason.value}")
176 |             logger.info(f"   Confidence: {escalation_analysis.confidence:.1%}")
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:177:1
    |
175 |             logger.info(f"   Reason: {escalation_analysis.reason.value}")
176 |             logger.info(f"   Confidence: {escalation_analysis.confidence:.1%}")
177 |             
    | ^^^^^^^^^^^^
178 |             # ========== FINAL RESULT ASSEMBLY ==========
179 |             total_execution_time = time.time() - start_time
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:180:1
    |
178 |             # ========== FINAL RESULT ASSEMBLY ==========
179 |             total_execution_time = time.time() - start_time
180 |             
    | ^^^^^^^^^^^^
181 |             # Calculate final metrics
182 |             total_tokens = swarm_result.tokens_used + swarm_result.coordination_tokens
    |
help: Remove whitespace from blank line

E501 Line too long (161 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:183:89
    |
181 | â€¦
182 | â€¦_result.coordination_tokens
183 | â€¦local if escalation_analysis.decision == "continue_local" else escalation_analysis.cost_estimate_cloud
    |                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
184 | â€¦ciency(task_analysis, swarm_result, escalation_analysis)
    |

E501 Line too long (115 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:184:89
    |
182 | â€¦     total_tokens = swarm_result.tokens_used + swarm_result.coordination_tokens
183 | â€¦     total_cost = escalation_analysis.cost_estimate_local if escalation_analysis.decision == "continue_local" else escalation_analysâ€¦
184 | â€¦     system_efficiency = self._calculate_system_efficiency(task_analysis, swarm_result, escalation_analysis)
    |                                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
185 | â€¦     
186 | â€¦     # Generate final recommendations
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:185:1
    |
183 | â€¦     total_cost = escalation_analysis.cost_estimate_local if escalation_analysis.decision == "continue_local" else escalation_analysâ€¦
184 | â€¦     system_efficiency = self._calculate_system_efficiency(task_analysis, swarm_result, escalation_analysis)
185 | â€¦     
^^^^^^^^^^^^
186 | â€¦     # Generate final recommendations
187 | â€¦     recommendations = self._generate_final_recommendations(
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:190:1
    |
188 |                 task_analysis, swarm_result, escalation_analysis
189 |             )
190 |             
    | ^^^^^^^^^^^^
191 |             # Create performance summary
192 |             performance_summary = {
    |
help: Remove whitespace from blank line

E501 Line too long (176 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:207:89
    |
205 | â€¦
206 | â€¦
207 | â€¦ate_cloud - escalation_analysis.cost_estimate_local if escalation_analysis.decision == "continue_local" else 0
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
208 | â€¦
209 | â€¦
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:210:1
    |
208 |                 }
209 |             }
210 |             
    | ^^^^^^^^^^^^
211 |             # Create final result
212 |             result = AdaptiveSwarmResult(
    |
help: Remove whitespace from blank line

invalid-syntax: Expected `,`, found name
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:216:33
    |
214 |                 success=swarm_result.success,
215 |                 task_analysis=task_analysis,
216 |                 swarm_result=sw escalation_analysis=escalarm_result,
    |                                 ^^^^^^^^^^^^^^^^^^^
217 |                ation_analysis,
218 |                 total_execution_time=total_execution_time,
    |

invalid-syntax: Positional argument cannot follow keyword argument
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:217:16
    |
215 |                 task_analysis=task_analysis,
216 |                 swarm_result=sw escalation_analysis=escalarm_result,
217 |                ation_analysis,
    |                ^^^^^^^^^^^^^^
218 |                 total_execution_time=total_execution_time,
219 |                 total_tokens_used=total_tokens,
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:225:1
    |
223 |                 performance_summary=performance_summary
224 |             )
225 |             
    | ^^^^^^^^^^^^
226 |             # Update system statistics
227 |             self._update_system_stats(result)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:228:1
    |
226 |             # Update system statistics
227 |             self._update_system_stats(result)
228 |             
    | ^^^^^^^^^^^^
229 |             logger.info(f"ðŸŽ¯ Complete! Total time: {total_execution_time:.2f}s, Efficiency: {system_efficiency:.3f}")
    |
help: Remove whitespace from blank line

E501 Line too long (117 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:229:88
    |
227 |             self._update_system_stats(result)
228 |             
229 |             logger.info(f"ðŸŽ¯ Complete! Total time: {total_execution_time:.2f}s, Efficiency: {system_efficiency:.3f}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
230 |             
231 |             return result
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:230:1
    |
229 |             logger.info(f"ðŸŽ¯ Complete! Total time: {total_execution_time:.2f}s, Efficiency: {system_efficiency:.3f}")
230 |             
    | ^^^^^^^^^^^^
231 |             return result
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:232:1
    |
231 |             return result
232 |             
    | ^^^^^^^^^^^^
233 |         except Exception as e:
234 |             logger.error(f"âŒ Adaptive swarm system failed: {e}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:235:1
    |
233 |         except Exception as e:
234 |             logger.error(f"âŒ Adaptive swarm system failed: {e}")
235 |             
    | ^^^^^^^^^^^^
236 |             # Return error result
237 |             return AdaptiveSwarmResult(
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:265:1
    |
263 |                 performance_summary={"error": str(e)}
264 |             )
265 |     
    | ^^^^
266 |     def _calculate_system_efficiency(
267 |         self, 
    |
help: Remove whitespace from blank line

W291 Trailing whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:267:14
    |
266 |     def _calculate_system_efficiency(
267 |         self, 
    |              ^
268 |         task_analysis: TaskAnalysis, 
269 |         swarm_result: SwarmExecutionResult, 
    |
help: Remove trailing whitespace

W291 Trailing whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:268:37
    |
266 |     def _calculate_system_efficiency(
267 |         self, 
268 |         task_analysis: TaskAnalysis, 
    |                                     ^
269 |         swarm_result: SwarmExecutionResult, 
270 |         escalation_analysis: EscalationAnalysis
    |
help: Remove trailing whitespace

W291 Trailing whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:269:44
    |
267 |         self, 
268 |         task_analysis: TaskAnalysis, 
269 |         swarm_result: SwarmExecutionResult, 
    |                                            ^
270 |         escalation_analysis: EscalationAnalysis
271 |     ) -> float:
    |
help: Remove trailing whitespace

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:273:1
    |
271 |     ) -> float:
272 |         """Calculate overall system efficiency."""
273 |         
    | ^^^^^^^^
274 |         # Base efficiency from swarm execution
275 |         base_efficiency = swarm_result.efficiency
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:276:1
    |
274 |         # Base efficiency from swarm execution
275 |         base_efficiency = swarm_result.efficiency
276 |         
    | ^^^^^^^^
277 |         # Adjust for architecture selection quality
278 |         architecture_bonus = task_analysis.confidence * 0.1
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:279:1
    |
277 |         # Adjust for architecture selection quality
278 |         architecture_bonus = task_analysis.confidence * 0.1
279 |         
    | ^^^^^^^^
280 |         # Adjust for escalation decision quality
281 |         escalation_bonus = escalation_analysis.confidence * 0.05
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:282:1
    |
280 |         # Adjust for escalation decision quality
281 |         escalation_bonus = escalation_analysis.confidence * 0.05
282 |         
    | ^^^^^^^^
283 |         # Adjust for cost efficiency
284 |         cost_ratio = escalation_analysis.cost_estimate_cloud / max(escalation_analysis.cost_estimate_local, 0.001)
    |
help: Remove whitespace from blank line

E501 Line too long (114 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:284:89
    |
283 |         # Adjust for cost efficiency
284 |         cost_ratio = escalation_analysis.cost_estimate_cloud / max(escalation_analysis.cost_estimate_local, 0.001)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
285 |         cost_efficiency = 1.0 / max(cost_ratio, 1.0)  # Prefer lower costs
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:286:1
    |
284 |         cost_ratio = escalation_analysis.cost_estimate_cloud / max(escalation_analysis.cost_estimate_local, 0.001)
285 |         cost_efficiency = 1.0 / max(cost_ratio, 1.0)  # Prefer lower costs
286 |         
    | ^^^^^^^^
287 |         # Calculate final efficiency
288 |         total_efficiency = base_efficiency + architecture_bonus + escalation_bonus + cost_efficiency
    |
help: Remove whitespace from blank line

E501 Line too long (100 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:288:89
    |
287 |         # Calculate final efficiency
288 |         total_efficiency = base_efficiency + architecture_bonus + escalation_bonus + cost_efficiency
    |                                                                                         ^^^^^^^^^^^^
289 |         
290 |         return min(total_efficiency, 2.0)  # Cap at 2.0 for realism
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:289:1
    |
287 |         # Calculate final efficiency
288 |         total_efficiency = base_efficiency + architecture_bonus + escalation_bonus + cost_efficiency
289 |         
    | ^^^^^^^^
290 |         return min(total_efficiency, 2.0)  # Cap at 2.0 for realism
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:291:1
    |
290 |         return min(total_efficiency, 2.0)  # Cap at 2.0 for realism
291 |     
    | ^^^^
292 |     def _generate_final_recommendations(
293 |         self,
    |
help: Remove whitespace from blank line

W291 Trailing whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:295:44
    |
293 |         self,
294 |         task_analysis: TaskAnalysis,
295 |         swarm_result: SwarmExecutionResult, 
    |                                            ^
296 |         escalation_analysis: EscalationAnalysis
297 |     ) -> List[str]:
    |
help: Remove trailing whitespace

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:299:1
    |
297 |     ) -> List[str]:
298 |         """Generate final system recommendations."""
299 |         
    | ^^^^^^^^
300 |         recommendations = []
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:301:1
    |
300 |         recommendations = []
301 |         
    | ^^^^^^^^
302 |         # Architecture selection recommendations
303 |         if task_analysis.confidence < 0.7:
    |
help: Remove whitespace from blank line

E501 Line too long (107 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:304:88
    |
302 |         # Architecture selection recommendations
303 |         if task_analysis.confidence < 0.7:
304 |             recommendations.append("ðŸ¤” Consider improving task analysis for better architecture selection")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
305 |         
306 |         # Performance recommendations
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:305:1
    |
303 |         if task_analysis.confidence < 0.7:
304 |             recommendations.append("ðŸ¤” Consider improving task analysis for better architecture selection")
305 |         
    | ^^^^^^^^
306 |         # Performance recommendations
307 |         if swarm_result.efficiency < 0.5:
    |
help: Remove whitespace from blank line

E501 Line too long (102 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:308:88
    |
306 |         # Performance recommendations
307 |         if swarm_result.efficiency < 0.5:
308 |             recommendations.append("ðŸ“Š Local execution efficiency is low - consider cloud escalation")
    |                                                                                         ^^^^^^^^^^^^^^
309 |         
310 |         if swarm_result.error_amplification > 10:
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:309:1
    |
307 |         if swarm_result.efficiency < 0.5:
308 |             recommendations.append("ðŸ“Š Local execution efficiency is low - consider cloud escalation")
309 |         
    | ^^^^^^^^
310 |         if swarm_result.error_amplification > 10:
311 |             recommendations.append("âš ï¸ High error amplification detected - immediate cloud escalation recommended")
    |
help: Remove whitespace from blank line

E501 Line too long (114 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:311:90
    |
310 |         if swarm_result.error_amplification > 10:
311 |             recommendations.append("âš ï¸ High error amplification detected - immediate cloud escalation recommended")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
312 |         
313 |         # Cost recommendations
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:312:1
    |
310 |         if swarm_result.error_amplification > 10:
311 |             recommendations.append("âš ï¸ High error amplification detected - immediate cloud escalation recommended")
312 |         
    | ^^^^^^^^
313 |         # Cost recommendations
314 |         cost_savings = escalation_analysis.cost_estimate_cloud - escalation_analysis.cost_estimate_local
    |
help: Remove whitespace from blank line

E501 Line too long (104 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:314:89
    |
313 |         # Cost recommendations
314 |         cost_savings = escalation_analysis.cost_estimate_cloud - escalation_analysis.cost_estimate_local
    |                                                                                         ^^^^^^^^^^^^^^^^
315 |         if cost_savings > 0.01:  # $0.01 savings
316 |             recommendations.append(f"ðŸ’° Local execution saved ${cost_savings:.4f} compared to cloud")
    |

E501 Line too long (101 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:316:88
    |
314 |         cost_savings = escalation_analysis.cost_estimate_cloud - escalation_analysis.cost_estimate_local
315 |         if cost_savings > 0.01:  # $0.01 savings
316 |             recommendations.append(f"ðŸ’° Local execution saved ${cost_savings:.4f} compared to cloud")
    |                                                                                         ^^^^^^^^^^^^^
317 |         
318 |         # System optimization recommendations
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:317:1
    |
315 |         if cost_savings > 0.01:  # $0.01 savings
316 |             recommendations.append(f"ðŸ’° Local execution saved ${cost_savings:.4f} compared to cloud")
317 |         
    | ^^^^^^^^
318 |         # System optimization recommendations
319 |         if not swarm_result.success:
    |
help: Remove whitespace from blank line

E501 Line too long (100 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:320:88
    |
318 |         # System optimization recommendations
319 |         if not swarm_result.success:
320 |             recommendations.append("ðŸ”„ Task failed - consider retrying with different architecture")
    |                                                                                         ^^^^^^^^^^^^
321 |         
322 |         if escalation_analysis.decision == "escalate":
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:321:1
    |
319 |         if not swarm_result.success:
320 |             recommendations.append("ðŸ”„ Task failed - consider retrying with different architecture")
321 |         
    | ^^^^^^^^
322 |         if escalation_analysis.decision == "escalate":
323 |             recommendations.append("â˜ï¸ Cloud escalation successful - system handled failure gracefully")
    |
help: Remove whitespace from blank line

E501 Line too long (103 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:323:90
    |
322 |         if escalation_analysis.decision == "escalate":
323 |             recommendations.append("â˜ï¸ Cloud escalation successful - system handled failure gracefully")
    |                                                                                         ^^^^^^^^^^^^^^^
324 |         
325 |         return recommendations
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:324:1
    |
322 |         if escalation_analysis.decision == "escalate":
323 |             recommendations.append("â˜ï¸ Cloud escalation successful - system handled failure gracefully")
324 |         
    | ^^^^^^^^
325 |         return recommendations
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:326:1
    |
325 |         return recommendations
326 |     
    | ^^^^
327 |     def _update_system_stats(self, result: AdaptiveSwarmResult):
328 |         """Update system performance statistics."""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:329:1
    |
327 |     def _update_system_stats(self, result: AdaptiveSwarmResult):
328 |         """Update system performance statistics."""
329 |         
    | ^^^^^^^^
330 |         self.performance_stats["total_tasks"] += 1
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:331:1
    |
330 |         self.performance_stats["total_tasks"] += 1
331 |         
    | ^^^^^^^^
332 |         if result.success:
333 |             self.performance_stats["successful_tasks"] += 1
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:334:1
    |
332 |         if result.success:
333 |             self.performance_stats["successful_tasks"] += 1
334 |         
    | ^^^^^^^^
335 |         if result.escalation_analysis.decision == "escalate":
336 |             self.performance_stats["escalated_tasks"] += 1
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:337:1
    |
335 |         if result.escalation_analysis.decision == "escalate":
336 |             self.performance_stats["escalated_tasks"] += 1
337 |         
    | ^^^^^^^^
338 |         # Update rolling averages
339 |         total = self.performance_stats["total_tasks"]
    |
help: Remove whitespace from blank line

E501 Line too long (107 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:341:89
    |
339 |         total = self.performance_stats["total_tasks"]
340 |         self.performance_stats["average_efficiency"] = (
341 |             (self.performance_stats["average_efficiency"] * (total - 1) + result.system_efficiency) / total
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
342 |         )
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:343:1
    |
341 |             (self.performance_stats["average_efficiency"] * (total - 1) + result.system_efficiency) / total
342 |         )
343 |         
    | ^^^^^^^^
344 |         cost_savings = result.escalation_analysis.cost_estimate_cloud - result.escalation_analysis.cost_estimate_local
345 |         self.performance_stats["average_cost_savings"] = (
    |
help: Remove whitespace from blank line

E501 Line too long (118 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:344:89
    |
342 |         )
343 |         
344 |         cost_savings = result.escalation_analysis.cost_estimate_cloud - result.escalation_analysis.cost_estimate_local
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
345 |         self.performance_stats["average_cost_savings"] = (
346 |             (self.performance_stats["average_cost_savings"] * (total - 1) + cost_savings) / total
    |

E501 Line too long (97 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:346:89
    |
344 |         cost_savings = result.escalation_analysis.cost_estimate_cloud - result.escalation_analysis.cost_estimate_local
345 |         self.performance_stats["average_cost_savings"] = (
346 |             (self.performance_stats["average_cost_savings"] * (total - 1) + cost_savings) / total
    |                                                                                         ^^^^^^^^^
347 |         )
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:348:1
    |
346 |             (self.performance_stats["average_cost_savings"] * (total - 1) + cost_savings) / total
347 |         )
348 |         
    | ^^^^^^^^
349 |         # Store execution history
350 |         self.execution_history.append({
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:358:1
    |
356 |             "cost": result.total_cost
357 |         })
358 |         
    | ^^^^^^^^
359 |         # Keep only recent history
360 |         if len(self.execution_history) > 1000:
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:362:1
    |
360 |         if len(self.execution_history) > 1000:
361 |             self.execution_history = self.execution_history[-500:]
362 |     
    | ^^^^
363 |     def get_system_performance_report(self) -> Dict[str, Any]:
364 |         """Generate comprehensive system performance report."""
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:365:1
    |
363 |     def get_system_performance_report(self) -> Dict[str, Any]:
364 |         """Generate comprehensive system performance report."""
365 |         
    | ^^^^^^^^
366 |         if not self.execution_history:
367 |             return {"message": "No execution history available"}
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:368:1
    |
366 |         if not self.execution_history:
367 |             return {"message": "No execution history available"}
368 |         
    | ^^^^^^^^
369 |         recent_tasks = self.execution_history[-100:]  # Last 100 tasks
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:370:1
    |
369 |         recent_tasks = self.execution_history[-100:]  # Last 100 tasks
370 |         
    | ^^^^^^^^
371 |         # Architecture usage statistics
372 |         architecture_usage = {}
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:376:1
    |
374 |             arch = task["architecture"]
375 |             architecture_usage[arch] = architecture_usage.get(arch, 0) + 1
376 |         
    | ^^^^^^^^
377 |         # Escalation statistics
378 |         escalations = sum(1 for task in recent_tasks if task["escalation"] == "escalate")
    |
help: Remove whitespace from blank line

E501 Line too long (89 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:378:89
    |
377 |         # Escalation statistics
378 |         escalations = sum(1 for task in recent_tasks if task["escalation"] == "escalate")
    |                                                                                         ^
379 |         
380 |         # Efficiency statistics
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:379:1
    |
377 |         # Escalation statistics
378 |         escalations = sum(1 for task in recent_tasks if task["escalation"] == "escalate")
379 |         
    | ^^^^^^^^
380 |         # Efficiency statistics
381 |         efficiencies = [task["efficiency"] for task in recent_tasks]
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:385:1
    |
383 |         max_efficiency = max(efficiencies)
384 |         min_efficiency = min(efficiencies)
385 |         
    | ^^^^^^^^
386 |         # Success rate
387 |         successes = sum(1 for task in recent_tasks if task["success"])
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:389:1
    |
387 |         successes = sum(1 for task in recent_tasks if task["success"])
388 |         success_rate = successes / len(recent_tasks)
389 |         
    | ^^^^^^^^
390 |         # Cost savings
391 |         cost_savings = [task["cost"] for task in recent_tasks if task["escalation"] == "continue_local"]
    |
help: Remove whitespace from blank line

E501 Line too long (104 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:391:89
    |
390 |         # Cost savings
391 |         cost_savings = [task["cost"] for task in recent_tasks if task["escalation"] == "continue_local"]
    |                                                                                         ^^^^^^^^^^^^^^^^
392 |         avg_cost_local = sum(cost_savings) / len(cost_savings) if cost_savings else 0
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:393:1
    |
391 |         cost_savings = [task["cost"] for task in recent_tasks if task["escalation"] == "continue_local"]
392 |         avg_cost_local = sum(cost_savings) / len(cost_savings) if cost_savings else 0
393 |         
    | ^^^^^^^^
394 |         return {
395 |             "overview": {
    |
help: Remove whitespace from blank line

E501 Line too long (119 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:406:89
    |
404 |                 "average_local_cost": f"${avg_cost_local:.6f}",
405 |                 "estimated_cloud_cost_multiplier": "20x",
406 |                 "total_cost_savings": f"${sum(self.performance_stats['average_cost_savings'] * len(recent_tasks)):.4f}"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
407 |             },
408 |             "system_health": {
    |

E501 Line too long (95 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:409:87
    |
407 |             },
408 |             "system_health": {
409 |                 "overall_status": "ðŸŸ¢ Healthy" if success_rate > 0.8 else "ðŸŸ¡ Needs Attention",
    |                                                                                         ^^^^^^^
410 |                 "recommendations": [
411 |                     "System performing well" if success_rate > 0.8 else "Monitor failure rates",
    |

E501 Line too long (96 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:411:89
    |
409 |                 "overall_status": "ðŸŸ¢ Healthy" if success_rate > 0.8 else "ðŸŸ¡ Needs Attention",
410 |                 "recommendations": [
411 |                     "System performing well" if success_rate > 0.8 else "Monitor failure rates",
    |                                                                                         ^^^^^^^^
412 |                     "Consider optimizing architecture selection" if avg_efficiency < 0.8 else "Architecture selection optimal",
413 |                     "Local execution cost-effective" if avg_cost_local < 0.01 else "Consider cloud for complex tasks"
    |

E501 Line too long (127 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:412:89
    |
410 |                 "recommendations": [
411 |                     "System performing well" if success_rate > 0.8 else "Monitor failure rates",
412 |                     "Consider optimizing architecture selection" if avg_efficiency < 0.8 else "Architecture selection optimal",
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
413 |                     "Local execution cost-effective" if avg_cost_local < 0.01 else "Consider cloud for complex tasks"
414 |                 ]
    |

E501 Line too long (117 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:413:89
    |
411 |                     "System performing well" if success_rate > 0.8 else "Monitor failure rates",
412 |                     "Consider optimizing architecture selection" if avg_efficiency < 0.8 else "Architecture selection optimal",
413 |                     "Local execution cost-effective" if avg_cost_local < 0.01 else "Consider cloud for complex tasks"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
414 |                 ]
415 |             }
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:417:1
    |
415 |             }
416 |         }
417 |     
    | ^^^^
418 |     def get_execution_explanation(self, result: AdaptiveSwarmResult) -> str:
419 |         """
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:421:1
    |
419 |         """
420 |         Generate comprehensive execution explanation.
421 |         
    | ^^^^^^^^
422 |         Args:
423 |             result: Adaptive swarm execution result
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:424:1
    |
422 |         Args:
423 |             result: Adaptive swarm execution result
424 |             
    | ^^^^^^^^^^^^
425 |         Returns:
426 |             Human-readable execution report
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:470:1
    |
468 | **ðŸ’¡ Recommendations:**
469 | """
470 |         
    | ^^^^^^^^
471 |         for i, rec in enumerate(result.recommendations, 1):
472 |             explanation += f"{i}. {rec}\n"
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:473:1
    |
471 |         for i, rec in enumerate(result.recommendations, 1):
472 |             explanation += f"{i}. {rec}\n"
473 |         
    | ^^^^^^^^
474 |         explanation += f"""
475 | **ðŸ”¬ Scientific Insights:**
    |
help: Remove whitespace from blank line

E501 Line too long (109 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:477:89
    |
475 | **ðŸ”¬ Scientific Insights:**
476 | - Architecture selection based on {len(result.task_analysis.reasoning)} factors
477 | - Error amplification detection prevented {result.swarm_result.error_amplification:.1f}x error multiplication
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^
478 | - Cost optimization saved ${result.escalation_analysis.cost_estimate_cloud - result.escalation_analysis.cost_estimate_local:.6f}
479 | - Performance vs. paper targets: {((result.system_efficiency - 1.0) * 100):+.1f}%
    |

E501 Line too long (128 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:478:89
    |
476 | - Architecture selection based on {len(result.task_analysis.reasoning)} factors
477 | - Error amplification detection prevented {result.swarm_result.error_amplification:.1f}x error multiplication
478 | - Cost optimization saved ${result.escalation_analysis.cost_estimate_cloud - result.escalation_analysis.cost_estimate_local:.6f}
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
479 | - Performance vs. paper targets: {((result.system_efficiency - 1.0) * 100):+.1f}%
480 | """
    |

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:481:1
    |
479 | - Performance vs. paper targets: {((result.system_efficiency - 1.0) * 100):+.1f}%
480 | """
481 |         
    | ^^^^^^^^
482 |         return explanation
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:487:1
    |
485 | # Example usage and demonstration
486 | if __name__ == "__main__":
487 |     
    | ^^^^
488 |     # Initialize the complete system
489 |     system = AdaptiveSwarmSystem()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:490:1
    |
488 |     # Initialize the complete system
489 |     system = AdaptiveSwarmSystem()
490 |     
    | ^^^^
491 |     # Test with different types of queries
492 |     test_queries = [
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:499:1
    |
497 |         "Research latest developments in renewable energy technology"
498 |     ]
499 |     
    | ^^^^
500 |     print("ðŸš€ DEMONSTRATION: Dynamically Adaptive Swarm System")
501 |     print("=" * 80)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:502:1
    |
500 |     print("ðŸš€ DEMONSTRATION: Dynamically Adaptive Swarm System")
501 |     print("=" * 80)
502 |     
    | ^^^^
503 |     for i, query in enumerate(test_queries, 1):
504 |         print(f"\n{'='*60}")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:507:1
    |
505 |         print(f"TEST {i}: {query[:50]}...")
506 |         print('='*60)
507 |         
    | ^^^^^^^^
508 |         # Process the request
509 |         result = system.process_request(
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:516:1
    |
514 |             }
515 |         )
516 |         
    | ^^^^^^^^
517 |         # Show the execution explanation
518 |         print(system.get_execution_explanation(result))
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:519:1
    |
517 |         # Show the execution explanation
518 |         print(system.get_execution_explanation(result))
519 |         
    | ^^^^^^^^
520 |         print("\n" + "="*60)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:521:1
    |
520 |         print("\n" + "="*60)
521 |     
    | ^^^^
522 |     # Show overall system performance
523 |     print("\nðŸ“Š SYSTEM PERFORMANCE REPORT")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:530:1
    |
528 |     print(f"Cost Analysis: {performance_report['cost_analysis']}")
529 |     print(f"System Health: {performance_report['system_health']}")
530 |     
    | ^^^^
531 |     print(f"\nâœ… Demonstration complete! Processed {len(test_queries)} tasks with adaptive intelligence.")
    |
help: Remove whitespace from blank line

E501 Line too long (106 > 88)
   --> adaptivemind/adaptive_swarm/adaptive_swarm_system.py:531:88
    |
529 |     print(f"System Health: {performance_report['system_health']}")
530 |     
531 |     print(f"\nâœ… Demonstration complete! Processed {len(test_queries)} tasks with adaptive intelligence.")
    |                                                                                         ^^^^^^^^^^^^^^^^^^
    |

E501 Line too long (89 > 88)
  --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:22:89
   |
20 | - Scientific architecture selection based on scaling laws
21 | - Fallback to regular models when 1-bit isn't available
22 | - Extracts 5 key metrics: parallelizable, dynamic, sequential, tool_intensive, complexity
   |                                                                                         ^
23 | """
   |

E501 Line too long (93 > 88)
  --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:38:89
   |
36 | logger = logging.getLogger(__name__)
37 |
38 | ArchitectureType = Literal["single", "independent", "centralized", "decentralized", "hybrid"]
   |                                                                                         ^^^^^
   |

E501 Line too long (96 > 88)
  --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:95:89
   |
93 |         }
94 |
95 |         logger.info(f"BitNet Optimizer initialized - BitNet available: {self.bitnet_available}")
   |                                                                                         ^^^^^^^^
96 |
97 |     def _check_bitnet_availability(self) -> bool:
   |

S607 Starting a process with a partial executable path
   --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:106:17
    |
104 |             # Check for common BitNet model names
105 |             result = subprocess.run(
106 |                 ["ollama", "list"],
    |                 ^^^^^^^^^^^^^^^^^^
107 |                 capture_output=True,
108 |                 text=True,
    |

E501 Line too long (93 > 88)
   --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:115:89
    |
113 |                 bitnet_indicators = ["bitnet", "b1.58", "1bit", "gguf"]
114 |                 return any(indicator in models for indicator in bitnet_indicators)
115 |         except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):
    |                                                                                         ^^^^^
116 |             pass
117 |         return False
    |

S607 Starting a process with a partial executable path
   --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:130:17
    |
128 |         try:
129 |             result = subprocess.run(
130 |                 ["ollama", "list"],
    |                 ^^^^^^^^^^^^^^^^^^
131 |                 capture_output=True,
132 |                 text=True,
    |

E501 Line too long (99 > 88)
   --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:138:89
    |
136 |                 lines = result.stdout.split('\n')
137 |                 for line in lines:
138 |                     if any(indicator in line.lower() for indicator in ["bitnet", "b1.58", "1bit"]):
    |                                                                                         ^^^^^^^^^^^
139 |                         # Extract model name from line like "llama3.1:8b-bitnet"
140 |                         parts = line.split()
    |

E501 Line too long (93 > 88)
   --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:143:89
    |
141 |                         if parts:
142 |                             return parts[0]
143 |         except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):
    |                                                                                         ^^^^^
144 |             pass
145 |         return None
    |

E501 Line too long (98 > 88)
   --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:162:89
    |
161 |         # Use 1-bit model if available, otherwise fallback
162 |         model_config = self.models["bitnet"] if self.bitnet_available else self.models["fallback"]
    |                                                                                         ^^^^^^^^^^
163 |
164 |         prompt = self._build_analysis_prompt(user_query)
    |

E501 Line too long (107 > 88)
   --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:172:89
    |
171 |             processing_time = time.time() - start_time
172 |             logger.info(f"Task analysis completed in {processing_time:.2f}s using {model_config['model']}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
173 |
174 |             return characteristics
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:176:16
    |
174 |             return characteristics
175 |
176 |         except Exception as e:
    |                ^^^^^^^^^
177 |             logger.error(f"Task analysis failed: {e}")
178 |             # Return default characteristics as fallback
    |

E501 Line too long (96 > 88)
   --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:222:89
    |
220 | """
221 |
222 |     def _call_bitnet_model(self, prompt: str, model_config: dict[str, Any]) -> dict[str, float]:
    |                                                                                         ^^^^^^^^
223 |         """Call 1-bit model for task analysis.
    |

E501 Line too long (103 > 88)
   --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:331:89
    |
329 |             complexity=characteristics["complexity"],
330 |             selected_architecture=selection_result["selected_architecture"],
331 |             confidence=max(selection_result["scores"].values()) if selection_result["scores"] else 0.0,
    |                                                                                         ^^^^^^^^^^^^^^^
332 |             scores=selection_result["scores"],
333 |             reasoning=selection_result["reasoning"],
    |

E501 Line too long (117 > 88)
   --> adaptivemind/adaptive_swarm/tier1_bitnet_optimizer.py:334:89
    |
332 |             scores=selection_result["scores"],
333 |             reasoning=selection_result["reasoning"],
334 |             model_used=self.models["bitnet"]["model"] if self.bitnet_available else self.models["fallback"]["model"],
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
335 |             processing_time=processing_time
336 |         )
    |

E501 Line too long (93 > 88)
  --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:41:89
   |
39 | logger = logging.getLogger(__name__)
40 |
41 | ArchitectureType = Literal["single", "independent", "centralized", "decentralized", "hybrid"]
   |                                                                                         ^^^^^
   |

E501 Line too long (90 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:134:89
    |
132 |             return self._execute_single_agent(query, context, start_time)
133 |         elif architecture_type == "centralized":
134 |             return self._execute_centralized_swarm(query, context, start_time, max_agents)
    |                                                                                         ^^
135 |         elif architecture_type == "decentralized":
136 |             return self._execute_decentralized_swarm(query, context, start_time, max_agents)
    |

E501 Line too long (92 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:136:89
    |
134 |             return self._execute_centralized_swarm(query, context, start_time, max_agents)
135 |         elif architecture_type == "decentralized":
136 |             return self._execute_decentralized_swarm(query, context, start_time, max_agents)
    |                                                                                         ^^^^
137 |         elif architecture_type == "independent":
138 |             return self._execute_independent_swarm(query, context, start_time, max_agents)
    |

E501 Line too long (90 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:138:89
    |
136 |             return self._execute_decentralized_swarm(query, context, start_time, max_agents)
137 |         elif architecture_type == "independent":
138 |             return self._execute_independent_swarm(query, context, start_time, max_agents)
    |                                                                                         ^^
139 |         elif architecture_type == "hybrid":
140 |             return self._execute_hybrid_swarm(query, context, start_time, max_agents)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:197:16
    |
195 |             )
196 |
197 |         except Exception as e:
    |                ^^^^^^^^^
198 |             execution_time = time.time() - start_time
199 |             logger.error(f"Single agent execution failed: {e}")
    |

E501 Line too long (89 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:240:89
    |
239 |             # Execute parallel tasks
240 |             task_funcs = [self._create_task_function(task, context) for task in subtasks]
    |                                                                                         ^
241 |             results = []
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:291:16
    |
289 |             )
290 |
291 |         except Exception as e:
    |                ^^^^^^^^^
292 |             execution_time = time.time() - start_time
293 |             logger.error(f"Centralized swarm execution failed: {e}")
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:362:16
    |
360 |             )
361 |
362 |         except Exception as e:
    |                ^^^^^^^^^
363 |             execution_time = time.time() - start_time
364 |             logger.error(f"Decentralized swarm execution failed: {e}")
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:417:28
    |
415 |                         result = future.result(timeout=30)
416 |                         results.append(result)
417 |                     except Exception as e:
    |                            ^^^^^^^^^
418 |                         logger.error(f"Independent agent failed: {e}")
419 |                         results.append(
    |

E501 Line too long (97 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:442:89
    |
440 |                 coordination_tokens=0,
441 |                 single_agent_error_rate=0.1,
442 |                 multi_agent_error_rate=max(0.1, 1.0 - task_progress * 0.8),  # High amplification
    |                                                                                         ^^^^^^^^^
443 |                 unique_actions=len(successful_results),
444 |                 total_actions=len(results)
    |

E501 Line too long (104 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:449:89
    |
447 |             # Apply paper's 17.2x amplification warning
448 |             if metrics.error_amplification > 10.0:
449 |                 logger.warning(f"High error amplification detected: {metrics.error_amplification:.1f}x")
    |                                                                                         ^^^^^^^^^^^^^^^^
450 |
451 |             synthesized_output = self._synthesize_results(successful_results, query)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:471:16
    |
469 |             )
470 |
471 |         except Exception as e:
    |                ^^^^^^^^^
472 |             execution_time = time.time() - start_time
473 |             logger.error(f"Independent swarm execution failed: {e}")
    |

E501 Line too long (108 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:506:89
    |
504 |             if not single_result.success or single_result.efficiency < 0.8:
505 |                 logger.info("Single agent insufficient, trying centralized swarm")
506 |                 centralized_result = self._execute_centralized_swarm(query, context, start_time, max_agents)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^
507 |
508 |                 # Return the better result
    |

E501 Line too long (107 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:509:89
    |
508 |                 # Return the better result
509 |                 if centralized_result.success and centralized_result.efficiency > single_result.efficiency:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
510 |                     return centralized_result
511 |                 else:
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:516:16
    |
514 |                 return single_result
515 |
516 |         except Exception as e:
    |                ^^^^^^^^^
517 |             execution_time = time.time() - start_time
518 |             logger.error(f"Hybrid swarm execution failed: {e}")
    |

E501 Line too long (111 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:608:89
    |
607 | **Scientific Metrics:**
608 | - Efficiency: {result.efficiency:.3f} {'(Target achieved!)' if result.efficiency > 1.0 else '(Below baseline)'}
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
609 | - Overhead: {result.overhead:.3f} {'(Low overhead)' if result.overhead < 0.3 else '(High overhead)'}
610 | - Error Amplification: {result.error_amplification:.1f}x
    |

E501 Line too long (100 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:609:89
    |
607 | **Scientific Metrics:**
608 | - Efficiency: {result.efficiency:.3f} {'(Target achieved!)' if result.efficiency > 1.0 else '(Below baseline)'}
609 | - Overhead: {result.overhead:.3f} {'(Low overhead)' if result.overhead < 0.3 else '(High overhead)'}
    |                                                                                         ^^^^^^^^^^^^
610 | - Error Amplification: {result.error_amplification:.1f}x
    |

E501 Line too long (110 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:617:90
    |
615 |         # Risk assessment based on paper's findings
616 |         if result.architecture == "independent" and result.error_amplification > 10:
617 |             explanation += "- âš ï¸ **HIGH RISK**: Independent agents detected high error amplification (17.2x)\n"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
618 |         elif result.architecture == "centralized" and result.error_amplification < 5:
619 |             explanation += "- âœ… **LOW RISK**: Centralized coordination contains errors well (4.4x)\n"
    |

E501 Line too long (102 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:619:88
    |
617 |             explanation += "- âš ï¸ **HIGH RISK**: Independent agents detected high error amplification (17.2x)\n"
618 |         elif result.architecture == "centralized" and result.error_amplification < 5:
619 |             explanation += "- âœ… **LOW RISK**: Centralized coordination contains errors well (4.4x)\n"
    |                                                                                         ^^^^^^^^^^^^^^
620 |         elif result.architecture == "single":
621 |             explanation += "- âœ… **NO RISK**: Single agent avoids coordination errors\n"
    |

E501 Line too long (93 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory.py:625:89
    |
623 |         explanation += f"""
624 | **Performance vs. Targets:**
625 | - Target Efficiency: {self.performance_targets[result.architecture]['target_efficiency']:.3f}
    |                                                                                         ^^^^^
626 | - Achieved Efficiency: {result.efficiency:.3f}
627 | - Efficiency Gain: {((result.efficiency - 1.0) * 100):+.1f}%
    |

E501 Line too long (93 > 88)
  --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:31:89
   |
29 | logger = logging.getLogger(__name__)
30 |
31 | ArchitectureType = Literal["single", "independent", "centralized", "decentralized", "hybrid"]
   |                                                                                         ^^^^^
   |

E501 Line too long (91 > 88)
  --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:69:89
   |
67 |         self.errors_count = 0
68 |
69 |     def execute_task(self, task_func, context: dict[str, Any] | None = None) -> TaskResult:
   |                                                                                         ^^^
70 |         """Execute a task function."""
71 |         try:
   |

BLE001 Do not catch blind exception: `Exception`
  --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:88:16
   |
86 |                 }
87 |             )
88 |         except Exception as e:
   |                ^^^^^^^^^
89 |             self.errors_count += 1
90 |             return TaskResult(
   |

E501 Line too long (90 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:172:89
    |
170 |             return self._execute_single_agent(query, context, start_time)
171 |         elif architecture_type == "centralized":
172 |             return self._execute_centralized_swarm(query, context, start_time, max_agents)
    |                                                                                         ^^
173 |         elif architecture_type == "decentralized":
174 |             return self._execute_decentralized_swarm(query, context, start_time, max_agents)
    |

E501 Line too long (92 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:174:89
    |
172 |             return self._execute_centralized_swarm(query, context, start_time, max_agents)
173 |         elif architecture_type == "decentralized":
174 |             return self._execute_decentralized_swarm(query, context, start_time, max_agents)
    |                                                                                         ^^^^
175 |         elif architecture_type == "independent":
176 |             return self._execute_independent_swarm(query, context, start_time, max_agents)
    |

E501 Line too long (90 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:176:89
    |
174 |             return self._execute_decentralized_swarm(query, context, start_time, max_agents)
175 |         elif architecture_type == "independent":
176 |             return self._execute_independent_swarm(query, context, start_time, max_agents)
    |                                                                                         ^^
177 |         elif architecture_type == "hybrid":
178 |             return self._execute_hybrid_swarm(query, context, start_time, max_agents)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:235:16
    |
233 |             )
234 |
235 |         except Exception as e:
    |                ^^^^^^^^^
236 |             execution_time = time.time() - start_time
237 |             logger.error(f"Single agent execution failed: {e}")
    |

E501 Line too long (89 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:280:89
    |
279 |             # Execute parallel tasks
280 |             task_funcs = [self._create_task_function(task, context) for task in subtasks]
    |                                                                                         ^
281 |             results = []
    |

E501 Line too long (95 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:285:89
    |
283 |             with ThreadPoolExecutor(max_workers=num_agents) as executor:
284 |                 future_to_agent = {
285 |                     executor.submit(agent.execute_task, task_func, context): (agent, task_func)
    |                                                                                         ^^^^^^^
286 |                     for agent, task_func in zip(agents, task_funcs, strict=False)
287 |                 }
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:293:28
    |
291 |                         result = future.result(timeout=30)
292 |                         results.append(result)
293 |                     except Exception as e:
    |                            ^^^^^^^^^
294 |                         logger.error(f"Centralized agent failed: {e}")
295 |                         results.append(
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:348:16
    |
346 |             )
347 |
348 |         except Exception as e:
    |                ^^^^^^^^^
349 |             execution_time = time.time() - start_time
350 |             logger.error(f"Centralized swarm execution failed: {e}")
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:418:16
    |
416 |             )
417 |
418 |         except Exception as e:
    |                ^^^^^^^^^
419 |             execution_time = time.time() - start_time
420 |             logger.error(f"Decentralized swarm execution failed: {e}")
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:473:28
    |
471 |                         result = future.result(timeout=30)
472 |                         results.append(result)
473 |                     except Exception as e:
    |                            ^^^^^^^^^
474 |                         logger.error(f"Independent agent failed: {e}")
475 |                         results.append(
    |

E501 Line too long (97 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:498:89
    |
496 |                 coordination_tokens=0,
497 |                 single_agent_error_rate=0.1,
498 |                 multi_agent_error_rate=max(0.1, 1.0 - task_progress * 0.8),  # High amplification
    |                                                                                         ^^^^^^^^^
499 |                 unique_actions=len(successful_results),
500 |                 total_actions=len(results)
    |

E501 Line too long (107 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:505:89
    |
503 |             # Apply paper's 17.2x amplification warning
504 |             if metrics["error_amplification"] > 10.0:
505 |                 logger.warning(f"High error amplification detected: {metrics['error_amplification']:.1f}x")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
506 |
507 |             synthesized_output = self._synthesize_results(successful_results, query)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:527:16
    |
525 |             )
526 |
527 |         except Exception as e:
    |                ^^^^^^^^^
528 |             execution_time = time.time() - start_time
529 |             logger.error(f"Independent swarm execution failed: {e}")
    |

E501 Line too long (108 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:562:89
    |
560 |             if not single_result.success or single_result.efficiency < 0.8:
561 |                 logger.info("Single agent insufficient, trying centralized swarm")
562 |                 centralized_result = self._execute_centralized_swarm(query, context, start_time, max_agents)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^
563 |
564 |                 # Return the better result
    |

E501 Line too long (107 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:565:89
    |
564 |                 # Return the better result
565 |                 if centralized_result.success and centralized_result.efficiency > single_result.efficiency:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
566 |                     return centralized_result
567 |                 else:
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:572:16
    |
570 |                 return single_result
571 |
572 |         except Exception as e:
    |                ^^^^^^^^^
573 |             execution_time = time.time() - start_time
574 |             logger.error(f"Hybrid swarm execution failed: {e}")
    |

E501 Line too long (89 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:606:89
    |
604 |             return [f"Process part {i+1} of: {query}" for i in range(num_agents)]
605 |
606 |     def _synthesize_results(self, results: list[TaskResult], original_query: str) -> str:
    |                                                                                         ^
607 |         """Synthesize multiple results into coherent output."""
608 |         if not results:
    |

E501 Line too long (111 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:674:89
    |
673 | **Scientific Metrics:**
674 | - Efficiency: {result.efficiency:.3f} {'(Target achieved!)' if result.efficiency > 1.0 else '(Below baseline)'}
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
675 | - Overhead: {result.overhead:.3f} {'(Low overhead)' if result.overhead < 0.3 else '(High overhead)'}
676 | - Error Amplification: {result.error_amplification:.1f}x
    |

E501 Line too long (100 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:675:89
    |
673 | **Scientific Metrics:**
674 | - Efficiency: {result.efficiency:.3f} {'(Target achieved!)' if result.efficiency > 1.0 else '(Below baseline)'}
675 | - Overhead: {result.overhead:.3f} {'(Low overhead)' if result.overhead < 0.3 else '(High overhead)'}
    |                                                                                         ^^^^^^^^^^^^
676 | - Error Amplification: {result.error_amplification:.1f}x
    |

E501 Line too long (110 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:683:90
    |
681 |         # Risk assessment based on paper's findings
682 |         if result.architecture == "independent" and result.error_amplification > 10:
683 |             explanation += "- âš ï¸ **HIGH RISK**: Independent agents detected high error amplification (17.2x)\n"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
684 |         elif result.architecture == "centralized" and result.error_amplification < 5:
685 |             explanation += "- âœ… **LOW RISK**: Centralized coordination contains errors well (4.4x)\n"
    |

E501 Line too long (102 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:685:88
    |
683 |             explanation += "- âš ï¸ **HIGH RISK**: Independent agents detected high error amplification (17.2x)\n"
684 |         elif result.architecture == "centralized" and result.error_amplification < 5:
685 |             explanation += "- âœ… **LOW RISK**: Centralized coordination contains errors well (4.4x)\n"
    |                                                                                         ^^^^^^^^^^^^^^
686 |         elif result.architecture == "single":
687 |             explanation += "- âœ… **NO RISK**: Single agent avoids coordination errors\n"
    |

E501 Line too long (93 > 88)
   --> adaptivemind/adaptive_swarm/tier2_swarm_factory_standalone.py:691:89
    |
689 |         explanation += f"""
690 | **Performance vs. Targets:**
691 | - Target Efficiency: {self.performance_targets[result.architecture]['target_efficiency']:.3f}
    |                                                                                         ^^^^^
692 | - Achieved Efficiency: {result.efficiency:.3f}
693 | - Efficiency Gain: {((result.efficiency - 1.0) * 100):+.1f}%
    |

E501 Line too long (93 > 88)
  --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:34:89
   |
33 | EscalationDecision = Literal["escalate", "continue_local", "retry_local"]
34 | ArchitectureType = Literal["single", "independent", "centralized", "decentralized", "hybrid"]
   |                                                                                         ^^^^^
   |

E501 Line too long (90 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:150:89
    |
149 |         # Factor 3: Task Complexity Analysis
150 |         complexity_analysis = self._analyze_task_complexity(task_complexity, swarm_result)
    |                                                                                         ^^
151 |         decision_factors.append(complexity_analysis)
    |

E501 Line too long (94 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:154:89
    |
153 |         # Factor 4: Cost Analysis
154 |         cost_analysis = self._analyze_costs(swarm_result, task_complexity, budget_constraints)
    |                                                                                         ^^^^^^
155 |         decision_factors.append(cost_analysis)
    |

E501 Line too long (91 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:158:89
    |
157 |         # Factor 5: User Preferences
158 |         preference_analysis = self._analyze_user_preferences(user_preference, swarm_result)
    |                                                                                         ^^^
159 |         decision_factors.append(preference_analysis)
    |

E501 Line too long (96 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:218:89
    |
216 |         }
217 |
218 |         if error_amp >= self.escalation_thresholds["error_amplification"]["immediate_escalate"]:
    |                                                                                         ^^^^^^^^
219 |             analysis.update({
220 |                 "risk_level": "critical",
    |

E501 Line too long (152 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:223:89
    |
221 | â€¦y",
222 | â€¦
223 | â€¦on: {error_amp:.1f}x (>{self.escalation_thresholds['error_amplification']['immediate_escalate']})"
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
224 | â€¦
225 | â€¦error_amplification"]["critical"]:
    |

E501 Line too long (167 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:230:89
    |
228 | â€¦
229 | â€¦
230 | â€¦mp:.1f}x (approaching {self.escalation_thresholds['error_amplification']['critical']} failure threshold)"
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
231 | â€¦
232 | â€¦plification"]["warning"]:
    |

E501 Line too long (90 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:246:89
    |
244 |         return analysis
245 |
246 |     def _analyze_efficiency(self, swarm_result, task_complexity: float) -> dict[str, Any]:
    |                                                                                         ^^
247 |         """Analyze efficiency performance."""
248 |         efficiency = swarm_result.efficiency
    |

E501 Line too long (89 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:253:89
    |
251 |         # Get target efficiency for this architecture
252 |         if architecture == "single":
253 |             target_efficiency = self.escalation_thresholds["efficiency"]["target_single"]
    |                                                                                         ^
254 |         elif architecture == "centralized":
255 |             target_efficiency = self.escalation_thresholds["efficiency"]["target_centralized"]
    |

E501 Line too long (94 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:255:89
    |
253 |             target_efficiency = self.escalation_thresholds["efficiency"]["target_single"]
254 |         elif architecture == "centralized":
255 |             target_efficiency = self.escalation_thresholds["efficiency"]["target_centralized"]
    |                                                                                         ^^^^^^
256 |         else:
257 |             target_efficiency = 1.0  # Default target
    |

E501 Line too long (148 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:280:89
    |
278 | â€¦
279 | â€¦
280 | â€¦ threshold: {efficiency:.3f} < {self.escalation_thresholds['efficiency']['minimum_acceptable']}"
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
281 | â€¦
282 | â€¦holds["efficiency"]["performance_degradation"]:
    |

E501 Line too long (99 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:282:89
    |
280 | â€¦             "reason": f"Below minimum efficiency threshold: {efficiency:.3f} < {self.escalation_thresholds['efficiency']['minimum_aâ€¦
281 | â€¦         })
282 | â€¦     elif performance_gap > self.escalation_thresholds["efficiency"]["performance_degradation"]:
    |                                                                                       ^^^^^^^^^^^
283 | â€¦         analysis.update({
284 | â€¦             "risk_level": "medium",
    |

E501 Line too long (92 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:287:89
    |
285 |                 "recommendation": "monitor",
286 |                 "weight": 0.4,
287 |                 "reason": f"Significant performance gap: {performance_gap:.1%} below target"
    |                                                                                         ^^^^
288 |             })
289 |         else:
    |

E501 Line too long (103 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:291:89
    |
289 |         else:
290 |             analysis.update({
291 |                 "reason": f"Acceptable efficiency: {efficiency:.3f} ({efficiency_ratio:.1%} of target)"
    |                                                                                         ^^^^^^^^^^^^^^^
292 |             })
    |

E501 Line too long (95 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:296:89
    |
294 |         return analysis
295 |
296 |     def _analyze_task_complexity(self, task_complexity: float, swarm_result) -> dict[str, Any]:
    |                                                                                         ^^^^^^^
297 |         """Analyze task complexity impact."""
298 |         analysis = {
    |

E501 Line too long (92 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:306:89
    |
304 |         }
305 |
306 |         if task_complexity >= self.escalation_thresholds["task_complexity"]["very_complex"]:
    |                                                                                         ^^^^
307 |             analysis.update({
308 |                 "risk_level": "high",
    |

E501 Line too long (115 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:311:89
    |
309 |                 "recommendation": "escalate",
310 |                 "weight": 0.5,
311 |                 "reason": f"Very complex task (complexity: {task_complexity:.1f}) may benefit from cloud resources"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
312 |             })
313 |         elif task_complexity >= self.escalation_thresholds["task_complexity"]["complex"]:
    |

E501 Line too long (89 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:313:89
    |
311 |                 "reason": f"Very complex task (complexity: {task_complexity:.1f}) may benefit from cloud resources"
312 |             })
313 |         elif task_complexity >= self.escalation_thresholds["task_complexity"]["complex"]:
    |                                                                                         ^
314 |             analysis.update({
315 |                 "risk_level": "medium",
    |

E501 Line too long (96 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:318:89
    |
316 |                 "recommendation": "monitor",
317 |                 "weight": 0.3,
318 |                 "reason": "Complex task may need cloud escalation if local performance degrades"
    |                                                                                         ^^^^^^^^
319 |             })
320 |         else:
    |

E501 Line too long (98 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:339:89
    |
337 |         local_cost = (
338 |             tokens_used * self.cost_model["local"]["base_cost_per_token"] +
339 |             swarm_result.coordination_tokens * self.cost_model["local"]["coordination_overhead"] +
    |                                                                                         ^^^^^^^^^^
340 |             self.cost_model["local"]["setup_cost"]
341 |         )
    |

E501 Line too long (98 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:346:89
    |
344 |         cloud_cost = (
345 |             tokens_used * self.cost_model["cloud"]["base_cost_per_token"] +
346 |             swarm_result.coordination_tokens * self.cost_model["cloud"]["coordination_overhead"] +
    |                                                                                         ^^^^^^^^^^
347 |             self.cost_model["cloud"]["setup_cost"]
348 |         )
    |

E501 Line too long (106 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:368:89
    |
367 |         # Cost-based escalation logic
368 |         if budget_constraints and budget_constraints.get("max_cost", float('inf')) < effective_cloud_cost:
    |                                                                                         ^^^^^^^^^^^^^^^^^^
369 |             analysis.update({
370 |                 "risk_level": "high",
    |

E501 Line too long (124 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:373:89
    |
371 |                 "recommendation": "continue_local",
372 |                 "weight": 0.8,
373 |                 "reason": f"Cloud cost (${effective_cloud_cost:.4f}) exceeds budget (${budget_constraints['max_cost']:.4f})"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
374 |             })
375 |         elif cost_ratio > 5.0:  # Cloud is 5x more expensive
    |

E501 Line too long (126 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:380:89
    |
378 |                 "recommendation": "continue_local",
379 |                 "weight": 0.4,
380 |                 "reason": f"Cloud cost {cost_ratio:.1f}x higher than local (${effective_cloud_cost:.4f} vs ${local_cost:.4f})"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
381 |             })
382 |         else:
    |

E501 Line too long (137 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:384:89
    |
382 | â€¦
383 | â€¦
384 | â€¦ference: {cost_ratio:.1f}x (${effective_cloud_cost:.4f} cloud vs ${local_cost:.4f} local)"
    |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
385 | â€¦
    |

E501 Line too long (96 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:428:89
    |
426 |         """Make final escalation decision based on all factors."""
427 |         # Check for immediate escalation triggers
428 |         error_factor = next(f for f in decision_factors if f["factor"] == "error_amplification")
    |                                                                                         ^^^^^^^^
429 |         if error_factor["recommendation"] == "escalate_immediately":
430 |             return "escalate", EscalationReason.HIGH_ERROR_AMPLIFICATION, 0.9
    |

E501 Line too long (106 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:466:89
    |
464 |             if error_factor["risk_level"] in ["high", "critical"]:
465 |                 reason = EscalationReason.HIGH_ERROR_AMPLIFICATION
466 |             elif next(f for f in decision_factors if f["factor"] == "efficiency")["risk_level"] == "high":
    |                                                                                         ^^^^^^^^^^^^^^^^^^
467 |                 reason = EscalationReason.LOW_EFFICIENCY
468 |             else:
    |

E501 Line too long (95 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:490:88
    |
489 |         if decision == "escalate":
490 |             recommendations.append("ðŸš€ Escalating to cloud resources for improved reliability")
    |                                                                                         ^^^^^^^
491 |
492 |             # Add reason-specific recommendations
    |

E501 Line too long (99 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:494:90
    |
492 |             # Add reason-specific recommendations
493 |             if reason == EscalationReason.HIGH_ERROR_AMPLIFICATION:
494 |                 recommendations.append("âš ï¸ Local multi-agent coordination showing high error rates")
    |                                                                                         ^^^^^^^^^^^
495 |                 recommendations.append("ðŸ’¡ Cloud models provide better consistency and reduced error propagation")
496 |             elif reason == EscalationReason.LOW_EFFICIENCY:
    |

E501 Line too long (114 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:495:88
    |
493 |             if reason == EscalationReason.HIGH_ERROR_AMPLIFICATION:
494 |                 recommendations.append("âš ï¸ Local multi-agent coordination showing high error rates")
495 |                 recommendations.append("ðŸ’¡ Cloud models provide better consistency and reduced error propagation")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
496 |             elif reason == EscalationReason.LOW_EFFICIENCY:
497 |                 recommendations.append("ðŸ“Š Local efficiency below acceptable threshold")
    |

E501 Line too long (109 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:498:90
    |
496 |             elif reason == EscalationReason.LOW_EFFICIENCY:
497 |                 recommendations.append("ðŸ“Š Local efficiency below acceptable threshold")
498 |                 recommendations.append("â˜ï¸ Cloud resources may provide better performance for this task type")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^
499 |             elif reason == EscalationReason.TASK_FAILURE:
500 |                 recommendations.append("âŒ Local execution failed, attempting cloud recovery")
    |

E501 Line too long (94 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:500:88
    |
498 |                 recommendations.append("â˜ï¸ Cloud resources may provide better performance for this task type")
499 |             elif reason == EscalationReason.TASK_FAILURE:
500 |                 recommendations.append("âŒ Local execution failed, attempting cloud recovery")
    |                                                                                         ^^^^^^
501 |                 recommendations.append("ðŸ”„ Cloud escalation provides fallback mechanism")
    |

E501 Line too long (89 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:501:88
    |
499 |             elif reason == EscalationReason.TASK_FAILURE:
500 |                 recommendations.append("âŒ Local execution failed, attempting cloud recovery")
501 |                 recommendations.append("ðŸ”„ Cloud escalation provides fallback mechanism")
    |                                                                                         ^
502 |
503 |         elif decision == "continue_local":
    |

E501 Line too long (96 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:508:89
    |
507 |             # Add optimization suggestions
508 |             efficiency_factor = next(f for f in decision_factors if f["factor"] == "efficiency")
    |                                                                                         ^^^^^^^^
509 |             if efficiency_factor.get("performance_gap", 0) > 0.2:
510 |                 recommendations.append("ðŸ“ˆ Consider optimizing local architecture for better efficiency")
    |

E501 Line too long (105 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:510:88
    |
508 |             efficiency_factor = next(f for f in decision_factors if f["factor"] == "efficiency")
509 |             if efficiency_factor.get("performance_gap", 0) > 0.2:
510 |                 recommendations.append("ðŸ“ˆ Consider optimizing local architecture for better efficiency")
    |                                                                                         ^^^^^^^^^^^^^^^^^
511 |
512 |             error_factor = next(f for f in decision_factors if f["factor"] == "error_amplification")
    |

E501 Line too long (100 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:512:89
    |
510 |                 recommendations.append("ðŸ“ˆ Consider optimizing local architecture for better efficiency")
511 |
512 |             error_factor = next(f for f in decision_factors if f["factor"] == "error_amplification")
    |                                                                                         ^^^^^^^^^^^^
513 |             if error_factor.get("risk_level") == "medium":
514 |                 recommendations.append("ðŸ‘ï¸ Monitor error rates for potential future escalation")
    |

E501 Line too long (95 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:514:90
    |
512 |             error_factor = next(f for f in decision_factors if f["factor"] == "error_amplification")
513 |             if error_factor.get("risk_level") == "medium":
514 |                 recommendations.append("ðŸ‘ï¸ Monitor error rates for potential future escalation")
    |                                                                                         ^^^^^^^
515 |
516 |         return recommendations
    |

E501 Line too long (104 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:539:89
    |
537 |             self.escalation_history = self.escalation_history[-500:]
538 |
539 |         logger.info(f"Escalation decision: {analysis.decision} (confidence: {analysis.confidence:.2f})")
    |                                                                                         ^^^^^^^^^^^^^^^^
540 |
541 |     def get_escalation_explanation(self, analysis: EscalationAnalysis) -> str:
    |

E501 Line too long (94 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:561:89
    |
559 | - **Local Cost:** ${analysis.cost_estimate_local:.4f}
560 | - **Cloud Cost:** ${analysis.cost_estimate_cloud:.4f}
561 | - **Cost Ratio:** {analysis.cost_estimate_cloud/max(analysis.cost_estimate_local, 0.001):.1f}x
    |                                                                                         ^^^^^^
562 |
563 | **Current Swarm Performance:**
    |

E501 Line too long (91 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:566:89
    |
564 | - **Architecture:** {analysis.metadata['swarm_metrics']['architecture'].upper()}
565 | - **Efficiency:** {analysis.metadata['swarm_metrics']['efficiency']:.3f}
566 | - **Error Amplification:** {analysis.metadata['swarm_metrics']['error_amplification']:.1f}x
    |                                                                                         ^^^
567 | - **Success:** {'âœ…' if analysis.metadata['swarm_metrics']['success'] else 'âŒ'}
    |

E501 Line too long (91 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:583:85
    |
581 | """
582 |         for factor in analysis.metadata["decision_factors"]:
583 |             risk_emoji = {"low": "ðŸŸ¢", "medium": "ðŸŸ¡", "high": "ðŸ”´", "critical": "âš«"}.get(
    |                                                                                         ^^^
584 |                 factor["risk_level"], "âšª"
585 |             )
    |

E501 Line too long (108 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:586:89
    |
584 |                 factor["risk_level"], "âšª"
585 |             )
586 |             explanation += f"- {risk_emoji} **{factor['factor'].title()}:** {factor.get('reason', 'N/A')}\n"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^
587 |
588 |         return explanation
    |

E501 Line too long (95 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:600:89
    |
598 |         sum(1 for d in recent_decisions if d["decision"] == "continue_local")
599 |
600 |         avg_confidence = sum(d["confidence"] for d in recent_decisions) / len(recent_decisions)
    |                                                                                         ^^^^^^^
601 |         avg_efficiency = sum(d["efficiency"] for d in recent_decisions) / len(recent_decisions)
602 |         avg_error_amp = sum(d["error_amplification"] for d in recent_decisions) / len(recent_decisions)
    |

E501 Line too long (95 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:601:89
    |
600 |         avg_confidence = sum(d["confidence"] for d in recent_decisions) / len(recent_decisions)
601 |         avg_efficiency = sum(d["efficiency"] for d in recent_decisions) / len(recent_decisions)
    |                                                                                         ^^^^^^^
602 |         avg_error_amp = sum(d["error_amplification"] for d in recent_decisions) / len(recent_decisions)
    |

E501 Line too long (103 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:602:89
    |
600 |         avg_confidence = sum(d["confidence"] for d in recent_decisions) / len(recent_decisions)
601 |         avg_efficiency = sum(d["efficiency"] for d in recent_decisions) / len(recent_decisions)
602 |         avg_error_amp = sum(d["error_amplification"] for d in recent_decisions) / len(recent_decisions)
    |                                                                                         ^^^^^^^^^^^^^^^
603 |
604 |         return {
    |

E501 Line too long (135 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:610:89
    |
608 | â€¦cy,
609 | â€¦_error_amp,
610 | â€¦cloud"] - d["cost_local"] for d in recent_decisions if d["decision"] == "continue_local")
    |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
611 | â€¦
    |

E501 Line too long (91 > 88)
   --> adaptivemind/adaptive_swarm/tier3_cloud_escalation.py:666:89
    |
664 |     for _i, result in enumerate(test_cases, 1):
665 |
666 |         analysis = escalation_manager.should_escalate_to_cloud(result, task_complexity=0.7)
    |                                                                                         ^^^
667 |
668 |         # Print performance stats
    |

D101 Missing docstring in public class
  --> adaptivemind/core/mcp_agent.py:14:7
   |
14 | class MCPAdaptiveMindAgent:
   |       ^^^^^^^^^^^^^^^^^^^^
15 |     def __init__(self, enable_mcp: bool = False, *args, **kwargs):
16 |         # Minimal compatibility shim used by legacy endpoints in tests
   |

FBT001 Boolean-typed positional argument in function definition
  --> adaptivemind/core/mcp_agent.py:15:24
   |
14 | class MCPAdaptiveMindAgent:
15 |     def __init__(self, enable_mcp: bool = False, *args, **kwargs):
   |                        ^^^^^^^^^^
16 |         # Minimal compatibility shim used by legacy endpoints in tests
17 |         self.enable_mcp = enable_mcp
   |

FBT002 Boolean default positional argument in function definition
  --> adaptivemind/core/mcp_agent.py:15:24
   |
14 | class MCPAdaptiveMindAgent:
15 |     def __init__(self, enable_mcp: bool = False, *args, **kwargs):
   |                        ^^^^^^^^^^
16 |         # Minimal compatibility shim used by legacy endpoints in tests
17 |         self.enable_mcp = enable_mcp
   |

D102 Missing docstring in public method
  --> adaptivemind/core/mcp_agent.py:19:9
   |
17 |         self.enable_mcp = enable_mcp
18 |
19 |     def start(self) -> bool:
   |         ^^^^^
20 |         return True
   |

D102 Missing docstring in public method
  --> adaptivemind/core/mcp_agent.py:22:9
   |
20 |         return True
21 |
22 |     def chat(self, prompt: str, force_local: bool = False, **kwargs) -> str:
   |         ^^^^
23 |         # Minimal chat implementation for tests: return a simple prefix that
24 |         # includes 'Persona focus' to satisfy test expectations.
   |

FBT001 Boolean-typed positional argument in function definition
  --> adaptivemind/core/mcp_agent.py:22:33
   |
20 |         return True
21 |
22 |     def chat(self, prompt: str, force_local: bool = False, **kwargs) -> str:
   |                                 ^^^^^^^^^^^
23 |         # Minimal chat implementation for tests: return a simple prefix that
24 |         # includes 'Persona focus' to satisfy test expectations.
   |

FBT002 Boolean default positional argument in function definition
  --> adaptivemind/core/mcp_agent.py:22:33
   |
20 |         return True
21 |
22 |     def chat(self, prompt: str, force_local: bool = False, **kwargs) -> str:
   |                                 ^^^^^^^^^^^
23 |         # Minimal chat implementation for tests: return a simple prefix that
24 |         # includes 'Persona focus' to satisfy test expectations.
   |

F401 `.client.MCPClient` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> adaptivemind/mcp/__init__.py:13:21
   |
11 | """MCP module shim for testing."""
12 |
13 | from .client import MCPClient, MCPServerManager, ModelRouter
   |                     ^^^^^^^^^
   |
help: Use an explicit re-export: `MCPClient as MCPClient`

F401 `.client.MCPServerManager` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> adaptivemind/mcp/__init__.py:13:32
   |
11 | """MCP module shim for testing."""
12 |
13 | from .client import MCPClient, MCPServerManager, ModelRouter
   |                                ^^^^^^^^^^^^^^^^
   |
help: Use an explicit re-export: `MCPServerManager as MCPServerManager`

F401 `.client.ModelRouter` imported but unused; consider removing, adding to `__all__`, or using a redundant alias
  --> adaptivemind/mcp/__init__.py:13:50
   |
11 | """MCP module shim for testing."""
12 |
13 | from .client import MCPClient, MCPServerManager, ModelRouter
   |                                                  ^^^^^^^^^^^
   |
help: Use an explicit re-export: `ModelRouter as ModelRouter`

D101 Missing docstring in public class
  --> adaptivemind/mcp/client.py:13:7
   |
11 | """MCP client shim for testing."""
12 |
13 | class MCPClient:
   |       ^^^^^^^^^
14 |     def __init__(self, servers=None, monitor=None):
15 |         pass
   |

D101 Missing docstring in public class
  --> adaptivemind/mcp/client.py:17:7
   |
15 |         pass
16 |
17 | class ModelRouter:
   |       ^^^^^^^^^^^
18 |     def __init__(self):
19 |         pass
   |

D101 Missing docstring in public class
  --> adaptivemind/mcp/client.py:21:7
   |
19 |         pass
20 |
21 | class MCPServerManager:
   |       ^^^^^^^^^^^^^^^^
22 |     def __init__(self):
23 |         pass
   |

D101 Missing docstring in public class
  --> adaptivemind/orchestration/graph.py:30:7
   |
30 | class TeamWorkflowState(TypedDict, total=False):
   |       ^^^^^^^^^^^^^^^^^
31 |     objective: str
32 |     context: dict[str, Any]
   |

FBT003 Boolean positional value in function call
   --> adaptivemind/orchestration/graph.py:163:17
    |
161 |                 )
162 |             return CriticVerdict(
163 |                 False,
    |                 ^^^^^
164 |                 [],
165 |                 1.0,
    |

D102 Missing docstring in public method
  --> adaptivemind/orchestration/message_bus.py:28:15
   |
26 |         self._messages: list[tuple[str, Any]] = []
27 |
28 |     async def publish(self, event: str, payload: Any, run_id: str | None = None, step_id: str | None = None, parent_id: str | None = Nâ€¦
   |               ^^^^^^^
29 |         # Simple asynchronous no-op that stores messages locally for introspection
30 |         self._messages.append((event, payload))
   |

E501 Line too long (147 > 88)
  --> adaptivemind/orchestration/message_bus.py:28:89
   |
26 | â€¦
27 | â€¦
28 | â€¦y, run_id: str | None = None, step_id: str | None = None, parent_id: str | None = None) -> None:
   |                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
29 | â€¦sages locally for introspection
30 | â€¦
   |

D102 Missing docstring in public method
  --> adaptivemind/orchestration/message_bus.py:33:9
   |
31 |         await asyncio.sleep(0)  # yield control
32 |
33 |     def get_messages(self) -> list[tuple[str, Any]]:
   |         ^^^^^^^^^^^^
34 |         return list(self._messages)
   |

D101 Missing docstring in public class
  --> adaptivemind/orchestration/mission.py:18:7
   |
17 | @dataclass
18 | class Mission:
   |       ^^^^^^^
19 |     id: str
20 |     title: str
   |

D205 1 blank line required between summary line and description
  --> adaptivemind/orchestration/mission.py:28:5
   |
27 |   def save_mission(mission: Mission) -> None:
28 | /     """Persist mission metadata. For tests we perform a no-op persistence.
29 | |     This implementation exists to avoid import-time errors during tests.
30 | |     """
   | |_______^
31 |       # In a full runtime this would write to disk or a DB. For tests, no-op.
32 |       return None
   |
help: Insert single blank line

D101 Missing docstring in public class
  --> adaptivemind/orchestration/mission_planner.py:19:7
   |
18 | @dataclass
19 | class DAGPlaceholder:
   |       ^^^^^^^^^^^^^^
20 |     mission_id: str
21 |     steps: list
   |

D101 Missing docstring in public class
  --> adaptivemind/orchestration/mission_planner.py:24:7
   |
24 | class MissionPlanner:
   |       ^^^^^^^^^^^^^^
25 |     def __init__(self, missions_dir: str | None = None) -> None:
26 |         self.missions_dir = missions_dir
   |

D102 Missing docstring in public method
  --> adaptivemind/orchestration/mission_planner.py:28:9
   |
26 |         self.missions_dir = missions_dir
27 |
28 |     def plan(self, goal: str, context: dict[str, Any]) -> DAGPlaceholder:
   |         ^^^^
29 |         # Create a trivial DAG object with a deterministic mission ID
30 |         mission_id = str(uuid.uuid4())
   |

FBT003 Boolean positional value in function call
   --> adaptivemind/orchestration/orchestrator.py:266:33
    |
264 |                         data = await coro
265 |                     self.performance_tracker.record_event(
266 |                         "step", True, attempt
    |                                 ^^^^
267 |                     )
268 |                     break
    |

FBT003 Boolean positional value in function call
   --> adaptivemind/orchestration/orchestrator.py:273:33
    |
271 |                         raise
272 |                     self.performance_tracker.record_event(
273 |                         "step", False, attempt
    |                                 ^^^^^
274 |                     )
275 |                     if attempt > retries:
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/orchestration/orchestrator.py:603:16
    |
601 |                 "exploration_metrics": auction.metrics,
602 |             }
603 |         except Exception as e:
    |                ^^^^^^^^^
604 |             logger.error(f"Single specialist analysis failed: {e}")
605 |             return self._create_error_response(str(e), request)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/orchestration/orchestrator.py:662:32
    |
660 |                                 models=mods,
661 |                             )
662 |                         except Exception as e:
    |                                ^^^^^^^^^
663 |                             res = self._create_specialist_error(stype, str(e))
664 |                         specialist_results[stype] = res
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/orchestration/orchestrator.py:719:16
    |
717 |                 "exploration_metrics": auction.metrics if auction else {},
718 |             }
719 |         except Exception as e:
    |                ^^^^^^^^^
720 |             logger.error(f"Parallel specialist analysis failed: {e}")
721 |             return self._create_error_response(str(e), request)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/orchestration/orchestrator.py:806:16
    |
804 |                 "exploration_metrics": auction.metrics if auction else {},
805 |             }
806 |         except Exception as e:
    |                ^^^^^^^^^
807 |             logger.error(f"Sequential specialist analysis failed: {e}")
808 |             return self._create_error_response(str(e), request)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/orchestration/orchestrator.py:849:16
    |
847 |                 "ollama", "llama3.2", prompt
848 |             )
849 |         except Exception as e:
    |                ^^^^^^^^^
850 |             logger.error(f"Synthesis failed: {e}")
851 |             return self._create_fallback_synthesis(results)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/orchestration/orchestrator.py:878:16
    |
876 |                 "ollama", "llama3.2", prompt
877 |             )
878 |         except Exception as e:
    |                ^^^^^^^^^
879 |             logger.error(f"Sequential synthesis failed: {e}")
880 |             return self._create_fallback_synthesis(list(results.values()))
    |

D102 Missing docstring in public method
   --> adaptivemind/orchestration/orchestrator.py:954:9
    |
952 |         }
953 |
954 |     def get_specialist_status(self) -> dict[str, Any]:
    |         ^^^^^^^^^^^^^^^^^^^^^
955 |         status = {
956 |             name: spec.get_specialization_info()
    |

D102 Missing docstring in public method
   --> adaptivemind/orchestration/orchestrator.py:968:15
    |
966 |         }
967 |
968 |     async def health_check_specialists(self) -> dict[str, Any]:
    |               ^^^^^^^^^^^^^^^^^^^^^^^^
969 |         health_results = {}
970 |         for name, _specialist in self.specialists.items():
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind/orchestration/orchestrator.py:979:20
    |
977 |                     "confidence": result.get("confidence", 0.0),
978 |                 }
979 |             except Exception as e:
    |                    ^^^^^^^^^
980 |                 health_results[name] = {"status": "error", "error": str(e)}
    |

D102 Missing docstring in public method
  --> adaptivemind/orchestration/path_memory.py:27:9
   |
25 |         self.records: list[Any] = []
26 |
27 |     def add_decisions(self, decisions: list[Any]) -> None:
   |         ^^^^^^^^^^^^^
28 |         if decisions:
29 |             self.decisions.extend(decisions)
   |

D102 Missing docstring in public method
  --> adaptivemind/orchestration/path_memory.py:31:9
   |
29 |             self.decisions.extend(decisions)
30 |
31 |     def add_step(self, step: Any) -> None:
   |         ^^^^^^^^
32 |         self.steps.append(step)
   |

D102 Missing docstring in public method
  --> adaptivemind/orchestration/path_memory.py:42:9
   |
40 |         return False, 0.0
41 |
42 |     def get_decisions(self) -> list[Any]:
   |         ^^^^^^^^^^^^^
43 |         return list(self.decisions)
   |

D102 Missing docstring in public method
  --> adaptivemind/orchestration/path_memory.py:45:9
   |
43 |         return list(self.decisions)
44 |
45 |     def get_steps(self) -> list[Any]:
   |         ^^^^^^^^^
46 |         return list(self.steps)
   |

D102 Missing docstring in public method
  --> adaptivemind/orchestration/path_memory.py:52:9
   |
50 |         self.records.append(score)
51 |
52 |     def get_records(self) -> list[Any]:
   |         ^^^^^^^^^^^
53 |         return list(self.records)
   |

D205 1 blank line required between summary line and description
  --> adaptivemind/orchestration/semantic_cache.py:17:5
   |
16 |   class SemanticCache:
17 | /     """A minimal in-memory semantic cache used during tests.
18 | |     Provides a get/set API for storing computed semantic entries.
19 | |     """
   | |_______^
20 |       def __init__(self):
21 |           self._cache: dict[str, Any] = {}
   |
help: Insert single blank line

D102 Missing docstring in public method
  --> adaptivemind/orchestration/semantic_cache.py:23:9
   |
21 |         self._cache: dict[str, Any] = {}
22 |
23 |     def get(self, key: str) -> Any:
   |         ^^^
24 |         return self._cache.get(key)
   |

D102 Missing docstring in public method
  --> adaptivemind/orchestration/semantic_cache.py:26:9
   |
24 |         return self._cache.get(key)
25 |
26 |     def set(self, key: str, value: Any) -> None:
   |         ^^^
27 |         self._cache[key] = value
   |

D103 Missing docstring in public function
  --> adaptivemind/security/secret_manager.py:17:5
   |
15 | _secrets_store: dict[str, Any] = {}
16 |
17 | def set_secret(key: str, value: str) -> bool:
   |     ^^^^^^^^^^
18 |     _secrets_store[key] = value
19 |     return True
   |

D103 Missing docstring in public function
  --> adaptivemind/security/secret_manager.py:21:5
   |
19 |     return True
20 |
21 | def get_secret(key: str, default: Any = None) -> Any:
   |     ^^^^^^^^^^
22 |     return _secrets_store.get(key, default)
   |

D101 Missing docstring in public class
  --> adaptivemind/workflows/engine.py:17:7
   |
17 | class WorkflowStatus(Enum):
   |       ^^^^^^^^^^^^^^
18 |     PENDING = "pending"
19 |     RUNNING = "running"
   |

D103 Missing docstring in public function
  --> adaptivemind/workflows/engine.py:24:5
   |
24 | def evaluate_workflow(dag: Any) -> dict[str, Any]:
   |     ^^^^^^^^^^^^^^^^^
25 |     return {"status": WorkflowStatus.PENDING}
   |

D101 Missing docstring in public class
  --> adaptivemind/world_model/neo4j_graph.py:16:7
   |
16 | class Neo4jGraph:
   |       ^^^^^^^^^^
17 |     def __init__(self, uri: str | None = None, user: str | None = None, password: str | None = None) -> None:
18 |         self.uri = uri
   |

E501 Line too long (109 > 88)
  --> adaptivemind/world_model/neo4j_graph.py:17:89
   |
16 | class Neo4jGraph:
17 |     def __init__(self, uri: str | None = None, user: str | None = None, password: str | None = None) -> None:
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^
18 |         self.uri = uri
19 |         self.user = user
   |

D102 Missing docstring in public method
  --> adaptivemind/world_model/neo4j_graph.py:23:9
   |
21 |         self.nodes = {}
22 |
23 |     def add_node(self, id: str, label: str, properties: dict[str, Any] | None = None) -> None:
   |         ^^^^^^^^
24 |         self.nodes[id] = {"label": label, "properties": properties or {}}
   |

E501 Line too long (94 > 88)
  --> adaptivemind/world_model/neo4j_graph.py:23:89
   |
21 |         self.nodes = {}
22 |
23 |     def add_node(self, id: str, label: str, properties: dict[str, Any] | None = None) -> None:
   |                                                                                         ^^^^^^
24 |         self.nodes[id] = {"label": label, "properties": properties or {}}
   |

D102 Missing docstring in public method
  --> adaptivemind/world_model/neo4j_graph.py:26:9
   |
24 |         self.nodes[id] = {"label": label, "properties": properties or {}}
25 |
26 |     def query(self, query: str):
   |         ^^^^^
27 |         return []
   |

E501 Line too long (89 > 88)
  --> adaptivemind_core/app.py:11:89
   |
11 | """Main AdaptiveMind Application module providing the core coordinator for AI operations.
   |                                                                                         ^
12 |
13 | This module contains the AdaptiveMindApplication class which serves as the main coordinator
   |

E501 Line too long (91 > 88)
  --> adaptivemind_core/app.py:13:89
   |
11 | """Main AdaptiveMind Application module providing the core coordinator for AI operations.
12 |
13 | This module contains the AdaptiveMindApplication class which serves as the main coordinator
   |                                                                                         ^^^
14 | that wires together configuration, routing, monitoring, and all backend services.
15 | It provides the high-level API for chat operations, persona management, and system
   |

E501 Line too long (92 > 88)
  --> adaptivemind_core/app.py:43:89
   |
41 |     """Main coordinator that wires configuration, routing, and monitoring.
42 |
43 |     The AdaptiveMindApplication class serves as the central coordinator for all AdaptiveMind
   |                                                                                         ^^^^
44 |     operations. It initializes and manages:
45 |     - Configuration management via AppConfig
   |

E501 Line too long (102 > 88)
   --> adaptivemind_core/app.py:166:89
    |
165 |         # Start the harvester thread with a descriptive name
166 |         self._harvester_thread = threading.Thread(target=_loop, name="metrics-harvester", daemon=True)
    |                                                                                         ^^^^^^^^^^^^^^
167 |         self._harvester_thread.start()
    |

E501 Line too long (151 > 88)
   --> adaptivemind_core/app.py:435:89
    |
433 | â€¦
434 | â€¦
435 | â€¦text_pipeline.extra_documents_dir) if self.config.context_pipeline.extra_documents_dir else None,
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
436 | â€¦ntext_pipeline.enable_semantic_chunking,
437 | â€¦.context_pipeline.max_combined_context_tokens,
    |

E501 Line too long (94 > 88)
   --> adaptivemind_core/app.py:436:89
    |
434 | â€¦     return {
435 | â€¦         "extra_documents_dir": str(self.config.context_pipeline.extra_documents_dir) if self.config.context_pipeline.extra_documentâ€¦
436 | â€¦         "enable_semantic_chunking": self.config.context_pipeline.enable_semantic_chunking,
    |                                                                                       ^^^^^^
437 | â€¦         "max_combined_context_tokens": self.config.context_pipeline.max_combined_context_tokens,
438 | â€¦     }
    |

E501 Line too long (100 > 88)
   --> adaptivemind_core/app.py:437:89
    |
435 | â€¦         "extra_documents_dir": str(self.config.context_pipeline.extra_documents_dir) if self.config.context_pipeline.extra_documentâ€¦
436 | â€¦         "enable_semantic_chunking": self.config.context_pipeline.enable_semantic_chunking,
437 | â€¦         "max_combined_context_tokens": self.config.context_pipeline.max_combined_context_tokens,
    |                                                                                       ^^^^^^^^^^^^
438 | â€¦     }
    |

E501 Line too long (99 > 88)
   --> adaptivemind_core/app.py:576:89
    |
574 |             self.config.allowed_personas = updates["allowed_personas"]
575 |
576 |         if "enable_adaptive_routing" in updates and updates["enable_adaptive_routing"] is not None:
    |                                                                                         ^^^^^^^^^^^
577 |             # For now, this is a placeholder - adaptive routing is always enabled
578 |             pass
    |

E501 Line too long (91 > 88)
   --> adaptivemind_core/app.py:600:89
    |
598 |         context_config = self.config.context_pipeline
599 |
600 |         if "extra_documents_dir" in updates and updates["extra_documents_dir"] is not None:
    |                                                                                         ^^^
601 |             from pathlib import Path
602 |             context_config.extra_documents_dir = Path(updates["extra_documents_dir"])
    |

E501 Line too long (101 > 88)
   --> adaptivemind_core/app.py:604:89
    |
602 |             context_config.extra_documents_dir = Path(updates["extra_documents_dir"])
603 |
604 |         if "enable_semantic_chunking" in updates and updates["enable_semantic_chunking"] is not None:
    |                                                                                         ^^^^^^^^^^^^^
605 |             context_config.enable_semantic_chunking = updates["enable_semantic_chunking"]
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/app.py:605:89
    |
604 |         if "enable_semantic_chunking" in updates and updates["enable_semantic_chunking"] is not None:
605 |             context_config.enable_semantic_chunking = updates["enable_semantic_chunking"]
    |                                                                                         ^
606 |
607 |         if "max_combined_context_tokens" in updates and updates["max_combined_context_tokens"] is not None:
    |

E501 Line too long (107 > 88)
   --> adaptivemind_core/app.py:607:89
    |
605 |             context_config.enable_semantic_chunking = updates["enable_semantic_chunking"]
606 |
607 |         if "max_combined_context_tokens" in updates and updates["max_combined_context_tokens"] is not None:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
608 |             context_config.max_combined_context_tokens = updates["max_combined_context_tokens"]
    |

E501 Line too long (95 > 88)
   --> adaptivemind_core/app.py:608:89
    |
607 |         if "max_combined_context_tokens" in updates and updates["max_combined_context_tokens"] is not None:
608 |             context_config.max_combined_context_tokens = updates["max_combined_context_tokens"]
    |                                                                                         ^^^^^^^
609 |
610 |         return self.get_context_config()
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/app.py:646:16
    |
644 |                 "error": None
645 |             }
646 |         except Exception as e:
    |                ^^^^^^^^^
647 |             latency = (time.time() - start_time) * 1000
648 |             return {
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/app.py:679:16
    |
677 |                 "message": "Configuration saved successfully (in-memory only for now)"
678 |             }
679 |         except Exception as e:
    |                ^^^^^^^^^
680 |             return {
681 |                 "success": False,
    |

FBT001 Boolean-typed positional argument in function definition
  --> adaptivemind_core/audit/cli.py:31:19
   |
31 | def setup_logging(verbose: bool = False) -> None:
   |                   ^^^^^^^
32 |     """Set up logging configuration."""
33 |     level = logging.DEBUG if verbose else logging.INFO
   |

FBT002 Boolean default positional argument in function definition
  --> adaptivemind_core/audit/cli.py:31:19
   |
31 | def setup_logging(verbose: bool = False) -> None:
   |                   ^^^^^^^
32 |     """Set up logging configuration."""
33 |     level = logging.DEBUG if verbose else logging.INFO
   |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/audit/cli.py:118:12
    |
116 |         return 0 if report.risk_score < 7.0 else 1
117 |
118 |     except Exception as e:
    |            ^^^^^^^^^
119 |         logging.error(f"Audit failed: {e}")
120 |         return 1
    |

E501 Line too long (113 > 88)
   --> adaptivemind_core/audit/cli.py:143:85
    |
142 |                 for severity, _count in severity_counts.items():
143 |                     {"CRITICAL": "ðŸš¨", "HIGH": "ðŸ”´", "MEDIUM": "ðŸŸ¡", "LOW": "ðŸŸ¢", "INFO": "â„¹ï¸"}.get(severity, "â€¢")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^
144 |
145 |     # Compliance status
    |

RUF001 String contains ambiguous `â„¹` (INFORMATION SOURCE). Did you mean `i` (LATIN SMALL LETTER I)?
   --> adaptivemind_core/audit/cli.py:143:88
    |
142 |                 for severity, _count in severity_counts.items():
143 |                     {"CRITICAL": "ðŸš¨", "HIGH": "ðŸ”´", "MEDIUM": "ðŸŸ¡", "LOW": "ðŸŸ¢", "INFO": "â„¹ï¸"}.get(severity, "â€¢")
    |                                                                                            ^
144 |
145 |     # Compliance status
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/audit/cli.py:196:12
    |
194 |         return 0
195 |
196 |     except Exception:
    |            ^^^^^^^^^
197 |         return 1
    |

E501 Line too long (97 > 88)
   --> adaptivemind_core/audit/cli.py:210:89
    |
208 |     """
209 |     parser = argparse.ArgumentParser(
210 |         description="AdaptiveMind AI Audit System - Comprehensive security and quality scanning",
    |                                                                                         ^^^^^^^^^
211 |         formatter_class=argparse.RawDescriptionHelpFormatter,
212 |         epilog="""
    |

E501 Line too long (93 > 88)
   --> adaptivemind_core/audit/cli.py:216:89
    |
214 |   %(prog)s scan /path/to/project                    # Basic audit scan
215 |   %(prog)s scan /path/to/project --output ./reports # Scan with output directory
216 |   %(prog)s scan . --scan-depth comprehensive        # Comprehensive scan of current directory
    |                                                                                         ^^^^^
217 |   %(prog)s scan . --include-tests                   # Include test files in scan
218 |   %(prog)s findings ./reports/audit_report_*.json   # List findings from saved report
    |

E501 Line too long (98 > 88)
   --> adaptivemind_core/audit/cli.py:229:89
    |
227 |     scan_parser.add_argument('target', help='Target directory or file to audit')
228 |     scan_parser.add_argument('-o', '--output', help='Output directory for reports')
229 |     scan_parser.add_argument('-d', '--scan-depth', choices=['basic', 'standard', 'comprehensive'],
    |                                                                                         ^^^^^^^^^^
230 |                            help='Scan depth level (default: standard)')
231 |     scan_parser.add_argument('-t', '--include-tests', action='store_true',
    |

E501 Line too long (111 > 88)
   --> adaptivemind_core/audit/cli.py:235:89
    |
233 |     scan_parser.add_argument('-e', '--exclude', action='append',
234 |                            help='Exclude pattern (can be used multiple times)')
235 |     scan_parser.add_argument('-s', '--standards', help='Comma-separated security standards (e.g., OWASP,NIST)')
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
236 |     scan_parser.add_argument('-v', '--verbose', action='store_true',
237 |                            help='Enable verbose logging')
    |

E501 Line too long (95 > 88)
   --> adaptivemind_core/audit/cli.py:240:89
    |
239 |     # Findings command
240 |     findings_parser = subparsers.add_parser('findings', help='List findings from saved report')
    |                                                                                         ^^^^^^^
241 |     findings_parser.add_argument('report_file', help='Path to audit report JSON file')
242 |     findings_parser.add_argument('-c', '--category', choices=['SECURITY', 'PERFORMANCE', 'CODE_QUALITY', 'DEPENDENCY', 'API_COMPLIANCâ€¦
    |

E501 Line too long (153 > 88)
   --> adaptivemind_core/audit/cli.py:242:89
    |
240 | â€¦ help='List findings from saved report')
241 | â€¦ath to audit report JSON file')
242 | â€¦oices=['SECURITY', 'PERFORMANCE', 'CODE_QUALITY', 'DEPENDENCY', 'API_COMPLIANCE', 'ARCHITECTURE'],
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
243 | â€¦ category')
    |

E501 Line too long (90 > 88)
  --> adaptivemind_core/audit/engine.py:64:89
   |
62 |         self._current_scan_id: str | None = None
63 |
64 |     def run_audit(self, target_path: Path, output_dir: Path | None = None) -> AuditReport:
   |                                                                                         ^^
65 |         """Run a comprehensive audit on the target directory.
   |

E501 Line too long (91 > 88)
   --> adaptivemind_core/audit/engine.py:129:89
    |
128 |             # Create summary
129 |             summary = self._generate_summary(total_findings, risk_score, compliance_status)
    |                                                                                         ^^^
130 |
131 |             # Create comprehensive report
    |

E501 Line too long (104 > 88)
   --> adaptivemind_core/audit/engine.py:148:89
    |
146 |                 self._save_report(report, output_dir)
147 |
148 |             self.logger.info(f"Audit completed. Found {total_findings} issues in {files_scanned} files")
    |                                                                                         ^^^^^^^^^^^^^^^^
149 |
150 |             return report
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> adaptivemind_core/audit/engine.py:197:9
    |
196 |           # Check if tests should be included
197 | /         if not self.config.include_tests:
198 | |             if 'test' in str(file_path).lower() or 'spec' in str(file_path).lower():
    | |____________________________________________________________________________________^
199 |                   return False
    |
help: Combine `if` statements using `and`

E501 Line too long (115 > 88)
   --> adaptivemind_core/audit/engine.py:203:89
    |
201 |         return True
202 |
203 |     def _group_findings_by_category(self, findings: list[AuditFinding]) -> dict[AuditCategory, list[AuditFinding]]:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
204 |         """Group findings by their category."""
205 |         grouped = {}
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/audit/engine.py:257:89
    |
256 |         # Group findings by severity
257 |         critical_findings = [f for f in findings if f.severity == SeverityLevel.CRITICAL]
    |                                                                                         ^
258 |         high_findings = [f for f in findings if f.severity == SeverityLevel.HIGH]
259 |         [f for f in findings if f.severity == SeverityLevel.MEDIUM]
    |

E501 Line too long (102 > 88)
   --> adaptivemind_core/audit/engine.py:263:89
    |
261 |         # Generate recommendations based on critical findings
262 |         if critical_findings:
263 |             security_critical = [f for f in critical_findings if f.category == AuditCategory.SECURITY]
    |                                                                                         ^^^^^^^^^^^^^^
264 |             if security_critical:
265 |                 recommendations.append("ðŸš¨ URGENT: Address all critical security vulnerabilities immediately")
    |

E501 Line too long (110 > 88)
   --> adaptivemind_core/audit/engine.py:265:88
    |
263 |             security_critical = [f for f in critical_findings if f.category == AuditCategory.SECURITY]
264 |             if security_critical:
265 |                 recommendations.append("ðŸš¨ URGENT: Address all critical security vulnerabilities immediately")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
266 |
267 |             performance_critical = [f for f in critical_findings if f.category == AuditCategory.PERFORMANCE]
    |

E501 Line too long (108 > 88)
   --> adaptivemind_core/audit/engine.py:267:89
    |
265 |                 recommendations.append("ðŸš¨ URGENT: Address all critical security vulnerabilities immediately")
266 |
267 |             performance_critical = [f for f in critical_findings if f.category == AuditCategory.PERFORMANCE]
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^
268 |             if performance_critical:
269 |                 recommendations.append("âš¡ CRITICAL: Optimize critical performance bottlenecks affecting system stability")
    |

E501 Line too long (123 > 88)
   --> adaptivemind_core/audit/engine.py:269:88
    |
267 |             performance_critical = [f for f in critical_findings if f.category == AuditCategory.PERFORMANCE]
268 |             if performance_critical:
269 |                 recommendations.append("âš¡ CRITICAL: Optimize critical performance bottlenecks affecting system stability")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
270 |
271 |         # Generate recommendations based on high findings
    |

E501 Line too long (112 > 88)
   --> adaptivemind_core/audit/engine.py:273:88
    |
271 |         # Generate recommendations based on high findings
272 |         if high_findings:
273 |             recommendations.append("ðŸ”’ HIGH: Review and address high-priority security and code quality issues")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^
274 |
275 |         # Generate category-specific recommendations
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/audit/engine.py:276:89
    |
275 |         # Generate category-specific recommendations
276 |         security_findings = [f for f in findings if f.category == AuditCategory.SECURITY]
    |                                                                                         ^
277 |         if security_findings:
278 |             recommendations.append("ðŸ›¡ï¸ SECURITY: Implement security best practices and fix vulnerabilities")
    |

E501 Line too long (107 > 88)
   --> adaptivemind_core/audit/engine.py:278:90
    |
276 |         security_findings = [f for f in findings if f.category == AuditCategory.SECURITY]
277 |         if security_findings:
278 |             recommendations.append("ðŸ›¡ï¸ SECURITY: Implement security best practices and fix vulnerabilities")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
279 |
280 |         code_quality_findings = [f for f in findings if f.category == AuditCategory.CODE_QUALITY]
    |

E501 Line too long (97 > 88)
   --> adaptivemind_core/audit/engine.py:280:89
    |
278 |             recommendations.append("ðŸ›¡ï¸ SECURITY: Implement security best practices and fix vulnerabilities")
279 |
280 |         code_quality_findings = [f for f in findings if f.category == AuditCategory.CODE_QUALITY]
    |                                                                                         ^^^^^^^^^
281 |         if code_quality_findings:
282 |             recommendations.append("ðŸ“ CODE QUALITY: Improve code maintainability and reduce technical debt")
    |

E501 Line too long (109 > 88)
   --> adaptivemind_core/audit/engine.py:282:88
    |
280 |         code_quality_findings = [f for f in findings if f.category == AuditCategory.CODE_QUALITY]
281 |         if code_quality_findings:
282 |             recommendations.append("ðŸ“ CODE QUALITY: Improve code maintainability and reduce technical debt")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^
283 |
284 |         dependency_findings = [f for f in findings if f.category == AuditCategory.DEPENDENCY]
    |

E501 Line too long (93 > 88)
   --> adaptivemind_core/audit/engine.py:284:89
    |
282 |             recommendations.append("ðŸ“ CODE QUALITY: Improve code maintainability and reduce technical debt")
283 |
284 |         dependency_findings = [f for f in findings if f.category == AuditCategory.DEPENDENCY]
    |                                                                                         ^^^^^
285 |         if dependency_findings:
286 |             recommendations.append("ðŸ“¦ DEPENDENCIES: Update vulnerable dependencies and review dependency management")
    |

E501 Line too long (118 > 88)
   --> adaptivemind_core/audit/engine.py:286:88
    |
284 |         dependency_findings = [f for f in findings if f.category == AuditCategory.DEPENDENCY]
285 |         if dependency_findings:
286 |             recommendations.append("ðŸ“¦ DEPENDENCIES: Update vulnerable dependencies and review dependency management")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
287 |
288 |         if not recommendations:
    |

E501 Line too long (111 > 88)
   --> adaptivemind_core/audit/engine.py:289:88
    |
288 |         if not recommendations:
289 |             recommendations.append("âœ… No critical issues found. Continue regular maintenance and monitoring.")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
290 |
291 |         return recommendations[:5]  # Limit to top 5 recommendations
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/audit/engine.py:305:89
    |
304 |         # OWASP compliance - check for OWASP Top 10 issues
305 |         owasp_violations = [f for f in findings if f.cwe_id and f.cwe_id.startswith('A')]
    |                                                                                         ^
306 |         compliance_status["OWASP"] = len(owasp_violations) == 0
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/audit/engine.py:311:89
    |
309 |         nist_violations = [f for f in findings
310 |                           if f.category == AuditCategory.SECURITY
311 |                           and f.severity in [SeverityLevel.CRITICAL, SeverityLevel.HIGH]]
    |                                                                                         ^
312 |         compliance_status["NIST"] = len(nist_violations) == 0
    |

E501 Line too long (94 > 88)
   --> adaptivemind_core/audit/engine.py:315:89
    |
314 |         # Code quality compliance
315 |         quality_violations = [f for f in findings if f.category == AuditCategory.CODE_QUALITY]
    |                                                                                         ^^^^^^
316 |         compliance_status["CODE_QUALITY"] = len(quality_violations) < 10  # Allow some quality issues
    |

E501 Line too long (101 > 88)
   --> adaptivemind_core/audit/engine.py:316:89
    |
314 |         # Code quality compliance
315 |         quality_violations = [f for f in findings if f.category == AuditCategory.CODE_QUALITY]
316 |         compliance_status["CODE_QUALITY"] = len(quality_violations) < 10  # Allow some quality issues
    |                                                                                         ^^^^^^^^^^^^^
317 |
318 |         # Performance compliance
    |

E501 Line too long (97 > 88)
   --> adaptivemind_core/audit/engine.py:319:89
    |
318 |         # Performance compliance
319 |         performance_violations = [f for f in findings if f.category == AuditCategory.PERFORMANCE]
    |                                                                                         ^^^^^^^^^
320 |         compliance_status["PERFORMANCE"] = len(performance_violations) < 5  # Allow some performance issues
    |

E501 Line too long (107 > 88)
   --> adaptivemind_core/audit/engine.py:320:89
    |
318 |         # Performance compliance
319 |         performance_violations = [f for f in findings if f.category == AuditCategory.PERFORMANCE]
320 |         compliance_status["PERFORMANCE"] = len(performance_violations) < 5  # Allow some performance issues
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
321 |
322 |         return compliance_status
    |

E501 Line too long (115 > 88)
   --> adaptivemind_core/audit/engine.py:324:89
    |
322 |         return compliance_status
323 |
324 |     def _generate_summary(self, total_findings: int, risk_score: float, compliance_status: dict[str, bool]) -> str:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
325 |         """Generate executive summary of the audit.
    |

E501 Line too long (98 > 88)
   --> adaptivemind_core/audit/engine.py:339:88
    |
337 |         # Overall assessment
338 |         if risk_score >= 7.0:
339 |             summary_parts.append("ðŸš¨ HIGH RISK: Significant security and quality issues detected")
    |                                                                                         ^^^^^^^^^^
340 |         elif risk_score >= 4.0:
341 |             summary_parts.append("âš ï¸ MODERATE RISK: Some security and quality improvements needed")
    |

E501 Line too long (98 > 88)
   --> adaptivemind_core/audit/engine.py:341:90
    |
339 |             summary_parts.append("ðŸš¨ HIGH RISK: Significant security and quality issues detected")
340 |         elif risk_score >= 4.0:
341 |             summary_parts.append("âš ï¸ MODERATE RISK: Some security and quality improvements needed")
    |                                                                                         ^^^^^^^^^^
342 |         else:
343 |             summary_parts.append("âœ… LOW RISK: Generally good security and code quality")
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/audit/engine.py:343:88
    |
341 |             summary_parts.append("âš ï¸ MODERATE RISK: Some security and quality improvements needed")
342 |         else:
343 |             summary_parts.append("âœ… LOW RISK: Generally good security and code quality")
    |                                                                                         ^
344 |
345 |         # Findings summary
    |

E501 Line too long (98 > 88)
   --> adaptivemind_core/audit/engine.py:351:89
    |
349 |         passed_standards = sum(1 for status in compliance_status.values() if status)
350 |         total_standards = len(compliance_status)
351 |         summary_parts.append(f"Compliance: {passed_standards}/{total_standards} standards passed")
    |                                                                                         ^^^^^^^^^^
352 |
353 |         # Key recommendations
    |

E501 Line too long (94 > 88)
   --> adaptivemind_core/audit/engine.py:354:89
    |
353 |         # Key recommendations
354 |         critical_compliance = [std for std, status in compliance_status.items() if not status]
    |                                                                                         ^^^^^^
355 |         if critical_compliance:
356 |             summary_parts.append(f"Focus areas: {', '.join(critical_compliance)} compliance")
    |

E501 Line too long (93 > 88)
   --> adaptivemind_core/audit/engine.py:356:89
    |
354 |         critical_compliance = [std for std, status in compliance_status.items() if not status]
355 |         if critical_compliance:
356 |             summary_parts.append(f"Focus areas: {', '.join(critical_compliance)} compliance")
    |                                                                                         ^^^^^
357 |
358 |         return " ".join(summary_parts)
    |

E501 Line too long (91 > 88)
  --> adaptivemind_core/audit/models.py:79:89
   |
77 |     description: str = Field(..., description="Detailed analysis and context")
78 |     file_path: str = Field(..., description="Path to the file containing the issue")
79 |     line_number: int | None = Field(None, description="Specific line number if applicable")
   |                                                                                         ^^^
80 |     remediation: str = Field(..., description="Recommended fix or remediation steps")
81 |     cwe_id: str | None = Field(None, description="CWE ID if security related")
   |

E501 Line too long (96 > 88)
  --> adaptivemind_core/audit/models.py:82:89
   |
80 |     remediation: str = Field(..., description="Recommended fix or remediation steps")
81 |     cwe_id: str | None = Field(None, description="CWE ID if security related")
82 |     cvss_score: float | None = Field(None, description="CVSS score (0.0-10.0)", ge=0.0, le=10.0)
   |                                                                                         ^^^^^^^^
83 |     timestamp: datetime = Field(default_factory=datetime.now, description="When finding was detected")
84 |     metadata: dict[str, Any] = Field(default_factory=dict, description="Additional metadata")
   |

E501 Line too long (102 > 88)
  --> adaptivemind_core/audit/models.py:83:89
   |
81 |     cwe_id: str | None = Field(None, description="CWE ID if security related")
82 |     cvss_score: float | None = Field(None, description="CVSS score (0.0-10.0)", ge=0.0, le=10.0)
83 |     timestamp: datetime = Field(default_factory=datetime.now, description="When finding was detected")
   |                                                                                         ^^^^^^^^^^^^^^
84 |     metadata: dict[str, Any] = Field(default_factory=dict, description="Additional metadata")
   |

E501 Line too long (93 > 88)
  --> adaptivemind_core/audit/models.py:84:89
   |
82 |     cvss_score: float | None = Field(None, description="CVSS score (0.0-10.0)", ge=0.0, le=10.0)
83 |     timestamp: datetime = Field(default_factory=datetime.now, description="When finding was detected")
84 |     metadata: dict[str, Any] = Field(default_factory=dict, description="Additional metadata")
   |                                                                                         ^^^^^
85 |
86 |     class Config:
   |

D106 Missing docstring in public nested class
  --> adaptivemind_core/audit/models.py:86:11
   |
84 |     metadata: dict[str, Any] = Field(default_factory=dict, description="Additional metadata")
85 |
86 |     class Config:
   |           ^^^^^^
87 |         use_enum_values = True
   |

E501 Line too long (105 > 88)
   --> adaptivemind_core/audit/models.py:106:89
    |
104 |     """
105 |     report_id: str = Field(..., description="Unique identifier for the report")
106 |     scan_timestamp: datetime = Field(default_factory=datetime.now, description="When scan was performed")
    |                                                                                         ^^^^^^^^^^^^^^^^^
107 |     scan_duration: float = Field(..., description="Duration of scan in seconds")
108 |     total_files_scanned: int = Field(..., description="Number of files analyzed")
    |

E501 Line too long (96 > 88)
   --> adaptivemind_core/audit/models.py:113:89
    |
111 |         default_factory=dict, description="Findings grouped by category"
112 |     )
113 |     risk_score: float = Field(..., description="Overall risk score (0.0-10.0)", ge=0.0, le=10.0)
    |                                                                                         ^^^^^^^^
114 |     compliance_status: dict[str, bool] = Field(
115 |         default_factory=dict, description="Compliance status for various standards"
    |

E501 Line too long (100 > 88)
   --> adaptivemind_core/audit/models.py:135:89
    |
133 |         custom_rules: Custom audit rules and configurations
134 |     """
135 |     scan_depth: ScanDepth = Field(default=ScanDepth.STANDARD, description="Level of scanning depth")
    |                                                                                         ^^^^^^^^^^^^
136 |     include_tests: bool = Field(default=False, description="Whether to include test files")
137 |     exclude_patterns: list[str] = Field(
    |

E501 Line too long (91 > 88)
   --> adaptivemind_core/audit/models.py:136:89
    |
134 |     """
135 |     scan_depth: ScanDepth = Field(default=ScanDepth.STANDARD, description="Level of scanning depth")
136 |     include_tests: bool = Field(default=False, description="Whether to include test files")
    |                                                                                         ^^^
137 |     exclude_patterns: list[str] = Field(
138 |         default_factory=lambda: [
    |

E501 Line too long (92 > 88)
   --> adaptivemind_core/audit/models.py:144:89
    |
142 |     )
143 |     security_standards: list[str] = Field(
144 |         default_factory=lambda: ["OWASP", "NIST"], description="Security standards to check"
    |                                                                                         ^^^^
145 |     )
146 |     performance_thresholds: dict[str, float] = Field(
    |

E501 Line too long (94 > 88)
   --> adaptivemind_core/audit/models.py:154:89
    |
152 |     )
153 |     code_quality_rules: list[str] = Field(
154 |         default_factory=lambda: ["flake8", "pylint", "mypy"], description="Code quality rules"
    |                                                                                         ^^^^^^
155 |     )
156 |     custom_rules: dict[str, Any] = Field(
    |

D106 Missing docstring in public nested class
   --> adaptivemind_core/audit/models.py:160:11
    |
158 |     )
159 |
160 |     class Config:
    |           ^^^^^^
161 |         use_enum_values = True
    |

BLE001 Do not catch blind exception: `Exception`
  --> adaptivemind_core/audit/scanner.py:73:16
   |
71 |             with open(file_path, encoding='utf-8') as f:
72 |                 return f.read()
73 |         except Exception as e:
   |                ^^^^^^^^^
74 |             self.logger.warning(f"Could not read {file_path}: {e}")
75 |             return None
   |

S607 Starting a process with a partial executable path
   --> adaptivemind_core/audit/scanner.py:181:21
    |
179 |                 # Run bandit
180 |                 result = subprocess.run(
181 |                     ["bandit", "-r", str(temp_path), "-f", "json"],
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
182 |                     capture_output=True,
183 |                     text=True,
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/audit/scanner.py:198:16
    |
196 |         except subprocess.TimeoutExpired:
197 |             self.logger.warning("Bandit scan timed out")
198 |         except Exception as e:
    |                ^^^^^^^^^
199 |             self.logger.debug(f"Bandit scan failed: {e}")
    |

E501 Line too long (100 > 88)
   --> adaptivemind_core/audit/scanner.py:220:89
    |
218 |             }
219 |
220 |             severity = severity_map.get(issue.get("issue_severity", "MEDIUM"), SeverityLevel.MEDIUM)
    |                                                                                         ^^^^^^^^^^^^
221 |
222 |             # Get CWE ID if available
    |

E501 Line too long (104 > 88)
   --> adaptivemind_core/audit/scanner.py:243:89
    |
241 |                 file_path=Path(issue.get("filename", "unknown")),
242 |                 line_number=issue.get("line_number"),
243 |                 remediation="Review and fix security vulnerability according to bandit recommendations",
    |                                                                                         ^^^^^^^^^^^^^^^^
244 |                 cwe_id=cwe_id,
245 |                 cvss_score=cvss_score,
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/audit/scanner.py:252:16
    |
250 |                 }
251 |             )
252 |         except Exception as e:
    |                ^^^^^^^^^
253 |             self.logger.debug(f"Failed to convert bandit finding: {e}")
254 |             return None
    |

E501 Line too long (91 > 88)
   --> adaptivemind_core/audit/scanner.py:256:89
    |
254 |             return None
255 |
256 |     def _scan_security_patterns(self, file_path: Path, content: str) -> list[AuditFinding]:
    |                                                                                         ^^^
257 |         """Scan for security patterns using regex patterns.
    |

E501 Line too long (90 > 88)
   --> adaptivemind_core/audit/scanner.py:271:89
    |
269 |         patterns = {
270 |             "hardcoded_secrets": {
271 |                 "pattern": r"(?i)(password|secret|key|token)\s*=\s*['\"][^'\"]{10,}['\"]",
    |                                                                                         ^^
272 |                 "severity": SeverityLevel.HIGH,
273 |                 "title": "Hardcoded Secret Detected",
    |

E501 Line too long (93 > 88)
   --> adaptivemind_core/audit/scanner.py:274:89
    |
272 |                 "severity": SeverityLevel.HIGH,
273 |                 "title": "Hardcoded Secret Detected",
274 |                 "description": "Potential hardcoded secret or password found in source code",
    |                                                                                         ^^^^^
275 |                 "remediation": "Move secrets to environment variables or secure configuration",
276 |                 "cwe_id": "CWE-798"
    |

E501 Line too long (95 > 88)
   --> adaptivemind_core/audit/scanner.py:275:89
    |
273 |                 "title": "Hardcoded Secret Detected",
274 |                 "description": "Potential hardcoded secret or password found in source code",
275 |                 "remediation": "Move secrets to environment variables or secure configuration",
    |                                                                                         ^^^^^^^
276 |                 "cwe_id": "CWE-798"
277 |             },
    |

E501 Line too long (111 > 88)
   --> adaptivemind_core/audit/scanner.py:282:89
    |
280 |                 "severity": SeverityLevel.HIGH,
281 |                 "title": "Potential SQL Injection",
282 |                 "description": "SQL query construction using string formatting may be vulnerable to injection",
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
283 |                 "remediation": "Use parameterized queries or ORM methods",
284 |                 "cwe_id": "CWE-89"
    |

E501 Line too long (99 > 88)
   --> adaptivemind_core/audit/scanner.py:290:89
    |
288 |                 "severity": SeverityLevel.HIGH,
289 |                 "title": "Use of eval() Function",
290 |                 "description": "Use of eval() function can lead to code injection vulnerabilities",
    |                                                                                         ^^^^^^^^^^^
291 |                 "remediation": "Avoid eval() or use ast.literal_eval() for safe evaluation",
292 |                 "cwe_id": "CWE-94"
    |

E501 Line too long (92 > 88)
   --> adaptivemind_core/audit/scanner.py:291:89
    |
289 |                 "title": "Use of eval() Function",
290 |                 "description": "Use of eval() function can lead to code injection vulnerabilities",
291 |                 "remediation": "Avoid eval() or use ast.literal_eval() for safe evaluation",
    |                                                                                         ^^^^
292 |                 "cwe_id": "CWE-94"
293 |             },
    |

E501 Line too long (96 > 88)
   --> adaptivemind_core/audit/scanner.py:298:89
    |
296 |                 "severity": SeverityLevel.MEDIUM,
297 |                 "title": "Insecure subprocess call",
298 |                 "description": "Use of shell=True in subprocess can be vulnerable to injection",
    |                                                                                         ^^^^^^^^
299 |                 "remediation": "Avoid shell=True or properly validate and sanitize inputs",
300 |                 "cwe_id": "CWE-78"
    |

E501 Line too long (91 > 88)
   --> adaptivemind_core/audit/scanner.py:299:89
    |
297 |                 "title": "Insecure subprocess call",
298 |                 "description": "Use of shell=True in subprocess can be vulnerable to injection",
299 |                 "remediation": "Avoid shell=True or properly validate and sanitize inputs",
    |                                                                                         ^^^
300 |                 "cwe_id": "CWE-78"
301 |             }
    |

E501 Line too long (104 > 88)
   --> adaptivemind_core/audit/scanner.py:319:89
    |
317 |                             remediation=pattern_config["remediation"],
318 |                             cwe_id=pattern_config["cwe_id"],
319 |                             cvss_score=7.5 if pattern_config["severity"] == SeverityLevel.HIGH else 5.0,
    |                                                                                         ^^^^^^^^^^^^^^^^
320 |                             metadata={"pattern_type": pattern_name}
321 |                         )
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/audit/scanner.py:358:89
    |
356 |         return findings
357 |
358 |     def _analyze_file_quality(self, file_path: Path, content: str) -> list[AuditFinding]:
    |                                                                                         ^
359 |         """Analyze a single file for quality issues.
    |

E501 Line too long (90 > 88)
   --> adaptivemind_core/audit/scanner.py:381:89
    |
379 |                 file_path=file_path,
380 |                 line_number=line_num,
381 |                 remediation="Break long lines into multiple lines for better readability",
    |                                                                                         ^^
382 |                 metadata={"line_length": len(line)}
383 |             )
    |

E501 Line too long (105 > 88)
   --> adaptivemind_core/audit/scanner.py:393:89
    |
391 |                 severity=SeverityLevel.MEDIUM if complexity > 15 else SeverityLevel.LOW,
392 |                 title="High cyclomatic complexity",
393 |                 description=f"Cyclomatic complexity of {complexity} exceeds recommended threshold of 10",
    |                                                                                         ^^^^^^^^^^^^^^^^^
394 |                 file_path=file_path,
395 |                 remediation="Refactor complex functions into smaller, more manageable pieces",
    |

E501 Line too long (94 > 88)
   --> adaptivemind_core/audit/scanner.py:395:89
    |
393 |                 description=f"Cyclomatic complexity of {complexity} exceeds recommended threshold of 10",
394 |                 file_path=file_path,
395 |                 remediation="Refactor complex functions into smaller, more manageable pieces",
    |                                                                                         ^^^^^^
396 |                 metadata={"complexity": complexity}
397 |             )
    |

E501 Line too long (92 > 88)
   --> adaptivemind_core/audit/scanner.py:408:89
    |
406 |                     severity=SeverityLevel.INFO,
407 |                     title="Technical debt marker",
408 |                     description=f"Found '{line.strip()}' comment indicating technical debt",
    |                                                                                         ^^^^
409 |                     file_path=file_path,
410 |                     line_number=line_num,
    |

E501 Line too long (104 > 88)
   --> adaptivemind_core/audit/scanner.py:411:89
    |
409 |                     file_path=file_path,
410 |                     line_number=line_num,
411 |                     remediation="Address the TODO/FIXME item or remove the comment if no longer needed",
    |                                                                                         ^^^^^^^^^^^^^^^^
412 |                     metadata={"comment_type": "technical_debt"}
413 |                 )
    |

E501 Line too long (100 > 88)
   --> adaptivemind_core/audit/scanner.py:426:89
    |
424 |                 file_path=file_path,
425 |                 line_number=line_num,
426 |                 remediation="Replace magic numbers with named constants for better maintainability",
    |                                                                                         ^^^^^^^^^^^^
427 |                 metadata={"magic_numbers": numbers}
428 |             )
    |

E501 Line too long (104 > 88)
   --> adaptivemind_core/audit/scanner.py:448:89
    |
446 |             for node in ast.walk(tree):
447 |                 # Count decision points
448 |                 if isinstance(node, (ast.If, ast.While, ast.For, ast.With, ast.Try, ast.ExceptHandler)):
    |                                                                                         ^^^^^^^^^^^^^^^^
449 |                     complexity += 1
450 |                 elif isinstance(node, ast.BoolOp):
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/audit/scanner.py:456:16
    |
455 |             return complexity
456 |         except Exception:
    |                ^^^^^^^^^
457 |             return 1
    |

E501 Line too long (99 > 88)
   --> adaptivemind_core/audit/scanner.py:482:89
    |
480 |                 try:
481 |                     num = int(num_str)
482 |                     if num not in allowed_numbers and num > 9:  # Consider > 9 as potentially magic
    |                                                                                         ^^^^^^^^^^^
483 |                         magic_nums.append(num)
484 |                 except ValueError:
    |

S607 Starting a process with a partial executable path
   --> adaptivemind_core/audit/scanner.py:533:17
    |
531 |         try:
532 |             result = subprocess.run(
533 |                 ["safety", "check", "--json"],
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
534 |                 capture_output=True,
535 |                 text=True,
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/audit/scanner.py:550:16
    |
548 |         except subprocess.TimeoutExpired:
549 |             self.logger.warning("Safety scan timed out")
550 |         except Exception as e:
    |                ^^^^^^^^^
551 |             self.logger.debug(f"Safety scan failed: {e}")
    |

E501 Line too long (112 > 88)
   --> adaptivemind_core/audit/scanner.py:580:89
    |
578 |                 severity=severity,
579 |                 title=f"Vulnerable dependency: {vuln.get('package_name', 'unknown')}",
580 |                 description=vuln.get("advisory", {}).get("description", "Security vulnerability in dependency"),
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^
581 |                 file_path=Path("requirements.txt"),  # Generic location
582 |                 remediation="Update the vulnerable dependency to the latest secure version",
    |

E501 Line too long (92 > 88)
   --> adaptivemind_core/audit/scanner.py:582:89
    |
580 |                 description=vuln.get("advisory", {}).get("description", "Security vulnerability in dependency"),
581 |                 file_path=Path("requirements.txt"),  # Generic location
582 |                 remediation="Update the vulnerable dependency to the latest secure version",
    |                                                                                         ^^^^
583 |                 metadata={
584 |                     "tool": "safety",
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/audit/scanner.py:590:16
    |
588 |                 }
589 |             )
590 |         except Exception as e:
    |                ^^^^^^^^^
591 |             self.logger.debug(f"Failed to convert safety finding: {e}")
592 |             return None
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/audit/scanner.py:594:89
    |
592 |             return None
593 |
594 |     def _scan_dependency_file(self, file_path: Path, content: str) -> list[AuditFinding]:
    |                                                                                         ^
595 |         """Scan dependency file for issues.
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> adaptivemind_core/audit/scanner.py:611:17
    |
609 |               for line_num, line in enumerate(lines, 1):
610 |                   line = line.strip()
611 | /                 if line and not line.startswith('#'):
612 | |                     # Check if version is pinned
613 | |                     if '==' not in line and '>=' not in line and '~=' not in line:
    | |__________________________________________________________________________________^
614 |                           finding = self._create_finding(
615 |                               category=AuditCategory.DEPENDENCY,
    |
help: Combine `if` statements using `and`

E501 Line too long (101 > 88)
   --> adaptivemind_core/audit/scanner.py:618:89
    |
616 | â€¦                     severity=SeverityLevel.LOW,
617 | â€¦                     title="Unpinned dependency version",
618 | â€¦                     description=f"Dependency '{line}' does not specify a version constraint",
    |                                                                                   ^^^^^^^^^^^^^
619 | â€¦                     file_path=file_path,
620 | â€¦                     line_number=line_num,
    |

E501 Line too long (96 > 88)
   --> adaptivemind_core/audit/scanner.py:621:89
    |
619 |                             file_path=file_path,
620 |                             line_number=line_num,
621 |                             remediation="Pin dependency versions to ensure reproducible builds",
    |                                                                                         ^^^^^^^^
622 |                             metadata={"dependency": line}
623 |                         )
    |

E501 Line too long (100 > 88)
  --> adaptivemind_core/config.py:50:89
   |
48 |         enable_ui: Whether to expose the Ollama chat UI
49 |     """
50 |     host: str = Field("http://127.0.0.1:11434", description="Base URL for the local Ollama service")
   |                                                                                         ^^^^^^^^^^^^
51 |     model: str = Field("llama3", description="Default Ollama model identifier")
52 |     timeout: float = Field(30.0, ge=1.0, description="Request timeout in seconds")
   |

FBT003 Boolean positional value in function call
  --> adaptivemind_core/config.py:53:29
   |
51 |     model: str = Field("llama3", description="Default Ollama model identifier")
52 |     timeout: float = Field(30.0, ge=1.0, description="Request timeout in seconds")
53 |     enable_ui: bool = Field(True, description="Expose the Ollama chat UI")
   |                             ^^^^
   |

E501 Line too long (95 > 88)
  --> adaptivemind_core/config.py:71:89
   |
69 |     model: str = Field("openai/gpt-3.5-turbo", description="Default OpenRouter model")
70 |     site_url: str = Field("", description="Site URL for OpenRouter rankings")
71 |     app_name: str = Field("AdaptiveMind Local", description="App name for OpenRouter rankings")
   |                                                                                         ^^^^^^^
   |

FBT003 Boolean positional value in function call
  --> adaptivemind_core/config.py:85:27
   |
83 |         device_preference: Preferred execution provider (cpu, dml)
84 |     """
85 |     enabled: bool = Field(False, description="Enable WindowsML fallback acceleration")
   |                           ^^^^^
86 |     model_path: Path | None = Field(
87 |         default=None, description="Path to an ONNX model consumable by WindowsML/ONNX Runtime"
   |

E501 Line too long (94 > 88)
  --> adaptivemind_core/config.py:87:89
   |
85 |     enabled: bool = Field(False, description="Enable WindowsML fallback acceleration")
86 |     model_path: Path | None = Field(
87 |         default=None, description="Path to an ONNX model consumable by WindowsML/ONNX Runtime"
   |                                                                                         ^^^^^^
88 |     )
89 |     device_preference: str = Field(
   |

E501 Line too long (110 > 88)
  --> adaptivemind_core/config.py:91:89
   |
89 |     device_preference: str = Field(
90 |         "cpu",
91 |         description="Preferred execution provider (cpu, dml). cpu is always available, dml requires DirectML",
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
92 |     )
   |

E501 Line too long (107 > 88)
   --> adaptivemind_core/config.py:113:89
    |
111 |         audit_log_path: Optional path to persist security audit logs
112 |     """
113 |     api_keys: list[str] = Field(default_factory=list, description="Static API keys allowed for API access")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
114 |     audit_log_path: Path | None = Field(default=None, description="Optional path to persist security audit logs")
    |

E501 Line too long (113 > 88)
   --> adaptivemind_core/config.py:114:89
    |
112 |     """
113 |     api_keys: list[str] = Field(default_factory=list, description="Static API keys allowed for API access")
114 |     audit_log_path: Path | None = Field(default=None, description="Optional path to persist security audit logs")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^
115 |
116 |     @field_validator("api_keys", mode="before")
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/config.py:165:89
    |
163 |     system_prompt: str
164 |     max_context_window: int = Field(4096, ge=512)
165 |     routing_hint: str = Field("general", description="Hint used by the routing pipeline")
    |                                                                                         ^
    |

E501 Line too long (101 > 88)
   --> adaptivemind_core/config.py:180:89
    |
178 |     """
179 |     extra_documents_dir: Path | None = Field(
180 |         default=None, description="Optional directory of additional documents to inject into context"
    |                                                                                         ^^^^^^^^^^^^^
181 |     )
182 |     enable_semantic_chunking: bool = Field(True, description="Split documents into semantic chunks")
    |

FBT003 Boolean positional value in function call
   --> adaptivemind_core/config.py:182:44
    |
180 |         default=None, description="Optional directory of additional documents to inject into context"
181 |     )
182 |     enable_semantic_chunking: bool = Field(True, description="Split documents into semantic chunks")
    |                                            ^^^^
183 |     max_combined_context_tokens: int = Field(8192, ge=1024)
    |

E501 Line too long (100 > 88)
   --> adaptivemind_core/config.py:182:89
    |
180 |         default=None, description="Optional directory of additional documents to inject into context"
181 |     )
182 |     enable_semantic_chunking: bool = Field(True, description="Split documents into semantic chunks")
    |                                                                                         ^^^^^^^^^^^^
183 |     max_combined_context_tokens: int = Field(8192, ge=1024)
    |

FBT003 Boolean positional value in function call
   --> adaptivemind_core/config.py:204:42
    |
202 |         harvest_interval_s: Interval in seconds between metric harvests
203 |     """
204 |     enable_metrics_harvest: bool = Field(True, description="Enable harvesting of metrics and traces")
    |                                          ^^^^
205 |     harvest_interval_s: float = Field(30.0, ge=5.0)
    |

E501 Line too long (101 > 88)
   --> adaptivemind_core/config.py:204:89
    |
202 |         harvest_interval_s: Interval in seconds between metric harvests
203 |     """
204 |     enable_metrics_harvest: bool = Field(True, description="Enable harvesting of metrics and traces")
    |                                                                                         ^^^^^^^^^^^^^
205 |     harvest_interval_s: float = Field(30.0, ge=5.0)
    |

E501 Line too long (125 > 88)
   --> adaptivemind_core/config.py:221:89
    |
219 |         description="Balanced assistant persona",
220 |         system_prompt=(
221 |             "You are AdaptiveMind, a local-first research assistant. Provide concise, factual answers and highlight sources."
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
222 |         ),
223 |         max_context_window=4096,
    |

E501 Line too long (90 > 88)
   --> adaptivemind_core/config.py:250:89
    |
248 |     security: SecurityConfig = Field(default_factory=SecurityConfig)
249 |     personas: dict[str, PersonaConfig] = Field(default_factory=_default_personas)
250 |     context_pipeline: ContextPipelineConfig = Field(default_factory=ContextPipelineConfig)
    |                                                                                         ^^
251 |     monitoring: MonitoringConfig = Field(default_factory=MonitoringConfig)
252 |     allowed_personas: list[str] = Field(default_factory=list)
    |

FBT003 Boolean positional value in function call
   --> adaptivemind_core/config.py:253:44
    |
251 |     monitoring: MonitoringConfig = Field(default_factory=MonitoringConfig)
252 |     allowed_personas: list[str] = Field(default_factory=list)
253 |     enable_research_features: bool = Field(True, description="Enable deep research workflows")
    |                                            ^^^^
254 |
255 |     @field_validator("allowed_personas", mode="after")
    |

E501 Line too long (94 > 88)
   --> adaptivemind_core/config.py:253:89
    |
251 |     monitoring: MonitoringConfig = Field(default_factory=MonitoringConfig)
252 |     allowed_personas: list[str] = Field(default_factory=list)
253 |     enable_research_features: bool = Field(True, description="Enable deep research workflows")
    |                                                                                         ^^^^^^
254 |
255 |     @field_validator("allowed_personas", mode="after")
    |

E501 Line too long (99 > 88)
   --> adaptivemind_core/config.py:257:89
    |
255 |     @field_validator("allowed_personas", mode="after")
256 |     @classmethod
257 |     def _default_allowed_personas(cls, value: list[str] | None, info: ValidationInfo) -> list[str]:
    |                                                                                         ^^^^^^^^^^^
258 |         """Set default allowed personas from configured personas if not explicitly set.
    |

E501 Line too long (91 > 88)
   --> adaptivemind_core/config.py:352:89
    |
350 |     Configuration loading priority (highest to lowest):
351 |     1. Explicit file path (if provided)
352 |     2. Environment variable files (ADAPTIVEMIND_CONFIG, ADAPTIVEMIND_HOME, ~/.adaptivemind)
    |                                                                                         ^^^
353 |     3. Environment variable overrides
354 |     4. Default values from AppConfig model
    |

E501 Line too long (112 > 88)
   --> adaptivemind_core/config.py:394:89
    |
392 |         env_overrides.setdefault("openrouter", {})["api_key"] = or_key
393 |     if keys := os.getenv("ADAPTIVEMIND_API_KEYS"):
394 |         env_overrides.setdefault("security", {})["api_keys"] = [k.strip() for k in keys.split(",") if k.strip()]
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^
395 |     if persona := os.getenv("ADAPTIVEMIND_DEFAULT_PERSONA"):
396 |         env_overrides["allowed_personas"] = [persona]
    |

D101 Missing docstring in public class
  --> adaptivemind_core/context/engine.py:25:7
   |
24 | @dataclass
25 | class ContextSection:
   |       ^^^^^^^^^^^^^^
26 |     title: str
27 |     body: str
   |

D102 Missing docstring in public method
  --> adaptivemind_core/context/engine.py:29:9
   |
27 |     body: str
28 |
29 |     def token_length(self) -> int:
   |         ^^^^^^^^^^^^
30 |         return max(1, len(self.body.split()))
   |

D102 Missing docstring in public method
  --> adaptivemind_core/context/engine.py:39:9
   |
37 |         self._config = config
38 |
39 |     def build_context(self, persona: PersonaConfig, messages: Sequence[dict], external_context: Iterable[str] | None = None) -> str:
   |         ^^^^^^^^^^^^^
40 |         sections: list[ContextSection] = [
41 |             ContextSection("Persona", persona.system_prompt),
   |

E501 Line too long (132 > 88)
  --> adaptivemind_core/context/engine.py:39:89
   |
37 |         self._config = config
38 |
39 |     def build_context(self, persona: PersonaConfig, messages: Sequence[dict], external_context: Iterable[str] | None = None) -> str:
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
40 |         sections: list[ContextSection] = [
41 |             ContextSection("Persona", persona.system_prompt),
   |

E501 Line too long (92 > 88)
  --> adaptivemind_core/context/engine.py:74:89
   |
72 |                     content = handle.read().strip()
73 |             except OSError:
74 |                 logger.warning("Failed to read context document", extra={"path": str(path)})
   |                                                                                         ^^^^
75 |                 continue
76 |             sections.append(ContextSection(title=f"Doc:{path.stem}", body=self._sanitize(content)))
   |

E501 Line too long (99 > 88)
  --> adaptivemind_core/context/engine.py:76:89
   |
74 |                 logger.warning("Failed to read context document", extra={"path": str(path)})
75 |                 continue
76 |             sections.append(ContextSection(title=f"Doc:{path.stem}", body=self._sanitize(content)))
   |                                                                                         ^^^^^^^^^^^
77 |         return sections
   |

E501 Line too long (101 > 88)
  --> adaptivemind_core/context/engine.py:79:89
   |
77 |         return sections
78 |
79 |     def _truncate(self, sections: Sequence[ContextSection], max_tokens: int) -> list[ContextSection]:
   |                                                                                         ^^^^^^^^^^^^^
80 |         result: list[ContextSection] = []
81 |         running_total = 0
   |

E501 Line too long (124 > 88)
  --> adaptivemind_core/context/engine.py:86:89
   |
84 |             if running_total + tokens > max_tokens:
85 |                 logger.debug(
86 |                     "Context truncated", extra={"section": section.title, "running_total": running_total, "max": max_tokens}
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
87 |                 )
88 |                 break
   |

D101 Missing docstring in public class
  --> adaptivemind_core/extensions/templates.py:18:7
   |
18 | class ExtensionHook(Protocol):
   |       ^^^^^^^^^^^^^
19 |     def __call__(self, *args, **kwargs): ...
   |

D102 Missing docstring in public method
  --> adaptivemind_core/extensions/templates.py:19:9
   |
18 | class ExtensionHook(Protocol):
19 |     def __call__(self, *args, **kwargs): ...
   |         ^^^^^^^^
   |

D101 Missing docstring in public class
  --> adaptivemind_core/llm/base.py:19:7
   |
18 | @dataclass
19 | class GenerationRequest:
   |       ^^^^^^^^^^^^^^^^^
20 |     messages: Sequence[dict]
21 |     persona: str
   |

D101 Missing docstring in public class
  --> adaptivemind_core/llm/base.py:29:7
   |
28 | @dataclass
29 | class GenerationResponse:
   |       ^^^^^^^^^^^^^^^^^^
30 |     content: str
31 |     tokens: int
   |

D101 Missing docstring in public class
  --> adaptivemind_core/llm/base.py:37:7
   |
36 | @dataclass
37 | class GenerationChunk:
   |       ^^^^^^^^^^^^^^^
38 |     content: str  # Incremental content (e.g., a token or partial text)
39 |     tokens: int  # Cumulative tokens generated so far
   |

D101 Missing docstring in public class
  --> adaptivemind_core/llm/base.py:45:7
   |
45 | class LLMBackend(Protocol):
   |       ^^^^^^^^^^
46 |     name: str
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/base.py:48:9
   |
46 |     name: str
47 |
48 |     def is_available(self) -> bool:
   |         ^^^^^^^^^^^^
49 |         ...
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/base.py:51:9
   |
49 |         ...
50 |
51 |     def generate(self, request: GenerationRequest) -> GenerationResponse:
   |         ^^^^^^^^
52 |         ...
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/base.py:54:9
   |
52 |         ...
53 |
54 |     def stream(self, request: GenerationRequest) -> Iterator[GenerationChunk]:
   |         ^^^^^^
55 |         ...
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/fallback.py:25:9
   |
23 |     name = "contextual-fallback"
24 |
25 |     def is_available(self) -> bool:
   |         ^^^^^^^^^^^^
26 |         return True
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/fallback.py:28:9
   |
26 |         return True
27 |
28 |     def generate(self, request: GenerationRequest) -> GenerationResponse:
   |         ^^^^^^^^
29 |         last_user_message = next((msg["content"] for msg in reversed(request.messages) if msg.get("role") == "user"), "")
30 |         persona_summary = request.context.split("\n", 1)[0]
   |

E501 Line too long (121 > 88)
  --> adaptivemind_core/llm/fallback.py:29:89
   |
28 |     def generate(self, request: GenerationRequest) -> GenerationResponse:
29 |         last_user_message = next((msg["content"] for msg in reversed(request.messages) if msg.get("role") == "user"), "")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
30 |         persona_summary = request.context.split("\n", 1)[0]
31 |         token_estimate = len(request.context.split())
   |

E501 Line too long (116 > 88)
  --> adaptivemind_core/llm/fallback.py:38:89
   |
36 |             Most recent user request: {last_user_message}
37 |             Key context terms: {', '.join(keywords)}
38 |             Response: Based on the available local context, here is a structured summary and recommended next steps.
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
39 |             - Context Window Size: {token_estimate} tokens (approx.)
40 |             - Suggested Actions: Verify facts, consult linked research snippets, and prepare citations before responding.
   |

E501 Line too long (121 > 88)
  --> adaptivemind_core/llm/fallback.py:40:89
   |
38 |             Response: Based on the available local context, here is a structured summary and recommended next steps.
39 |             - Context Window Size: {token_estimate} tokens (approx.)
40 |             - Suggested Actions: Verify facts, consult linked research snippets, and prepare citations before responding.
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
41 |             - Safety: Ensure API usage complies with configured policies and redact sensitive data.
42 |             """
   |

E501 Line too long (99 > 88)
  --> adaptivemind_core/llm/fallback.py:41:89
   |
39 |             - Context Window Size: {token_estimate} tokens (approx.)
40 |             - Suggested Actions: Verify facts, consult linked research snippets, and prepare citations before responding.
41 |             - Safety: Ensure API usage complies with configured policies and redact sensitive data.
   |                                                                                         ^^^^^^^^^^^
42 |             """
43 |         ).strip()
   |

E501 Line too long (116 > 88)
  --> adaptivemind_core/llm/fallback.py:44:89
   |
42 |             """
43 |         ).strip()
44 |         return GenerationResponse(content=content, tokens=len(content.split()), backend=self.name, diagnostics=None)
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
45 |
46 |     def _top_keywords(self, context: str, limit: int = 5) -> Sequence[str]:
   |

BLE001 Do not catch blind exception: `Exception`
  --> adaptivemind_core/llm/ollama.py:48:16
   |
46 |             self._health_cache = len(models) > 0  # At least one model available
47 |             self._models_cache = list(models)
48 |         except Exception:
   |                ^^^^^^^^^
49 |             self._health_cache = False
50 |             self._models_cache = []
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/ollama.py:61:9
   |
59 |         return self._models_cache.copy()
60 |
61 |     def generate(self, request: GenerationRequest) -> GenerationResponse:
   |         ^^^^^^^^
62 |         payload: dict[str, object] = {
63 |             "model": self._model,
   |

E501 Line too long (114 > 88)
  --> adaptivemind_core/llm/ollama.py:84:89
   |
82 |             "total_duration": str(data.get("total_duration")),
83 |         }
84 |         return GenerationResponse(content=message, tokens=int(tokens), backend=self.name, diagnostics=diagnostics)
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
85 |
86 |     def stream(self, request: GenerationRequest) -> Iterator[GenerationChunk]:
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/ollama.py:86:9
   |
84 |         return GenerationResponse(content=message, tokens=int(tokens), backend=self.name, diagnostics=diagnostics)
85 |
86 |     def stream(self, request: GenerationRequest) -> Iterator[GenerationChunk]:
   |         ^^^^^^
87 |         payload: dict[str, object] = {
88 |             "model": self._model,
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/ollama_old.py:34:9
   |
32 |         self._health_cache: bool = False
33 |
34 |     def is_available(self) -> bool:
   |         ^^^^^^^^^^^^
35 |         now = time.time()
36 |         if now - self._last_health_check < 10:
   |

BLE001 Do not catch blind exception: `Exception`
  --> adaptivemind_core/llm/ollama_old.py:44:16
   |
42 |             models = {entry.get("name") for entry in data.get("models", [])}
43 |             self._health_cache = self._model in models
44 |         except Exception:
   |                ^^^^^^^^^
45 |             self._health_cache = False
46 |         self._last_health_check = now
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/ollama_old.py:49:9
   |
47 |         return self._health_cache
48 |
49 |     def generate(self, request: GenerationRequest) -> GenerationResponse:
   |         ^^^^^^^^
50 |         payload: dict[str, object] = {
51 |             "model": self._model,
   |

E501 Line too long (114 > 88)
  --> adaptivemind_core/llm/ollama_old.py:72:89
   |
70 |             "total_duration": str(data.get("total_duration")),
71 |         }
72 |         return GenerationResponse(content=message, tokens=int(tokens), backend=self.name, diagnostics=diagnostics)
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
73 |
74 |     def stream(self, request: GenerationRequest) -> Iterator[GenerationChunk]:
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/ollama_old.py:74:9
   |
72 |         return GenerationResponse(content=message, tokens=int(tokens), backend=self.name, diagnostics=diagnostics)
73 |
74 |     def stream(self, request: GenerationRequest) -> Iterator[GenerationChunk]:
   |         ^^^^^^
75 |         payload: dict[str, object] = {
76 |             "model": self._model,
   |

E501 Line too long (132 > 88)
  --> adaptivemind_core/llm/openrouter.py:24:89
   |
22 |     """Backend for OpenRouter API (Cloud Agent)."""
23 |
24 |     def __init__(self, api_key: str, model: str = "openai/gpt-3.5-turbo", site_url: str = "", app_name: str = "AdaptiveMind Local"):
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
25 |         self.name = "openrouter"
26 |         self.api_key = api_key
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/openrouter.py:32:9
   |
30 |         self._base_url = "https://openrouter.ai/api/v1"
31 |
32 |     def is_available(self) -> bool:
   |         ^^^^^^^^^^^^
33 |         return bool(self.api_key)
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/openrouter.py:35:9
   |
33 |         return bool(self.api_key)
34 |
35 |     def generate(self, request: GenerationRequest) -> GenerationResponse:
   |         ^^^^^^^^
36 |         headers = {
37 |             "Authorization": f"Bearer {self.api_key}",
   |

E501 Line too long (109 > 88)
  --> adaptivemind_core/llm/openrouter.py:46:89
   |
44 |         messages = []
45 |         # If context is provided, prepend it to the system prompt or first user message
46 |         system_content = f"You are acting as the '{request.persona}' persona.\n\nContext:\n{request.context}"
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^
47 |         messages.append({"role": "system", "content": system_content})
   |

E501 Line too long (97 > 88)
  --> adaptivemind_core/llm/openrouter.py:51:89
   |
49 |         # Append conversation history
50 |         for msg in request.messages:
51 |             messages.append({"role": msg.get("role", "user"), "content": msg.get("content", "")})
   |                                                                                         ^^^^^^^^^
52 |
53 |         payload = {
   |

E501 Line too long (97 > 88)
  --> adaptivemind_core/llm/openrouter.py:83:89
   |
81 |             logger.error("OpenRouter generation failed", extra={"error": str(e)})
82 |             # Return a fallback response or re-raise depending on strategy
83 |             # For now, we return an error message as content to be handled by the router fallback
   |                                                                                         ^^^^^^^^^
84 |             raise e
   |

BLE001 Do not catch blind exception: `Exception`
  --> adaptivemind_core/llm/windowsml.py:18:8
   |
16 | try:
17 |     import onnxruntime as ort
18 | except Exception:  # pragma: no cover - optional dependency
   |        ^^^^^^^^^
19 |     ort = None
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/windowsml.py:39:9
   |
37 |         self._session: ort.InferenceSession | None = None
38 |
39 |     def is_available(self) -> bool:
   |         ^^^^^^^^^^^^
40 |         if ort is None:
41 |             return False
   |

BLE001 Do not catch blind exception: `Exception`
  --> adaptivemind_core/llm/windowsml.py:49:16
   |
47 |             self._ensure_session()
48 |             return True
49 |         except Exception:
   |                ^^^^^^^^^
50 |             return False
   |

D102 Missing docstring in public method
  --> adaptivemind_core/llm/windowsml.py:61:9
   |
59 |         return self._session
60 |
61 |     def generate(self, request: GenerationRequest) -> GenerationResponse:
   |         ^^^^^^^^
62 |         session = self._ensure_session()
63 |         prompt = request.context.encode("utf-8")
   |

E501 Line too long (109 > 88)
  --> adaptivemind_core/llm/windowsml.py:73:89
   |
71 |         tokens = len(content.split())
72 |         diagnostics = {"provider": ",".join(session.get_providers())}
73 |         return GenerationResponse(content=content, tokens=tokens, backend=self.name, diagnostics=diagnostics)
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^
   |

E501 Line too long (90 > 88)
  --> adaptivemind_core/logger.py:39:89
   |
39 | def configure_logging(log_level: str | int = "INFO", log_path: str | None = None) -> None:
   |                                                                                         ^^
40 |     """Configure central structured logging for the AdaptiveMind runtime.
   |

E501 Line too long (98 > 88)
  --> adaptivemind_core/logger.py:43:89
   |
42 |     Sets up JSON-formatted logging with both console and optional file handlers.
43 |     Uses environment variables ADAPTIVEMIND_LOG_LEVEL and ADAPTIVEMIND_LOG_PATH for configuration.
   |                                                                                         ^^^^^^^^^^
44 |     Implements singleton pattern to prevent multiple configurations.
   |

E501 Line too long (91 > 88)
   --> adaptivemind_core/logger.py:106:89
    |
104 |     """JSON formatter for structured logging with trace-friendly fields.
105 |
106 |     Formats log records as JSON objects with standard fields (level, logger, message, time)
    |                                                                                         ^^^
107 |     plus any extra fields provided via the 'extra' parameter. Exception information
108 |     is included when present. Designed for easy parsing by log aggregation systems.
    |

E501 Line too long (91 > 88)
   --> adaptivemind_core/logger.py:139:89
    |
137 |         # Extract and include extra fields that aren't part of standard LogRecord
138 |         # This allows structured logging with custom context data
139 |         standard_attrs = set(logging.LogRecord("", 0, "", 0, "", (), None).__dict__.keys())
    |                                                                                         ^^^
140 |         for key, value in record.__dict__.items():
141 |             if key not in standard_attrs and key not in data:
    |

E501 Line too long (106 > 88)
   --> adaptivemind_core/logger.py:165:89
    |
163 |     """
164 |     if not _LOGGER_CONFIGURED:
165 |         configure_logging(os.getenv("ADAPTIVEMIND_LOG_LEVEL", "INFO"), os.getenv("ADAPTIVEMIND_LOG_PATH"))
    |                                                                                         ^^^^^^^^^^^^^^^^^^
166 |     return logging.getLogger(name)
    |

D101 Missing docstring in public class
  --> adaptivemind_core/minimal_server.py:31:7
   |
30 | # Request/Response Models
31 | class ChatRequest(BaseModel):
   |       ^^^^^^^^^^^
32 |     messages: list[dict]
33 |     persona: str = "generalist"
   |

D101 Missing docstring in public class
  --> adaptivemind_core/minimal_server.py:37:7
   |
35 |     max_tokens: int = 512
36 |
37 | class ChatResponse(BaseModel):
   |       ^^^^^^^^^^^^
38 |     content: str
39 |     model: str
   |

E501 Line too long (121 > 88)
  --> adaptivemind_core/minimal_server.py:74:89
   |
72 |                 raise HTTPException(
73 |                     status_code=status.HTTP_400_BAD_REQUEST,
74 |                     detail=f"Persona '{request.persona}' not found. Available: {list(jarvis_app.config.personas.keys())}"
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
75 |                 )
   |

BLE001 Do not catch blind exception: `Exception`
  --> adaptivemind_core/minimal_server.py:87:16
   |
85 |             return ChatResponse(**payload)
86 |
87 |         except Exception as e:
   |                ^^^^^^^^^
88 |             raise HTTPException(
89 |                 status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
   |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
  --> adaptivemind_core/minimal_server.py:88:13
   |
87 |           except Exception as e:
88 | /             raise HTTPException(
89 | |                 status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
90 | |                 detail=f"Chat request failed: {e!s}"
91 | |             )
   | |_____________^
92 |
93 |       return app
   |

E501 Line too long (91 > 88)
   --> adaptivemind_core/minimal_server.py:133:89
    |
131 |         }
132 |         .status.ok { background: rgba(40, 167, 69, 0.2); border: 1px solid #28a745; }
133 |         .status.degraded { background: rgba(255, 193, 7, 0.2); border: 1px solid #ffc107; }
    |                                                                                         ^^^
134 |         textarea {
135 |             width: 100%;
    |

E501 Line too long (110 > 88)
   --> adaptivemind_core/minimal_server.py:199:89
    |
197 |                 const data = await response.json();
198 |                 const statusEl = document.getElementById('status');
199 |                 statusEl.textContent = `Status: ${data.status} | Models: ${data.available_models.join(', ')}`;
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
200 |                 statusEl.className = `status ${data.status}`;
201 |             } catch (error) {
    |

E501 Line too long (117 > 88)
   --> adaptivemind_core/minimal_server.py:241:88
    |
240 |                 const data = await response.json();
241 |                 output.textContent = data.content + '\\n\\nðŸ“Š Tokens: ' + data.tokens + ' | ðŸ¤– Model: ' + data.model;
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
242 |
243 |             } catch (error) {
    |

D102 Missing docstring in public method
  --> adaptivemind_core/routing/router.py:48:9
   |
46 |         self._traces = traces
47 |
48 |     def available_personas(self) -> dict[str, PersonaConfig]:
   |         ^^^^^^^^^^^^^^^^^^
49 |         return self._config.personas
   |

D102 Missing docstring in public method
  --> adaptivemind_core/routing/router.py:51:9
   |
49 |         return self._config.personas
50 |
51 |     def select_backend(self, persona: PersonaConfig) -> LLMBackend:
   |         ^^^^^^^^^^^^^^
52 |         for backend in self._backends:
53 |             if backend.is_available():
   |

E501 Line too long (106 > 88)
  --> adaptivemind_core/routing/router.py:54:89
   |
52 |         for backend in self._backends:
53 |             if backend.is_available():
54 |                 logger.debug("Selected backend", extra={"persona": persona.name, "backend": backend.name})
   |                                                                                         ^^^^^^^^^^^^^^^^^^
55 |                 return backend
56 |         logger.warning("Falling back to contextual generator", extra={"persona": persona.name})
   |

E501 Line too long (95 > 88)
  --> adaptivemind_core/routing/router.py:56:89
   |
54 |                 logger.debug("Selected backend", extra={"persona": persona.name, "backend": backend.name})
55 |                 return backend
56 |         logger.warning("Falling back to contextual generator", extra={"persona": persona.name})
   |                                                                                         ^^^^^^^
57 |         return self._backends[-1]
   |

D102 Missing docstring in public method
  --> adaptivemind_core/routing/router.py:59:9
   |
57 |         return self._backends[-1]
58 |
59 |     def generate(
   |         ^^^^^^^^
60 |         self,
61 |         persona_name: str,
   |

BLE001 Do not catch blind exception: `Exception`
  --> adaptivemind_core/routing/router.py:71:16
   |
69 |         try:
70 |             allowed = set(self._config.allowed_personas)
71 |         except Exception:
   |                ^^^^^^^^^
72 |             # If allowed_personas is not iterable (e.g., a Mock in tests),
73 |             # fall back to the declared personas in the config.
   |

E501 Line too long (89 > 88)
  --> adaptivemind_core/routing/router.py:79:89
   |
77 |             raise ValueError(f"Persona '{persona_name}' is not enabled")
78 |         persona = self._config.personas[persona_name]
79 |         context = self._context_engine.build_context(persona, messages, external_context)
   |                                                                                         ^
80 |         backend = self.select_backend(persona)
81 |         request = GenerationRequest(
   |

E501 Line too long (146 > 88)
  --> adaptivemind_core/routing/router.py:93:89
   |
91 | â€¦* 1000
92 | â€¦
93 | â€¦a.name, latency_ms=latency_ms, generated_tokens=response.tokens, context_tokens=context_tokens)
   |                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
94 | â€¦
95 | â€¦
   |

D102 Missing docstring in public method
   --> adaptivemind_core/routing/router.py:117:9
    |
115 |         return response
116 |
117 |     def stream(
    |         ^^^^^^
118 |         self,
119 |         persona_name: str,
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/routing/router.py:129:16
    |
127 |         try:
128 |             allowed = set(self._config.allowed_personas)
129 |         except Exception:
    |                ^^^^^^^^^
130 |             allowed = set(self._config.personas.keys())
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/routing/router.py:135:89
    |
133 |             raise ValueError(f"Persona '{persona_name}' is not enabled")
134 |         persona = self._config.personas[persona_name]
135 |         context = self._context_engine.build_context(persona, messages, external_context)
    |                                                                                         ^
136 |         backend = self.select_backend(persona)
137 |         request = GenerationRequest(
    |

SIM113 Use `enumerate()` for index variable `chunk_count` in `for` loop
   --> adaptivemind_core/routing/router.py:148:13
    |
146 |         chunk_count = 0
147 |         for chunk in backend.stream(request):
148 |             chunk_count += 1
    |             ^^^^^^^^^^^^^^^^
149 |             yield chunk
150 |             if chunk.finished:
    |

E501 Line too long (151 > 88)
   --> adaptivemind_core/routing/router.py:153:89
    |
151 | â€¦art) * 1000
152 | â€¦
153 | â€¦ersona.name, latency_ms=latency_ms, generated_tokens=chunk.tokens, context_tokens=context_tokens)
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
154 | â€¦
155 | â€¦
    |

D102 Missing docstring in public method
  --> adaptivemind_core/routing/router_fixed.py:54:9
   |
52 |         self._traces = traces
53 |
54 |     def available_personas(self) -> dict[str, PersonaConfig]:
   |         ^^^^^^^^^^^^^^^^^^
55 |         return self._config.personas
   |

D102 Missing docstring in public method
  --> adaptivemind_core/routing/router_fixed.py:57:9
   |
55 |         return self._config.personas
56 |
57 |     def select_backend(self, persona: PersonaConfig) -> LLMBackend:
   |         ^^^^^^^^^^^^^^
58 |         for backend in self._backends:
59 |             if backend.is_available():
   |

E501 Line too long (106 > 88)
  --> adaptivemind_core/routing/router_fixed.py:60:89
   |
58 |         for backend in self._backends:
59 |             if backend.is_available():
60 |                 logger.debug("Selected backend", extra={"persona": persona.name, "backend": backend.name})
   |                                                                                         ^^^^^^^^^^^^^^^^^^
61 |                 return backend
62 |         logger.warning("Falling back to contextual generator", extra={"persona": persona.name})
   |

E501 Line too long (95 > 88)
  --> adaptivemind_core/routing/router_fixed.py:62:89
   |
60 |                 logger.debug("Selected backend", extra={"persona": persona.name, "backend": backend.name})
61 |                 return backend
62 |         logger.warning("Falling back to contextual generator", extra={"persona": persona.name})
   |                                                                                         ^^^^^^^
63 |         return self._backends[-1]
   |

D102 Missing docstring in public method
  --> adaptivemind_core/routing/router_fixed.py:65:9
   |
63 |         return self._backends[-1]
64 |
65 |     def generate(
   |         ^^^^^^^^
66 |         self,
67 |         persona_name: str,
   |

E501 Line too long (95 > 88)
  --> adaptivemind_core/routing/router_fixed.py:79:89
   |
78 |         # Check allowed_personas only if it's explicitly set (not empty)
79 |         if self._config.allowed_personas and persona_name not in self._config.allowed_personas:
   |                                                                                         ^^^^^^^
80 |             raise ValueError(f"Persona '{persona_name}' is not enabled")
   |

E501 Line too long (89 > 88)
  --> adaptivemind_core/routing/router_fixed.py:83:89
   |
82 |         persona = self._config.personas[persona_name]
83 |         context = self._context_engine.build_context(persona, messages, external_context)
   |                                                                                         ^
84 |         backend = self.select_backend(persona)
85 |         request = GenerationRequest(
   |

E501 Line too long (146 > 88)
  --> adaptivemind_core/routing/router_fixed.py:97:89
   |
95 | â€¦* 1000
96 | â€¦
97 | â€¦a.name, latency_ms=latency_ms, generated_tokens=response.tokens, context_tokens=context_tokens)
   |                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
98 | â€¦
99 | â€¦
   |

D102 Missing docstring in public method
   --> adaptivemind_core/routing/router_fixed.py:121:9
    |
119 |         return response
120 |
121 |     def stream(
    |         ^^^^^^
122 |         self,
123 |         persona_name: str,
    |

E501 Line too long (95 > 88)
   --> adaptivemind_core/routing/router_fixed.py:135:89
    |
134 |         # Check allowed_personas only if it's explicitly set (not empty)
135 |         if self._config.allowed_personas and persona_name not in self._config.allowed_personas:
    |                                                                                         ^^^^^^^
136 |             raise ValueError(f"Persona '{persona_name}' is not enabled")
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/routing/router_fixed.py:139:89
    |
138 |         persona = self._config.personas[persona_name]
139 |         context = self._context_engine.build_context(persona, messages, external_context)
    |                                                                                         ^
140 |         backend = self.select_backend(persona)
141 |         request = GenerationRequest(
    |

SIM113 Use `enumerate()` for index variable `chunk_count` in `for` loop
   --> adaptivemind_core/routing/router_fixed.py:152:13
    |
150 |         chunk_count = 0
151 |         for chunk in backend.stream(request):
152 |             chunk_count += 1
    |             ^^^^^^^^^^^^^^^^
153 |             yield chunk
154 |             if chunk.finished:
    |

E501 Line too long (151 > 88)
   --> adaptivemind_core/routing/router_fixed.py:157:89
    |
155 | â€¦art) * 1000
156 | â€¦
157 | â€¦ersona.name, latency_ms=latency_ms, generated_tokens=chunk.tokens, context_tokens=context_tokens)
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
158 | â€¦
159 | â€¦
    |

D103 Missing docstring in public function
   --> adaptivemind_core/server.py:192:5
    |
192 | def build_app(config: AppConfig | None = None) -> FastAPI:
    |     ^^^^^^^^^
193 |     # Allow tests and external code to patch the legacy `jarvis_core.server`
194 |     # AdaptiveMindApplication symbol; resolve dynamically so that mocking
    |

N806 Variable `AppClass` in function should be lowercase
   --> adaptivemind_core/server.py:199:9
    |
197 |         import importlib
198 |         legacy = importlib.import_module("jarvis_core.server")
199 |         AppClass = getattr(legacy, "AdaptiveMindApplication", AdaptiveMindApplication)
    |         ^^^^^^^^
200 |     except Exception:
201 |         AppClass = AdaptiveMindApplication
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:200:12
    |
198 |         legacy = importlib.import_module("jarvis_core.server")
199 |         AppClass = getattr(legacy, "AdaptiveMindApplication", AdaptiveMindApplication)
200 |     except Exception:
    |            ^^^^^^^^^
201 |         AppClass = AdaptiveMindApplication
    |

N806 Variable `AppClass` in function should be lowercase
   --> adaptivemind_core/server.py:201:9
    |
199 |         AppClass = getattr(legacy, "AdaptiveMindApplication", AdaptiveMindApplication)
200 |     except Exception:
201 |         AppClass = AdaptiveMindApplication
    |         ^^^^^^^^
202 |
203 |     jarvis_app = AppClass(config=config)
    |

E501 Line too long (99 > 88)
   --> adaptivemind_core/server.py:212:89
    |
210 |             jarvis_app.shutdown()
211 |
212 |     fastapi_app = FastAPI(title="AdaptiveMind Local Assistant", version="1.0.0", lifespan=lifespan)
    |                                                                                         ^^^^^^^^^^^
213 |
214 |     # Compatibility: Normalize middleware entries for Starlette/FastAPI versions
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> adaptivemind_core/server.py:225:5
    |
223 |                   normalized.append((cls, options))
224 |           fastapi_app.user_middleware = normalized
225 | /     except Exception:
226 | |         pass
    | |____________^
227 |
228 |       # Ensure FastAPI.build_middleware_stack accepts different starlette Middleware shapes
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:225:12
    |
223 |                 normalized.append((cls, options))
224 |         fastapi_app.user_middleware = normalized
225 |     except Exception:
    |            ^^^^^^^^^
226 |         pass
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/server.py:228:89
    |
226 |         pass
227 |
228 |     # Ensure FastAPI.build_middleware_stack accepts different starlette Middleware shapes
    |                                                                                         ^
229 |     try:
230 |         # Use safe imports so the compatibility wrapper doesn't fail due to missing
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:237:16
    |
235 |                 ServerErrorMiddleware,
236 |             )
237 |         except Exception:
    |                ^^^^^^^^^
238 |             ServerErrorMiddleware = None
239 |             ExceptionMiddleware = None
    |

N806 Variable `ServerErrorMiddleware` in function should be lowercase
   --> adaptivemind_core/server.py:238:13
    |
236 |             )
237 |         except Exception:
238 |             ServerErrorMiddleware = None
    |             ^^^^^^^^^^^^^^^^^^^^^
239 |             ExceptionMiddleware = None
240 |         try:
    |

N806 Variable `ExceptionMiddleware` in function should be lowercase
   --> adaptivemind_core/server.py:239:13
    |
237 |         except Exception:
238 |             ServerErrorMiddleware = None
239 |             ExceptionMiddleware = None
    |             ^^^^^^^^^^^^^^^^^^^
240 |         try:
241 |             from fastapi.middleware.asyncexitstack import (
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:244:16
    |
242 |                 AsyncExitStackMiddleware,  # type: ignore
243 |             )
244 |         except Exception:
    |                ^^^^^^^^^
245 |             AsyncExitStackMiddleware = None
    |

N806 Variable `AsyncExitStackMiddleware` in function should be lowercase
   --> adaptivemind_core/server.py:245:13
    |
243 |             )
244 |         except Exception:
245 |             AsyncExitStackMiddleware = None
    |             ^^^^^^^^^^^^^^^^^^^^^^^^
246 |
247 |         # Provide a minimal ExceptionMiddleware fallback (if missing in starlette).
    |

E501 Line too long (106 > 88)
   --> adaptivemind_core/server.py:250:89
    |
248 |         # This is only enabled during tests when requested via environment
249 |         # (ADAPTIVEMIND_TEST_MODE=true).
250 |         if ExceptionMiddleware is None and os.getenv("ADAPTIVEMIND_TEST_MODE", "false").lower() == "true":
    |                                                                                         ^^^^^^^^^^^^^^^^^^
251 |             from fastapi import HTTPException as FastAPIHTTPException
252 |             from starlette.responses import JSONResponse
    |

FBT001 Boolean-typed positional argument in function definition
   --> adaptivemind_core/server.py:255:56
    |
254 |             class ExceptionMiddleware:  # type: ignore
255 |                 def __init__(self, app, handlers=None, debug: bool = False):
    |                                                        ^^^^^
256 |                     self.app = app
257 |                     self.handlers = handlers or {}
    |

FBT002 Boolean default positional argument in function definition
   --> adaptivemind_core/server.py:255:56
    |
254 |             class ExceptionMiddleware:  # type: ignore
255 |                 def __init__(self, app, handlers=None, debug: bool = False):
    |                                                        ^^^^^
256 |                     self.app = app
257 |                     self.handlers = handlers or {}
    |

E501 Line too long (96 > 88)
   --> adaptivemind_core/server.py:264:89
    |
262 |                         await self.app(scope, receive, send)
263 |                     except FastAPIHTTPException as exc:
264 |                         resp = JSONResponse({"detail": exc.detail}, status_code=exc.status_code)
    |                                                                                         ^^^^^^^^
265 |                         await resp(scope, receive, send)
266 |                     except Exception:
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/server.py:279:89
    |
278 |             debug = self.debug
279 |             # Build a list of normalized middleware entries as tuples (cls, args, kwargs)
    |                                                                                         ^
280 |             middleware_raw = []
281 |             if ServerErrorMiddleware is not None:
    |

E501 Line too long (110 > 88)
   --> adaptivemind_core/server.py:282:89
    |
280 |             middleware_raw = []
281 |             if ServerErrorMiddleware is not None:
282 |                 middleware_raw.append((ServerErrorMiddleware, (), {'handler': error_handler, 'debug': debug}))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
283 |             # Extend with any user middleware (already normalized to 2- or 3-tuples)
284 |             middleware_raw += list(self.user_middleware)
    |

E501 Line too long (114 > 88)
   --> adaptivemind_core/server.py:286:89
    |
284 |             middleware_raw += list(self.user_middleware)
285 |             if ExceptionMiddleware is not None:
286 |                 middleware_raw.append((ExceptionMiddleware, (), {'handlers': exception_handlers, 'debug': debug}))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
287 |             if AsyncExitStackMiddleware is not None:
288 |                 middleware_raw.append((AsyncExitStackMiddleware, (), {}))
    |

B026 Star-arg unpacking after a keyword argument is strongly discouraged
   --> adaptivemind_core/server.py:314:44
    |
312 |                 if cls is None:
313 |                     continue
314 |                 app_obj = cls(app=app_obj, *args, **(options or {}))
    |                                            ^^^^^
315 |             return app_obj
    |

E501 Line too long (105 > 88)
   --> adaptivemind_core/server.py:318:89
    |
317 |         import types
318 |         fastapi_app.build_middleware_stack = types.MethodType(build_middleware_stack_compat, fastapi_app)
    |                                                                                         ^^^^^^^^^^^^^^^^^
319 |     except Exception:
320 |         pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> adaptivemind_core/server.py:319:5
    |
317 |           import types
318 |           fastapi_app.build_middleware_stack = types.MethodType(build_middleware_stack_compat, fastapi_app)
319 | /     except Exception:
320 | |         pass
    | |____________^
321 |
322 |       def _verify_api_key(request: Request) -> None:
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:319:12
    |
317 |         import types
318 |         fastapi_app.build_middleware_stack = types.MethodType(build_middleware_stack_compat, fastapi_app)
319 |     except Exception:
    |            ^^^^^^^^^
320 |         pass
    |

E501 Line too long (99 > 88)
   --> adaptivemind_core/server.py:329:89
    |
327 |         provided = header_key or query_key
328 |         if not provided or provided not in jarvis_app.config.security.api_keys:
329 |             raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="Invalid API key")
    |                                                                                         ^^^^^^^^^^^
330 |
331 |     def _app_dependency(request: Request) -> AdaptiveMindApplication:
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:336:47
    |
335 |     @fastapi_app.get("/health", response_model=HealthResponse)
336 |     def health(app: AdaptiveMindApplication = Depends(_app_dependency)) -> HealthResponse:
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^
337 |         models = app.models()
338 |         status_value = "ok" if models else "degraded"
    |

E501 Line too long (90 > 88)
   --> adaptivemind_core/server.py:336:89
    |
335 |     @fastapi_app.get("/health", response_model=HealthResponse)
336 |     def health(app: AdaptiveMindApplication = Depends(_app_dependency)) -> HealthResponse:
    |                                                                                         ^^
337 |         models = app.models()
338 |         status_value = "ok" if models else "degraded"
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:346:47
    |
345 |     @fastapi_app.get("/api/v1/models", response_model=list[str])
346 |     def models(app: AdaptiveMindApplication = Depends(_app_dependency)) -> list[str]:
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^
347 |         return app.models()
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:350:49
    |
349 |     @fastapi_app.get("/api/v1/personas", response_model=list[dict])
350 |     def personas(app: AdaptiveMindApplication = Depends(_app_dependency)) -> list[dict]:
    |                                                 ^^^^^^^^^^^^^^^^^^^^^^^^
351 |         try:
352 |             return app.personas()
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:353:16
    |
351 |         try:
352 |             return app.personas()
353 |         except Exception as e:
    |                ^^^^^^^^^
354 |             logger.error("Failed to retrieve personas", exc_info=e)
355 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve personas")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:355:13
    |
353 |         except Exception as e:
354 |             logger.error("Failed to retrieve personas", exc_info=e)
355 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve personas")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
356 |
357 |     @fastapi_app.post("/api/v1/chat", response_model=ChatResponse)
    |

E501 Line too long (120 > 88)
   --> adaptivemind_core/server.py:355:89
    |
353 |         except Exception as e:
354 |             logger.error("Failed to retrieve personas", exc_info=e)
355 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve personas")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
356 |
357 |     @fastapi_app.post("/api/v1/chat", response_model=ChatResponse)
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:358:67
    |
357 |     @fastapi_app.post("/api/v1/chat", response_model=ChatResponse)
358 |     def chat(request: ChatRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> ChatResponse:
    |                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^
359 |         # Validate persona exists
360 |         if request.persona not in app.config.personas:
    |

E501 Line too long (108 > 88)
   --> adaptivemind_core/server.py:358:89
    |
357 |     @fastapi_app.post("/api/v1/chat", response_model=ChatResponse)
358 |     def chat(request: ChatRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> ChatResponse:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^
359 |         # Validate persona exists
360 |         if request.persona not in app.config.personas:
    |

E501 Line too long (168 > 88)
   --> adaptivemind_core/server.py:361:89
    |
359 | â€¦
360 | â€¦
361 | â€¦D_REQUEST, detail=f"Persona '{request.persona}' not found. Available: {list(app.config.personas.keys())}")
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
362 | â€¦
363 | â€¦
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:373:16
    |
371 |             )
372 |             return ChatResponse(**payload)
373 |         except Exception as e:
    |                ^^^^^^^^^
374 |             logger.error("Chat request failed", exc_info=e)
375 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:375:13
    |
373 |         except Exception as e:
374 |             logger.error("Chat request failed", exc_info=e)
375 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |

E501 Line too long (112 > 88)
   --> adaptivemind_core/server.py:375:89
    |
373 |         except Exception as e:
374 |             logger.error("Chat request failed", exc_info=e)
375 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:380:48
    |
379 |     @fastapi_app.get("/api/v1/monitoring/metrics", response_model=MetricsResponse)
380 |     def metrics(app: AdaptiveMindApplication = Depends(_app_dependency)) -> MetricsResponse:
    |                                                ^^^^^^^^^^^^^^^^^^^^^^^^
381 |         try:
382 |             return MetricsResponse(history=app.metrics_snapshot())
    |

E501 Line too long (92 > 88)
   --> adaptivemind_core/server.py:380:89
    |
379 |     @fastapi_app.get("/api/v1/monitoring/metrics", response_model=MetricsResponse)
380 |     def metrics(app: AdaptiveMindApplication = Depends(_app_dependency)) -> MetricsResponse:
    |                                                                                         ^^^^
381 |         try:
382 |             return MetricsResponse(history=app.metrics_snapshot())
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:383:16
    |
381 |         try:
382 |             return MetricsResponse(history=app.metrics_snapshot())
383 |         except Exception as e:
    |                ^^^^^^^^^
384 |             logger.error("Failed to retrieve metrics", exc_info=e)
385 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve metrics")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:385:13
    |
383 |         except Exception as e:
384 |             logger.error("Failed to retrieve metrics", exc_info=e)
385 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve metrics")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
386 |
387 |     @fastapi_app.get("/api/v1/monitoring/traces", response_model=TracesResponse)
    |

E501 Line too long (119 > 88)
   --> adaptivemind_core/server.py:385:89
    |
383 |         except Exception as e:
384 |             logger.error("Failed to retrieve metrics", exc_info=e)
385 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve metrics")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
386 |
387 |     @fastapi_app.get("/api/v1/monitoring/traces", response_model=TracesResponse)
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:388:47
    |
387 |     @fastapi_app.get("/api/v1/monitoring/traces", response_model=TracesResponse)
388 |     def traces(app: AdaptiveMindApplication = Depends(_app_dependency)) -> TracesResponse:
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^
389 |         try:
390 |             return TracesResponse(traces=app.traces_latest())
    |

E501 Line too long (90 > 88)
   --> adaptivemind_core/server.py:388:89
    |
387 |     @fastapi_app.get("/api/v1/monitoring/traces", response_model=TracesResponse)
388 |     def traces(app: AdaptiveMindApplication = Depends(_app_dependency)) -> TracesResponse:
    |                                                                                         ^^
389 |         try:
390 |             return TracesResponse(traces=app.traces_latest())
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:391:16
    |
389 |         try:
390 |             return TracesResponse(traces=app.traces_latest())
391 |         except Exception as e:
    |                ^^^^^^^^^
392 |             logger.error("Failed to retrieve traces", exc_info=e)
393 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve traces")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:393:13
    |
391 |         except Exception as e:
392 |             logger.error("Failed to retrieve traces", exc_info=e)
393 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve traces")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
394 |
395 |     # Management API endpoints -------------------------------------------
    |

E501 Line too long (118 > 88)
   --> adaptivemind_core/server.py:393:89
    |
391 |         except Exception as e:
392 |             logger.error("Failed to retrieve traces", exc_info=e)
393 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve traces")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
394 |
395 |     # Management API endpoints -------------------------------------------
    |

E501 Line too long (93 > 88)
   --> adaptivemind_core/server.py:397:89
    |
395 |     # Management API endpoints -------------------------------------------
396 |
397 |     @fastapi_app.get("/api/v1/management/system/status", response_model=SystemStatusResponse)
    |                                                                                         ^^^^^
398 |     def get_system_status(app: AdaptiveMindApplication = Depends(_app_dependency)) -> SystemStatusResponse:
399 |         return SystemStatusResponse(**app.system_status())
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:398:58
    |
397 |     @fastapi_app.get("/api/v1/management/system/status", response_model=SystemStatusResponse)
398 |     def get_system_status(app: AdaptiveMindApplication = Depends(_app_dependency)) -> SystemStatusResponse:
    |                                                          ^^^^^^^^^^^^^^^^^^^^^^^^
399 |         return SystemStatusResponse(**app.system_status())
    |

E501 Line too long (107 > 88)
   --> adaptivemind_core/server.py:398:89
    |
397 |     @fastapi_app.get("/api/v1/management/system/status", response_model=SystemStatusResponse)
398 |     def get_system_status(app: AdaptiveMindApplication = Depends(_app_dependency)) -> SystemStatusResponse:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
399 |         return SystemStatusResponse(**app.system_status())
    |

E501 Line too long (95 > 88)
   --> adaptivemind_core/server.py:401:89
    |
399 |         return SystemStatusResponse(**app.system_status())
400 |
401 |     @fastapi_app.get("/api/v1/management/routing/config", response_model=RoutingConfigResponse)
    |                                                                                         ^^^^^^^
402 |     def get_routing_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> RoutingConfigResponse:
403 |         return RoutingConfigResponse(**app.get_routing_config())
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:402:59
    |
401 |     @fastapi_app.get("/api/v1/management/routing/config", response_model=RoutingConfigResponse)
402 |     def get_routing_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> RoutingConfigResponse:
    |                                                           ^^^^^^^^^^^^^^^^^^^^^^^^
403 |         return RoutingConfigResponse(**app.get_routing_config())
    |

E501 Line too long (109 > 88)
   --> adaptivemind_core/server.py:402:89
    |
401 |     @fastapi_app.get("/api/v1/management/routing/config", response_model=RoutingConfigResponse)
402 |     def get_routing_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> RoutingConfigResponse:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^
403 |         return RoutingConfigResponse(**app.get_routing_config())
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:406:54
    |
405 |     @fastapi_app.get("/api/v1/management/backends", response_model=BackendListResponse)
406 |     def list_backends(app: AdaptiveMindApplication = Depends(_app_dependency)) -> BackendListResponse:
    |                                                      ^^^^^^^^^^^^^^^^^^^^^^^^
407 |         return BackendListResponse(backends=app.list_backends())
    |

E501 Line too long (102 > 88)
   --> adaptivemind_core/server.py:406:89
    |
405 |     @fastapi_app.get("/api/v1/management/backends", response_model=BackendListResponse)
406 |     def list_backends(app: AdaptiveMindApplication = Depends(_app_dependency)) -> BackendListResponse:
    |                                                                                         ^^^^^^^^^^^^^^
407 |         return BackendListResponse(backends=app.list_backends())
    |

E501 Line too long (95 > 88)
   --> adaptivemind_core/server.py:409:89
    |
407 |         return BackendListResponse(backends=app.list_backends())
408 |
409 |     @fastapi_app.get("/api/v1/management/context/config", response_model=ContextConfigResponse)
    |                                                                                         ^^^^^^^
410 |     def get_context_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> ContextConfigResponse:
411 |         return ContextConfigResponse(**app.get_context_config())
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:410:59
    |
409 |     @fastapi_app.get("/api/v1/management/context/config", response_model=ContextConfigResponse)
410 |     def get_context_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> ContextConfigResponse:
    |                                                           ^^^^^^^^^^^^^^^^^^^^^^^^
411 |         return ContextConfigResponse(**app.get_context_config())
    |

E501 Line too long (109 > 88)
   --> adaptivemind_core/server.py:410:89
    |
409 |     @fastapi_app.get("/api/v1/management/context/config", response_model=ContextConfigResponse)
410 |     def get_context_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> ContextConfigResponse:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^
411 |         return ContextConfigResponse(**app.get_context_config())
    |

E501 Line too long (97 > 88)
   --> adaptivemind_core/server.py:413:89
    |
411 |         return ContextConfigResponse(**app.get_context_config())
412 |
413 |     @fastapi_app.get("/api/v1/management/security/status", response_model=SecurityStatusResponse)
    |                                                                                         ^^^^^^^^^
414 |     def get_security_status(app: AdaptiveMindApplication = Depends(_app_dependency)) -> SecurityStatusResponse:
415 |         return SecurityStatusResponse(**app.get_security_status())
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:414:60
    |
413 |     @fastapi_app.get("/api/v1/management/security/status", response_model=SecurityStatusResponse)
414 |     def get_security_status(app: AdaptiveMindApplication = Depends(_app_dependency)) -> SecurityStatusResponse:
    |                                                            ^^^^^^^^^^^^^^^^^^^^^^^^
415 |         return SecurityStatusResponse(**app.get_security_status())
    |

E501 Line too long (111 > 88)
   --> adaptivemind_core/server.py:414:89
    |
413 |     @fastapi_app.get("/api/v1/management/security/status", response_model=SecurityStatusResponse)
414 |     def get_security_status(app: AdaptiveMindApplication = Depends(_app_dependency)) -> SecurityStatusResponse:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
415 |         return SecurityStatusResponse(**app.get_security_status())
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:420:86
    |
419 |     @fastapi_app.post("/api/v1/management/personas", response_model=PersonaResponse)
420 |     def create_persona(request: PersonaCreateRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> PersonaResponse:
    |                                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^
421 |         try:
422 |             result = app.create_persona(request.model_dump())
    |

E501 Line too long (130 > 88)
   --> adaptivemind_core/server.py:420:89
    |
419 |     @fastapi_app.post("/api/v1/management/personas", response_model=PersonaResponse)
420 |     def create_persona(request: PersonaCreateRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> PersonaResponse:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
421 |         try:
422 |             result = app.create_persona(request.model_dump())
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:425:13
    |
423 |             return PersonaResponse(**result)
424 |         except ValueError as e:
425 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
426 |         except Exception as e:
427 |             logger.error("Failed to create persona", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:426:16
    |
424 |         except ValueError as e:
425 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
426 |         except Exception as e:
    |                ^^^^^^^^^
427 |             logger.error("Failed to create persona", exc_info=e)
428 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to create persona")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:428:13
    |
426 |         except Exception as e:
427 |             logger.error("Failed to create persona", exc_info=e)
428 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to create persona")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
429 |
430 |     @fastapi_app.put("/api/v1/management/personas/{name}", response_model=PersonaResponse)
    |

E501 Line too long (117 > 88)
   --> adaptivemind_core/server.py:428:89
    |
426 |         except Exception as e:
427 |             logger.error("Failed to create persona", exc_info=e)
428 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to create persona")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
429 |
430 |     @fastapi_app.put("/api/v1/management/personas/{name}", response_model=PersonaResponse)
    |

E501 Line too long (90 > 88)
   --> adaptivemind_core/server.py:430:89
    |
428 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to create persona")
429 |
430 |     @fastapi_app.put("/api/v1/management/personas/{name}", response_model=PersonaResponse)
    |                                                                                         ^^
431 |     def update_persona(name: str, request: PersonaUpdateRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> PersonaRâ€¦
432 |         try:
    |

E501 Line too long (141 > 88)
   --> adaptivemind_core/server.py:431:89
    |
430 | â€¦/{name}", response_model=PersonaResponse)
431 | â€¦aUpdateRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> PersonaResponse:
    |                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
432 | â€¦
433 | â€¦uest.model_dump(exclude_unset=True))
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:431:97
    |
430 |     @fastapi_app.put("/api/v1/management/personas/{name}", response_model=PersonaResponse)
431 |     def update_persona(name: str, request: PersonaUpdateRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> PersonaRâ€¦
    |                                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^
432 |         try:
433 |             result = app.update_persona(name, request.model_dump(exclude_unset=True))
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:436:13
    |
434 | â€¦     return PersonaResponse(**result)
435 | â€¦ except ValueError as e:
436 | â€¦     raise HTTPException(status_code=status.HTTP_404_NOT_FOUND if "not found" in str(e) else status.HTTP_400_BAD_REQUEST, detail=str(e))
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
437 | â€¦ except Exception as e:
438 | â€¦     logger.error(f"Failed to update persona '{name}'", exc_info=e)
    |

E501 Line too long (143 > 88)
   --> adaptivemind_core/server.py:436:89
    |
434 | â€¦
435 | â€¦
436 | â€¦.HTTP_404_NOT_FOUND if "not found" in str(e) else status.HTTP_400_BAD_REQUEST, detail=str(e))
    |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
437 | â€¦
438 | â€¦a '{name}'", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:437:16
    |
435 | â€¦     except ValueError as e:
436 | â€¦         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND if "not found" in str(e) else status.HTTP_400_BAD_REQUEST, detailâ€¦
437 | â€¦     except Exception as e:
    |              ^^^^^^^^^
438 | â€¦         logger.error(f"Failed to update persona '{name}'", exc_info=e)
439 | â€¦         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to update persona '{name}'")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:439:13
    |
437 |         except Exception as e:
438 |             logger.error(f"Failed to update persona '{name}'", exc_info=e)
439 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to update persona '{name}'")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
440 |
441 |     @fastapi_app.delete("/api/v1/management/personas/{name}")
    |

E501 Line too long (127 > 88)
   --> adaptivemind_core/server.py:439:89
    |
437 |         except Exception as e:
438 |             logger.error(f"Failed to update persona '{name}'", exc_info=e)
439 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to update persona '{name}'")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
440 |
441 |     @fastapi_app.delete("/api/v1/management/personas/{name}")
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:442:66
    |
441 |     @fastapi_app.delete("/api/v1/management/personas/{name}")
442 |     def delete_persona(name: str, app: AdaptiveMindApplication = Depends(_app_dependency)):
    |                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
443 |         try:
444 |             app.delete_persona(name)
    |

E501 Line too long (91 > 88)
   --> adaptivemind_core/server.py:442:89
    |
441 |     @fastapi_app.delete("/api/v1/management/personas/{name}")
442 |     def delete_persona(name: str, app: AdaptiveMindApplication = Depends(_app_dependency)):
    |                                                                                         ^^^
443 |         try:
444 |             app.delete_persona(name)
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:447:13
    |
445 | â€¦     return {"message": f"Persona '{name}' deleted successfully"}
446 | â€¦ except ValueError as e:
447 | â€¦     raise HTTPException(status_code=status.HTTP_404_NOT_FOUND if "not found" in str(e) else status.HTTP_400_BAD_REQUEST, detail=str(e))
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
448 | â€¦ except Exception as e:
449 | â€¦     logger.error(f"Failed to delete persona '{name}'", exc_info=e)
    |

E501 Line too long (143 > 88)
   --> adaptivemind_core/server.py:447:89
    |
445 | â€¦deleted successfully"}
446 | â€¦
447 | â€¦.HTTP_404_NOT_FOUND if "not found" in str(e) else status.HTTP_400_BAD_REQUEST, detail=str(e))
    |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
448 | â€¦
449 | â€¦a '{name}'", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:448:16
    |
446 | â€¦     except ValueError as e:
447 | â€¦         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND if "not found" in str(e) else status.HTTP_400_BAD_REQUEST, detailâ€¦
448 | â€¦     except Exception as e:
    |              ^^^^^^^^^
449 | â€¦         logger.error(f"Failed to delete persona '{name}'", exc_info=e)
450 | â€¦         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to delete persona '{name}'")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:450:13
    |
448 |         except Exception as e:
449 |             logger.error(f"Failed to delete persona '{name}'", exc_info=e)
450 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to delete persona '{name}'")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
451 |
452 |     @fastapi_app.put("/api/v1/management/config/routing", response_model=RoutingConfigResponse)
    |

E501 Line too long (127 > 88)
   --> adaptivemind_core/server.py:450:89
    |
448 |         except Exception as e:
449 |             logger.error(f"Failed to delete persona '{name}'", exc_info=e)
450 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to delete persona '{name}'")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
451 |
452 |     @fastapi_app.put("/api/v1/management/config/routing", response_model=RoutingConfigResponse)
    |

E501 Line too long (95 > 88)
   --> adaptivemind_core/server.py:452:89
    |
450 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to delete persona '{name}'")
451 |
452 |     @fastapi_app.put("/api/v1/management/config/routing", response_model=RoutingConfigResponse)
    |                                                                                         ^^^^^^^
453 |     def update_routing_config(request: RoutingConfigUpdateRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> Routinâ€¦
454 |         try:
    |

E501 Line too long (149 > 88)
   --> adaptivemind_core/server.py:453:89
    |
452 | â€¦ng", response_model=RoutingConfigResponse)
453 | â€¦pdateRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> RoutingConfigResponse:
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
454 | â€¦
455 | â€¦t.model_dump(exclude_unset=True))
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:453:99
    |
452 |     @fastapi_app.put("/api/v1/management/config/routing", response_model=RoutingConfigResponse)
453 |     def update_routing_config(request: RoutingConfigUpdateRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> Routinâ€¦
    |                                                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^
454 |         try:
455 |             result = app.update_routing_config(request.model_dump(exclude_unset=True))
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:458:13
    |
456 |             return RoutingConfigResponse(**result)
457 |         except ValueError as e:
458 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
459 |         except Exception as e:
460 |             logger.error("Failed to update routing config", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:459:16
    |
457 |         except ValueError as e:
458 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
459 |         except Exception as e:
    |                ^^^^^^^^^
460 |             logger.error("Failed to update routing config", exc_info=e)
461 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update routing config")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:461:13
    |
459 |         except Exception as e:
460 |             logger.error("Failed to update routing config", exc_info=e)
461 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update routing config")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
462 |
463 |     @fastapi_app.put("/api/v1/management/config/context", response_model=ContextConfigResponse)
    |

E501 Line too long (124 > 88)
   --> adaptivemind_core/server.py:461:89
    |
459 |         except Exception as e:
460 |             logger.error("Failed to update routing config", exc_info=e)
461 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update routing config")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
462 |
463 |     @fastapi_app.put("/api/v1/management/config/context", response_model=ContextConfigResponse)
    |

E501 Line too long (95 > 88)
   --> adaptivemind_core/server.py:463:89
    |
461 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update routing config")
462 |
463 |     @fastapi_app.put("/api/v1/management/config/context", response_model=ContextConfigResponse)
    |                                                                                         ^^^^^^^
464 |     def update_context_config(request: ContextConfigUpdateRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> Contexâ€¦
465 |         try:
    |

E501 Line too long (149 > 88)
   --> adaptivemind_core/server.py:464:89
    |
463 | â€¦xt", response_model=ContextConfigResponse)
464 | â€¦pdateRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> ContextConfigResponse:
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
465 | â€¦
466 | â€¦t.model_dump(exclude_unset=True))
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:464:99
    |
463 |     @fastapi_app.put("/api/v1/management/config/context", response_model=ContextConfigResponse)
464 |     def update_context_config(request: ContextConfigUpdateRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> Contexâ€¦
    |                                                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^
465 |         try:
466 |             result = app.update_context_config(request.model_dump(exclude_unset=True))
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:469:13
    |
467 |             return ContextConfigResponse(**result)
468 |         except ValueError as e:
469 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
470 |         except Exception as e:
471 |             logger.error("Failed to update context config", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:470:16
    |
468 |         except ValueError as e:
469 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
470 |         except Exception as e:
    |                ^^^^^^^^^
471 |             logger.error("Failed to update context config", exc_info=e)
472 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update context config")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:472:13
    |
470 |         except Exception as e:
471 |             logger.error("Failed to update context config", exc_info=e)
472 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update context config")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
473 |
474 |     @fastapi_app.post("/api/v1/management/backends/{name}/test", response_model=BackendTestResponse)
    |

E501 Line too long (124 > 88)
   --> adaptivemind_core/server.py:472:89
    |
470 |         except Exception as e:
471 |             logger.error("Failed to update context config", exc_info=e)
472 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update context config")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
473 |
474 |     @fastapi_app.post("/api/v1/management/backends/{name}/test", response_model=BackendTestResponse)
    |

E501 Line too long (100 > 88)
   --> adaptivemind_core/server.py:474:89
    |
472 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update context config")
473 |
474 |     @fastapi_app.post("/api/v1/management/backends/{name}/test", response_model=BackendTestResponse)
    |                                                                                         ^^^^^^^^^^^^
475 |     def test_backend(name: str, app: AdaptiveMindApplication = Depends(_app_dependency)) -> BackendTestResponse:
476 |         try:
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:475:64
    |
474 |     @fastapi_app.post("/api/v1/management/backends/{name}/test", response_model=BackendTestResponse)
475 |     def test_backend(name: str, app: AdaptiveMindApplication = Depends(_app_dependency)) -> BackendTestResponse:
    |                                                                ^^^^^^^^^^^^^^^^^^^^^^^^
476 |         try:
477 |             result = app.test_backend(name)
    |

E501 Line too long (112 > 88)
   --> adaptivemind_core/server.py:475:89
    |
474 |     @fastapi_app.post("/api/v1/management/backends/{name}/test", response_model=BackendTestResponse)
475 |     def test_backend(name: str, app: AdaptiveMindApplication = Depends(_app_dependency)) -> BackendTestResponse:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^
476 |         try:
477 |             result = app.test_backend(name)
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:480:13
    |
478 |             return BackendTestResponse(**result)
479 |         except ValueError as e:
480 |             raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
481 |         except Exception as e:
482 |             logger.error(f"Failed to test backend '{name}'", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:481:16
    |
479 |         except ValueError as e:
480 |             raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
481 |         except Exception as e:
    |                ^^^^^^^^^
482 |             logger.error(f"Failed to test backend '{name}'", exc_info=e)
483 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to test backend '{name}'")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:483:13
    |
481 |         except Exception as e:
482 |             logger.error(f"Failed to test backend '{name}'", exc_info=e)
483 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to test backend '{name}'")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
484 |
485 |     @fastapi_app.post("/api/v1/management/config/save", response_model=ConfigSaveResponse)
    |

E501 Line too long (125 > 88)
   --> adaptivemind_core/server.py:483:89
    |
481 |         except Exception as e:
482 |             logger.error(f"Failed to test backend '{name}'", exc_info=e)
483 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to test backend '{name}'")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
484 |
485 |     @fastapi_app.post("/api/v1/management/config/save", response_model=ConfigSaveResponse)
    |

E501 Line too long (90 > 88)
   --> adaptivemind_core/server.py:485:89
    |
483 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to test backend '{name}'")
484 |
485 |     @fastapi_app.post("/api/v1/management/config/save", response_model=ConfigSaveResponse)
    |                                                                                         ^^
486 |     def save_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> ConfigSaveResponse:
487 |         try:
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:486:52
    |
485 |     @fastapi_app.post("/api/v1/management/config/save", response_model=ConfigSaveResponse)
486 |     def save_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> ConfigSaveResponse:
    |                                                    ^^^^^^^^^^^^^^^^^^^^^^^^
487 |         try:
488 |             result = app.save_config()
    |

E501 Line too long (99 > 88)
   --> adaptivemind_core/server.py:486:89
    |
485 |     @fastapi_app.post("/api/v1/management/config/save", response_model=ConfigSaveResponse)
486 |     def save_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> ConfigSaveResponse:
    |                                                                                         ^^^^^^^^^^^
487 |         try:
488 |             result = app.save_config()
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server.py:490:16
    |
488 |             result = app.save_config()
489 |             return ConfigSaveResponse(**result)
490 |         except Exception as e:
    |                ^^^^^^^^^
491 |             logger.error("Failed to save config", exc_info=e)
492 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to save configuration")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server.py:492:13
    |
490 |         except Exception as e:
491 |             logger.error("Failed to save config", exc_info=e)
492 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to save configuration")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
493 |
494 |     # OpenAI-compatible endpoints
    |

E501 Line too long (121 > 88)
   --> adaptivemind_core/server.py:492:89
    |
490 |         except Exception as e:
491 |             logger.error("Failed to save config", exc_info=e)
492 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to save configuration")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
493 |
494 |     # OpenAI-compatible endpoints
    |

E501 Line too long (139 > 88)
   --> adaptivemind_core/server.py:496:89
    |
494 | â€¦
495 | â€¦
496 | â€¦hatRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> OpenAIChatResponse:
    |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
497 | â€¦
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:496:92
    |
494 |     # OpenAI-compatible endpoints
495 |     @fastapi_app.post("/v1/chat/completions")
496 |     def openai_chat_completions(request: OpenAIChatRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> OpenAIChatResâ€¦
    |                                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^
497 |         import time
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/server.py:500:89
    |
499 |         # Convert OpenAI format to AdaptiveMind format
500 |         persona = request.model if request.model in app.config.personas else "generalist"
    |                                                                                         ^
501 |         messages = request.messages
502 |         temperature = request.temperature
    |

E501 Line too long (92 > 88)
   --> adaptivemind_core/server.py:506:89
    |
505 |         # Estimate prompt tokens if not provided by AdaptiveMind
506 |         prompt_text = " ".join([msg.content for msg in messages if hasattr(msg, 'content')])
    |                                                                                         ^^^^
507 |         estimated_prompt_tokens = len(prompt_text) // 4  # Rough approximation: ~4 chars per token
    |

E501 Line too long (98 > 88)
   --> adaptivemind_core/server.py:507:89
    |
505 |         # Estimate prompt tokens if not provided by AdaptiveMind
506 |         prompt_text = " ".join([msg.content for msg in messages if hasattr(msg, 'content')])
507 |         estimated_prompt_tokens = len(prompt_text) // 4  # Rough approximation: ~4 chars per token
    |                                                                                         ^^^^^^^^^^
508 |
509 |         # Call AdaptiveMind chat
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server.py:545:54
    |
544 |     @fastapi_app.get("/v1/models")
545 |     def openai_models(app: AdaptiveMindApplication = Depends(_app_dependency)):
    |                                                      ^^^^^^^^^^^^^^^^^^^^^^^^
546 |         import time
547 |         # For now, return hardcoded models
    |

E501 Line too long (96 > 88)
   --> adaptivemind_core/server.py:572:89
    |
570 |     <title>AdaptiveMind Ollama Console</title>
571 |     <style>
572 |         body { font-family: Arial, sans-serif; margin: 2rem; background: #111; color: #f5f5f5; }
    |                                                                                         ^^^^^^^^
573 |         h1 { color: #00e0ff; }
574 |         .container { max-width: 720px; margin: auto; }
    |

E501 Line too long (144 > 88)
   --> adaptivemind_core/server.py:575:89
    |
573 | â€¦
574 | â€¦o; }
575 | â€¦ding: 1rem; background: #1b1b1b; color: #f5f5f5; border: 1px solid #333; border-radius: 8px; }
    |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
576 | â€¦op: 0.5rem; background: #00e0ff; color: #111; border: none; border-radius: 6px; cursor: pointer; }
577 | â€¦1b1b1b; padding: 1rem; border-radius: 8px; border: 1px solid #333; }
    |

E501 Line too long (148 > 88)
   --> adaptivemind_core/server.py:576:89
    |
574 | â€¦ }
575 | â€¦ng: 1rem; background: #1b1b1b; color: #f5f5f5; border: 1px solid #333; border-radius: 8px; }
576 | â€¦: 0.5rem; background: #00e0ff; color: #111; border: none; border-radius: 6px; cursor: pointer; }
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
577 | â€¦1b1b; padding: 1rem; border-radius: 8px; border: 1px solid #333; }
578 | â€¦
    |

E501 Line too long (118 > 88)
   --> adaptivemind_core/server.py:577:89
    |
575 |         textarea { width: 100%; height: 160px; padding: 1rem; background: #1b1b1b; color: #f5f5f5; border: 1px solid #333; border-radâ€¦
576 |         select, button { padding: 0.5rem; margin-top: 0.5rem; background: #00e0ff; color: #111; border: none; border-radius: 6px; curâ€¦
577 |         pre { white-space: pre-wrap; background: #1b1b1b; padding: 1rem; border-radius: 8px; border: 1px solid #333; }
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
578 |         label { display: block; margin-top: 1rem; }
579 |     </style>
    |

E501 Line too long (100 > 88)
   --> adaptivemind_core/server.py:584:89
    |
582 |     <div class="container">
583 |         <h1>AdaptiveMind Ollama Console</h1>
584 |         <p>Local-first assistant with deep research, persona routing, and secure API key gating.</p>
    |                                                                                         ^^^^^^^^^^^^
585 |         <label for="persona">Persona</label>
586 |         <select id="persona"></select>
    |

E501 Line too long (101 > 88)
   --> adaptivemind_core/server.py:620:89
    |
618 |             });
619 |             if (!response.ok) {
620 |                 document.getElementById('output').textContent = 'Request failed: ' + response.status;
    |                                                                                         ^^^^^^^^^^^^^
621 |                 return;
622 |             }
    |

E501 Line too long (131 > 88)
   --> adaptivemind_core/server.py:624:89
    |
622 |             }
623 |             const data = await response.json();
624 |             document.getElementById('output').textContent = data.content + '\n\nTokens: ' + data.tokens + '\nModel: ' + data.model;
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
625 |         }
626 |         loadPersonas();
    |

E501 Line too long (133 > 88)
  --> adaptivemind_core/server_fixed.py:36:89
   |
36 | def create_error_response(error: str, message: str, status_code: int, details: list[dict[str, Any]] | None = None) -> dict[str, Any]:
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
37 |     """Create a standardized error response."""
38 |     return {
   |

D103 Missing docstring in public function
  --> adaptivemind_core/server_fixed.py:47:5
   |
47 | def build_app(config: AppConfig | None = None) -> FastAPI:
   |     ^^^^^^^^^
48 |     jarvis_app = AdaptiveMindApplication(config=config)
   |

E501 Line too long (99 > 88)
  --> adaptivemind_core/server_fixed.py:57:89
   |
55 |             jarvis_app.shutdown()
56 |
57 |     fastapi_app = FastAPI(title="AdaptiveMind Local Assistant", version="1.0.0", lifespan=lifespan)
   |                                                                                         ^^^^^^^^^^^
58 |
59 |     # Add custom exception handlers for proper status code handling
   |

E501 Line too long (90 > 88)
  --> adaptivemind_core/server_fixed.py:61:89
   |
59 |     # Add custom exception handlers for proper status code handling
60 |     @fastapi_app.exception_handler(RequestValidationError)
61 |     async def validation_exception_handler(request: Request, exc: RequestValidationError):
   |                                                                                         ^^
62 |         """Handle validation errors with proper HTTP 422 status code."""
63 |         error_details = []
   |

E501 Line too long (99 > 88)
   --> adaptivemind_core/server_fixed.py:114:89
    |
112 |         provided = header_key or query_key
113 |         if not provided or provided not in jarvis_app.config.security.api_keys:
114 |             raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="Invalid API key")
    |                                                                                         ^^^^^^^^^^^
115 |
116 |     def _app_dependency(request: Request) -> AdaptiveMindApplication:
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:137:47
    |
135 |     # Core endpoints
136 |     @fastapi_app.get("/health")
137 |     def health(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^
138 |         models = app.models()
139 |         status_value = "ok" if models else "degraded"
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:151:47
    |
150 |     @fastapi_app.get("/api/v1/models")
151 |     def models(app: AdaptiveMindApplication = Depends(_app_dependency)) -> list[str]:
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^
152 |         return app.models()
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:155:49
    |
154 |     @fastapi_app.get("/api/v1/personas")
155 |     def personas(app: AdaptiveMindApplication = Depends(_app_dependency)) -> list[dict]:
    |                                                 ^^^^^^^^^^^^^^^^^^^^^^^^
156 |         try:
157 |             return app.personas()
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:158:16
    |
156 |         try:
157 |             return app.personas()
158 |         except Exception as e:
    |                ^^^^^^^^^
159 |             logger.error("Failed to retrieve personas", exc_info=e)
160 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve personas")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:160:13
    |
158 |         except Exception as e:
159 |             logger.error("Failed to retrieve personas", exc_info=e)
160 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve personas")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
161 |
162 |     @fastapi_app.post("/api/v1/chat", response_model=ChatRequest)
    |

E501 Line too long (120 > 88)
   --> adaptivemind_core/server_fixed.py:160:89
    |
158 |         except Exception as e:
159 |             logger.error("Failed to retrieve personas", exc_info=e)
160 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve personas")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
161 |
162 |     @fastapi_app.post("/api/v1/chat", response_model=ChatRequest)
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:163:67
    |
162 |     @fastapi_app.post("/api/v1/chat", response_model=ChatRequest)
163 |     def chat(request: ChatRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^
164 |         """Enhanced chat endpoint with proper validation and error handling."""
165 |         # Validate persona exists
    |

E501 Line too long (100 > 88)
   --> adaptivemind_core/server_fixed.py:163:89
    |
162 |     @fastapi_app.post("/api/v1/chat", response_model=ChatRequest)
163 |     def chat(request: ChatRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^^^^^^^^^^
164 |         """Enhanced chat endpoint with proper validation and error handling."""
165 |         # Validate persona exists
    |

E501 Line too long (110 > 88)
   --> adaptivemind_core/server_fixed.py:169:89
    |
167 |             raise HTTPException(
168 |                 status_code=status.HTTP_400_BAD_REQUEST,
169 |                 detail=f"Persona '{request.persona}' not found. Available: {list(app.config.personas.keys())}"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
170 |             )
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:187:16
    |
185 |                 "diagnostics": payload["diagnostics"]
186 |             }
187 |         except Exception as e:
    |                ^^^^^^^^^
188 |             logger.error("Chat request failed", exc_info=e)
189 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:189:13
    |
187 |         except Exception as e:
188 |             logger.error("Chat request failed", exc_info=e)
189 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
190 |
191 |     @fastapi_app.get("/api/v1/monitoring/metrics")
    |

E501 Line too long (112 > 88)
   --> adaptivemind_core/server_fixed.py:189:89
    |
187 |         except Exception as e:
188 |             logger.error("Chat request failed", exc_info=e)
189 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^
190 |
191 |     @fastapi_app.get("/api/v1/monitoring/metrics")
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:192:48
    |
191 |     @fastapi_app.get("/api/v1/monitoring/metrics")
192 |     def metrics(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                ^^^^^^^^^^^^^^^^^^^^^^^^
193 |         try:
194 |             return {"history": app.metrics_snapshot()}
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:195:16
    |
193 |         try:
194 |             return {"history": app.metrics_snapshot()}
195 |         except Exception as e:
    |                ^^^^^^^^^
196 |             logger.error("Failed to retrieve metrics", exc_info=e)
197 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve metrics")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:197:13
    |
195 |         except Exception as e:
196 |             logger.error("Failed to retrieve metrics", exc_info=e)
197 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve metrics")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
198 |
199 |     @fastapi_app.get("/api/v1/monitoring/traces")
    |

E501 Line too long (119 > 88)
   --> adaptivemind_core/server_fixed.py:197:89
    |
195 |         except Exception as e:
196 |             logger.error("Failed to retrieve metrics", exc_info=e)
197 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve metrics")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
198 |
199 |     @fastapi_app.get("/api/v1/monitoring/traces")
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:200:47
    |
199 |     @fastapi_app.get("/api/v1/monitoring/traces")
200 |     def traces(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^
201 |         try:
202 |             return {"traces": app.traces_latest()}
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:203:16
    |
201 |         try:
202 |             return {"traces": app.traces_latest()}
203 |         except Exception as e:
    |                ^^^^^^^^^
204 |             logger.error("Failed to retrieve traces", exc_info=e)
205 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve traces")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:205:13
    |
203 |         except Exception as e:
204 |             logger.error("Failed to retrieve traces", exc_info=e)
205 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve traces")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
206 |
207 |     # Management API endpoints
    |

E501 Line too long (118 > 88)
   --> adaptivemind_core/server_fixed.py:205:89
    |
203 |         except Exception as e:
204 |             logger.error("Failed to retrieve traces", exc_info=e)
205 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to retrieve traces")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
206 |
207 |     # Management API endpoints
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:209:58
    |
207 |     # Management API endpoints
208 |     @fastapi_app.get("/api/v1/management/system/status")
209 |     def get_system_status(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                          ^^^^^^^^^^^^^^^^^^^^^^^^
210 |         return app.system_status()
    |

E501 Line too long (91 > 88)
   --> adaptivemind_core/server_fixed.py:209:89
    |
207 |     # Management API endpoints
208 |     @fastapi_app.get("/api/v1/management/system/status")
209 |     def get_system_status(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^
210 |         return app.system_status()
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:213:59
    |
212 |     @fastapi_app.get("/api/v1/management/routing/config")
213 |     def get_routing_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                           ^^^^^^^^^^^^^^^^^^^^^^^^
214 |         return app.get_routing_config()
    |

E501 Line too long (92 > 88)
   --> adaptivemind_core/server_fixed.py:213:89
    |
212 |     @fastapi_app.get("/api/v1/management/routing/config")
213 |     def get_routing_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^^
214 |         return app.get_routing_config()
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:217:54
    |
216 |     @fastapi_app.get("/api/v1/management/backends")
217 |     def list_backends(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                      ^^^^^^^^^^^^^^^^^^^^^^^^
218 |         return {"backends": app.list_backends()}
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:221:59
    |
220 |     @fastapi_app.get("/api/v1/management/context/config")
221 |     def get_context_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                           ^^^^^^^^^^^^^^^^^^^^^^^^
222 |         return app.get_context_config()
    |

E501 Line too long (92 > 88)
   --> adaptivemind_core/server_fixed.py:221:89
    |
220 |     @fastapi_app.get("/api/v1/management/context/config")
221 |     def get_context_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^^
222 |         return app.get_context_config()
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:225:60
    |
224 |     @fastapi_app.get("/api/v1/management/security/status")
225 |     def get_security_status(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                            ^^^^^^^^^^^^^^^^^^^^^^^^
226 |         return app.get_security_status()
    |

E501 Line too long (93 > 88)
   --> adaptivemind_core/server_fixed.py:225:89
    |
224 |     @fastapi_app.get("/api/v1/management/security/status")
225 |     def get_security_status(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^^^
226 |         return app.get_security_status()
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:230:70
    |
228 |     # Phase 2: Mutation endpoints
229 |     @fastapi_app.post("/api/v1/management/personas")
230 |     def create_persona(request: dict, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^
231 |         try:
232 |             result = app.create_persona(request)
    |

E501 Line too long (103 > 88)
   --> adaptivemind_core/server_fixed.py:230:89
    |
228 |     # Phase 2: Mutation endpoints
229 |     @fastapi_app.post("/api/v1/management/personas")
230 |     def create_persona(request: dict, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^^^^^^^^^^^^^
231 |         try:
232 |             result = app.create_persona(request)
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:235:13
    |
233 |             return result
234 |         except ValueError as e:
235 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
236 |         except Exception as e:
237 |             logger.error("Failed to create persona", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:236:16
    |
234 |         except ValueError as e:
235 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
236 |         except Exception as e:
    |                ^^^^^^^^^
237 |             logger.error("Failed to create persona", exc_info=e)
238 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to create persona")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:238:13
    |
236 |         except Exception as e:
237 |             logger.error("Failed to create persona", exc_info=e)
238 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to create persona")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
239 |
240 |     @fastapi_app.put("/api/v1/management/personas/{name}")
    |

E501 Line too long (117 > 88)
   --> adaptivemind_core/server_fixed.py:238:89
    |
236 |         except Exception as e:
237 |             logger.error("Failed to create persona", exc_info=e)
238 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to create persona")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
239 |
240 |     @fastapi_app.put("/api/v1/management/personas/{name}")
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:241:81
    |
240 |     @fastapi_app.put("/api/v1/management/personas/{name}")
241 |     def update_persona(name: str, request: dict, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^
242 |         try:
243 |             result = app.update_persona(name, request)
    |

E501 Line too long (114 > 88)
   --> adaptivemind_core/server_fixed.py:241:89
    |
240 |     @fastapi_app.put("/api/v1/management/personas/{name}")
241 |     def update_persona(name: str, request: dict, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
242 |         try:
243 |             result = app.update_persona(name, request)
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:247:17
    |
245 |         except ValueError as e:
246 |             if "not found" in str(e):
247 |                 raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
248 |             else:
249 |                 raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/server_fixed.py:247:89
    |
245 |         except ValueError as e:
246 |             if "not found" in str(e):
247 |                 raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
    |                                                                                         ^
248 |             else:
249 |                 raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:249:17
    |
247 |                 raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
248 |             else:
249 |                 raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
250 |         except Exception as e:
251 |             logger.error(f"Failed to update persona '{name}'", exc_info=e)
    |

E501 Line too long (91 > 88)
   --> adaptivemind_core/server_fixed.py:249:89
    |
247 |                 raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
248 |             else:
249 |                 raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |                                                                                         ^^^
250 |         except Exception as e:
251 |             logger.error(f"Failed to update persona '{name}'", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:250:16
    |
248 |             else:
249 |                 raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
250 |         except Exception as e:
    |                ^^^^^^^^^
251 |             logger.error(f"Failed to update persona '{name}'", exc_info=e)
252 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to update persona '{name}'")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:252:13
    |
250 |         except Exception as e:
251 |             logger.error(f"Failed to update persona '{name}'", exc_info=e)
252 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to update persona '{name}'")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
253 |
254 |     @fastapi_app.delete("/api/v1/management/personas/{name}")
    |

E501 Line too long (127 > 88)
   --> adaptivemind_core/server_fixed.py:252:89
    |
250 |         except Exception as e:
251 |             logger.error(f"Failed to update persona '{name}'", exc_info=e)
252 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to update persona '{name}'")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
253 |
254 |     @fastapi_app.delete("/api/v1/management/personas/{name}")
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:255:66
    |
254 |     @fastapi_app.delete("/api/v1/management/personas/{name}")
255 |     def delete_persona(name: str, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
256 |         try:
257 |             app.delete_persona(name)
    |

E501 Line too long (99 > 88)
   --> adaptivemind_core/server_fixed.py:255:89
    |
254 |     @fastapi_app.delete("/api/v1/management/personas/{name}")
255 |     def delete_persona(name: str, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^^^^^^^^^
256 |         try:
257 |             app.delete_persona(name)
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:261:17
    |
259 |         except ValueError as e:
260 |             if "not found" in str(e):
261 |                 raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
262 |             else:
263 |                 raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/server_fixed.py:261:89
    |
259 |         except ValueError as e:
260 |             if "not found" in str(e):
261 |                 raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
    |                                                                                         ^
262 |             else:
263 |                 raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:263:17
    |
261 |                 raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
262 |             else:
263 |                 raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
264 |         except Exception as e:
265 |             logger.error(f"Failed to delete persona '{name}'", exc_info=e)
    |

E501 Line too long (91 > 88)
   --> adaptivemind_core/server_fixed.py:263:89
    |
261 |                 raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
262 |             else:
263 |                 raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |                                                                                         ^^^
264 |         except Exception as e:
265 |             logger.error(f"Failed to delete persona '{name}'", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:264:16
    |
262 |             else:
263 |                 raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
264 |         except Exception as e:
    |                ^^^^^^^^^
265 |             logger.error(f"Failed to delete persona '{name}'", exc_info=e)
266 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to delete persona '{name}'")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:266:13
    |
264 |         except Exception as e:
265 |             logger.error(f"Failed to delete persona '{name}'", exc_info=e)
266 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to delete persona '{name}'")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
267 |
268 |     @fastapi_app.put("/api/v1/management/config/routing")
    |

E501 Line too long (127 > 88)
   --> adaptivemind_core/server_fixed.py:266:89
    |
264 |         except Exception as e:
265 |             logger.error(f"Failed to delete persona '{name}'", exc_info=e)
266 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to delete persona '{name}'")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
267 |
268 |     @fastapi_app.put("/api/v1/management/config/routing")
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:269:77
    |
268 |     @fastapi_app.put("/api/v1/management/config/routing")
269 |     def update_routing_config(request: dict, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^
270 |         try:
271 |             result = app.update_routing_config(request)
    |

E501 Line too long (110 > 88)
   --> adaptivemind_core/server_fixed.py:269:89
    |
268 |     @fastapi_app.put("/api/v1/management/config/routing")
269 |     def update_routing_config(request: dict, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
270 |         try:
271 |             result = app.update_routing_config(request)
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:274:13
    |
272 |             return result
273 |         except ValueError as e:
274 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
275 |         except Exception as e:
276 |             logger.error("Failed to update routing config", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:275:16
    |
273 |         except ValueError as e:
274 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
275 |         except Exception as e:
    |                ^^^^^^^^^
276 |             logger.error("Failed to update routing config", exc_info=e)
277 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update routing config")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:277:13
    |
275 |         except Exception as e:
276 |             logger.error("Failed to update routing config", exc_info=e)
277 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update routing config")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
278 |
279 |     @fastapi_app.put("/api/v1/management/config/context")
    |

E501 Line too long (124 > 88)
   --> adaptivemind_core/server_fixed.py:277:89
    |
275 |         except Exception as e:
276 |             logger.error("Failed to update routing config", exc_info=e)
277 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update routing config")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
278 |
279 |     @fastapi_app.put("/api/v1/management/config/context")
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:280:77
    |
279 |     @fastapi_app.put("/api/v1/management/config/context")
280 |     def update_context_config(request: dict, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^
281 |         try:
282 |             result = app.update_context_config(request)
    |

E501 Line too long (110 > 88)
   --> adaptivemind_core/server_fixed.py:280:89
    |
279 |     @fastapi_app.put("/api/v1/management/config/context")
280 |     def update_context_config(request: dict, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
281 |         try:
282 |             result = app.update_context_config(request)
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:285:13
    |
283 |             return result
284 |         except ValueError as e:
285 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
286 |         except Exception as e:
287 |             logger.error("Failed to update context config", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:286:16
    |
284 |         except ValueError as e:
285 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
286 |         except Exception as e:
    |                ^^^^^^^^^
287 |             logger.error("Failed to update context config", exc_info=e)
288 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update context config")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:288:13
    |
286 |         except Exception as e:
287 |             logger.error("Failed to update context config", exc_info=e)
288 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update context config")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
289 |
290 |     @fastapi_app.post("/api/v1/management/backends/{name}/test")
    |

E501 Line too long (124 > 88)
   --> adaptivemind_core/server_fixed.py:288:89
    |
286 |         except Exception as e:
287 |             logger.error("Failed to update context config", exc_info=e)
288 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to update context config")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
289 |
290 |     @fastapi_app.post("/api/v1/management/backends/{name}/test")
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:291:64
    |
290 |     @fastapi_app.post("/api/v1/management/backends/{name}/test")
291 |     def test_backend(name: str, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                ^^^^^^^^^^^^^^^^^^^^^^^^
292 |         try:
293 |             result = app.test_backend(name)
    |

E501 Line too long (97 > 88)
   --> adaptivemind_core/server_fixed.py:291:89
    |
290 |     @fastapi_app.post("/api/v1/management/backends/{name}/test")
291 |     def test_backend(name: str, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^^^^^^^
292 |         try:
293 |             result = app.test_backend(name)
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:296:13
    |
294 |             return result
295 |         except ValueError as e:
296 |             raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
297 |         except Exception as e:
298 |             logger.error(f"Failed to test backend '{name}'", exc_info=e)
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:297:16
    |
295 |         except ValueError as e:
296 |             raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
297 |         except Exception as e:
    |                ^^^^^^^^^
298 |             logger.error(f"Failed to test backend '{name}'", exc_info=e)
299 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to test backend '{name}'")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:299:13
    |
297 |         except Exception as e:
298 |             logger.error(f"Failed to test backend '{name}'", exc_info=e)
299 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to test backend '{name}'")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
300 |
301 |     @fastapi_app.post("/api/v1/management/config/save")
    |

E501 Line too long (125 > 88)
   --> adaptivemind_core/server_fixed.py:299:89
    |
297 |         except Exception as e:
298 |             logger.error(f"Failed to test backend '{name}'", exc_info=e)
299 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to test backend '{name}'")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
300 |
301 |     @fastapi_app.post("/api/v1/management/config/save")
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:302:52
    |
301 |     @fastapi_app.post("/api/v1/management/config/save")
302 |     def save_config(app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                    ^^^^^^^^^^^^^^^^^^^^^^^^
303 |         try:
304 |             result = app.save_config()
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:306:16
    |
304 |             result = app.save_config()
305 |             return result
306 |         except Exception as e:
    |                ^^^^^^^^^
307 |             logger.error("Failed to save config", exc_info=e)
308 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to save configuration")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:308:13
    |
306 |         except Exception as e:
307 |             logger.error("Failed to save config", exc_info=e)
308 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to save configuration")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
309 |
310 |     # OpenAI-compatible endpoints
    |

E501 Line too long (121 > 88)
   --> adaptivemind_core/server_fixed.py:308:89
    |
306 |         except Exception as e:
307 |             logger.error("Failed to save config", exc_info=e)
308 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to save configuration")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
309 |
310 |     # OpenAI-compatible endpoints
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:312:79
    |
310 |     # OpenAI-compatible endpoints
311 |     @fastapi_app.post("/v1/chat/completions")
312 |     def openai_chat_completions(request: dict, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                               ^^^^^^^^^^^^^^^^^^^^^^^^
313 |         import time
    |

E501 Line too long (112 > 88)
   --> adaptivemind_core/server_fixed.py:312:89
    |
310 |     # OpenAI-compatible endpoints
311 |     @fastapi_app.post("/v1/chat/completions")
312 |     def openai_chat_completions(request: dict, app: AdaptiveMindApplication = Depends(_app_dependency)) -> dict:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^
313 |         import time
    |

E501 Line too long (101 > 88)
   --> adaptivemind_core/server_fixed.py:325:89
    |
324 |         # Estimate prompt tokens if not provided by AdaptiveMind
325 |         prompt_text = " ".join([msg.get("content", "") for msg in messages if isinstance(msg, dict)])
    |                                                                                         ^^^^^^^^^^^^^
326 |         estimated_prompt_tokens = len(prompt_text) // 4  # Rough approximation: ~4 chars per token
    |

E501 Line too long (98 > 88)
   --> adaptivemind_core/server_fixed.py:326:89
    |
324 |         # Estimate prompt tokens if not provided by AdaptiveMind
325 |         prompt_text = " ".join([msg.get("content", "") for msg in messages if isinstance(msg, dict)])
326 |         estimated_prompt_tokens = len(prompt_text) // 4  # Rough approximation: ~4 chars per token
    |                                                                                         ^^^^^^^^^^
327 |
328 |         try:
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_fixed.py:364:16
    |
362 |                 }
363 |             }
364 |         except Exception as e:
    |                ^^^^^^^^^
365 |             logger.error("OpenAI chat completion failed", exc_info=e)
366 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat completion failed")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_fixed.py:366:13
    |
364 |         except Exception as e:
365 |             logger.error("OpenAI chat completion failed", exc_info=e)
366 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat completion failed")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
367 |
368 |     @fastapi_app.get("/v1/models")
    |

E501 Line too long (115 > 88)
   --> adaptivemind_core/server_fixed.py:366:89
    |
364 |         except Exception as e:
365 |             logger.error("OpenAI chat completion failed", exc_info=e)
366 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat completion failed")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
367 |
368 |     @fastapi_app.get("/v1/models")
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_fixed.py:369:54
    |
368 |     @fastapi_app.get("/v1/models")
369 |     def openai_models(app: AdaptiveMindApplication = Depends(_app_dependency)):
    |                                                      ^^^^^^^^^^^^^^^^^^^^^^^^
370 |         import time
371 |         # Return hardcoded models
    |

E501 Line too long (96 > 88)
   --> adaptivemind_core/server_fixed.py:393:89
    |
391 |     <title>AdaptiveMind Ollama Console</title>
392 |     <style>
393 |         body { font-family: Arial, sans-serif; margin: 2rem; background: #111; color: #f5f5f5; }
    |                                                                                         ^^^^^^^^
394 |         h1 { color: #00e0ff; }
395 |         .container { max-width: 720px; margin: auto; }
    |

E501 Line too long (144 > 88)
   --> adaptivemind_core/server_fixed.py:396:89
    |
394 | â€¦
395 | â€¦o; }
396 | â€¦ding: 1rem; background: #1b1b1b; color: #f5f5f5; border: 1px solid #333; border-radius: 8px; }
    |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
397 | â€¦op: 0.5rem; background: #00e0ff; color: #111; border: none; border-radius: 6px; cursor: pointer; }
398 | â€¦1b1b1b; padding: 1rem; border-radius: 8px; border: 1px solid #333; }
    |

E501 Line too long (148 > 88)
   --> adaptivemind_core/server_fixed.py:397:89
    |
395 | â€¦ }
396 | â€¦ng: 1rem; background: #1b1b1b; color: #f5f5f5; border: 1px solid #333; border-radius: 8px; }
397 | â€¦: 0.5rem; background: #00e0ff; color: #111; border: none; border-radius: 6px; cursor: pointer; }
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
398 | â€¦1b1b; padding: 1rem; border-radius: 8px; border: 1px solid #333; }
399 | â€¦
    |

E501 Line too long (118 > 88)
   --> adaptivemind_core/server_fixed.py:398:89
    |
396 |         textarea { width: 100%; height: 160px; padding: 1rem; background: #1b1b1b; color: #f5f5f5; border: 1px solid #333; border-radâ€¦
397 |         select, button { padding: 0.5rem; margin-top: 0.5rem; background: #00e0ff; color: #111; border: none; border-radius: 6px; curâ€¦
398 |         pre { white-space: pre-wrap; background: #1b1b1b; padding: 1rem; border-radius: 8px; border: 1px solid #333; }
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
399 |         label { display: block; margin-top: 1rem; }
400 |     </style>
    |

E501 Line too long (100 > 88)
   --> adaptivemind_core/server_fixed.py:405:89
    |
403 |     <div class="container">
404 |         <h1>AdaptiveMind Ollama Console</h1>
405 |         <p>Local-first assistant with deep research, persona routing, and secure API key gating.</p>
    |                                                                                         ^^^^^^^^^^^^
406 |         <label for="persona">Persona</label>
407 |         <select id="persona"></select>
    |

E501 Line too long (148 > 88)
   --> adaptivemind_core/server_fixed.py:447:89
    |
445 | â€¦
446 | â€¦.json();
447 | â€¦).textContent = `Request failed: ${response.status} - ${errorData.message || errorData.detail}`;
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
448 | â€¦
449 | â€¦
    |

E501 Line too long (138 > 88)
   --> adaptivemind_core/server_fixed.py:451:89
    |
449 | â€¦
450 | â€¦n();
451 | â€¦').textContent = data.content + '\\n\\nTokens: ' + data.tokens + '\\nModel: ' + data.model;
    |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
452 | â€¦
453 | â€¦').textContent = 'Request failed: ' + e.message;
    |

E501 Line too long (95 > 88)
   --> adaptivemind_core/server_fixed.py:453:89
    |
451 | â€¦             document.getElementById('output').textContent = data.content + '\\n\\nTokens: ' + data.tokens + '\\nModel: ' + data.modâ€¦
452 | â€¦         } catch (e) {
453 | â€¦             document.getElementById('output').textContent = 'Request failed: ' + e.message;
    |                                                                                       ^^^^^^^
454 | â€¦         }
455 | â€¦     }
    |

S104 Possible binding to all interfaces
   --> adaptivemind_core/server_fixed.py:471:43
    |
470 |     port = int(os.getenv("ADAPTIVEMIND_PORT", 8000))
471 |     host = os.getenv("ADAPTIVEMIND_HOST", "0.0.0.0")
    |                                           ^^^^^^^^^
472 |
473 |     # Initialize config
    |

D103 Missing docstring in public function
  --> adaptivemind_core/server_simple.py:75:5
   |
75 | def build_app(config: AppConfig | None = None) -> FastAPI:
   |     ^^^^^^^^^
76 |     jarvis_app = AdaptiveMindApplication(config=config)
   |

E501 Line too long (99 > 88)
  --> adaptivemind_core/server_simple.py:85:89
   |
83 |             jarvis_app.shutdown()
84 |
85 |     fastapi_app = FastAPI(title="AdaptiveMind Local Assistant", version="1.0.0", lifespan=lifespan)
   |                                                                                         ^^^^^^^^^^^
86 |
87 |     def _verify_api_key(request: Request) -> None:
   |

E501 Line too long (99 > 88)
  --> adaptivemind_core/server_simple.py:94:89
   |
92 |         provided = header_key or query_key
93 |         if not provided or provided not in jarvis_app.config.security.api_keys:
94 |             raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="Invalid API key")
   |                                                                                         ^^^^^^^^^^^
95 |
96 |     def _app_dependency(request: Request) -> AdaptiveMindApplication:
   |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_simple.py:101:47
    |
100 |     @fastapi_app.get("/health", response_model=HealthResponse)
101 |     def health(app: AdaptiveMindApplication = Depends(_app_dependency)) -> HealthResponse:
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^
102 |         models = app.models()
103 |         status_value = "ok" if models else "degraded"
    |

E501 Line too long (90 > 88)
   --> adaptivemind_core/server_simple.py:101:89
    |
100 |     @fastapi_app.get("/health", response_model=HealthResponse)
101 |     def health(app: AdaptiveMindApplication = Depends(_app_dependency)) -> HealthResponse:
    |                                                                                         ^^
102 |         models = app.models()
103 |         status_value = "ok" if models else "degraded"
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_simple.py:111:47
    |
110 |     @fastapi_app.get("/api/v1/models", response_model=list[str])
111 |     def models(app: AdaptiveMindApplication = Depends(_app_dependency)) -> list[str]:
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^
112 |         return app.models()
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_simple.py:115:67
    |
114 |     @fastapi_app.post("/api/v1/chat", response_model=ChatResponse)
115 |     def chat(request: ChatRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> ChatResponse:
    |                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^
116 |         if request.persona not in app.config.personas:
117 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=f"Persona '{request.persona}' not found")
    |

E501 Line too long (108 > 88)
   --> adaptivemind_core/server_simple.py:115:89
    |
114 |     @fastapi_app.post("/api/v1/chat", response_model=ChatResponse)
115 |     def chat(request: ChatRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> ChatResponse:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^
116 |         if request.persona not in app.config.personas:
117 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=f"Persona '{request.persona}' not found")
    |

E501 Line too long (121 > 88)
   --> adaptivemind_core/server_simple.py:117:89
    |
115 |     def chat(request: ChatRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> ChatResponse:
116 |         if request.persona not in app.config.personas:
117 |             raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=f"Persona '{request.persona}' not found")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
118 |
119 |         try:
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_simple.py:129:16
    |
127 |             )
128 |             return ChatResponse(**payload)
129 |         except Exception as e:
    |                ^^^^^^^^^
130 |             logger.error("Chat request failed", exc_info=e)
131 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_simple.py:131:13
    |
129 |         except Exception as e:
130 |             logger.error("Chat request failed", exc_info=e)
131 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
132 |
133 |     @fastapi_app.post("/v1/chat/completions")
    |

E501 Line too long (112 > 88)
   --> adaptivemind_core/server_simple.py:131:89
    |
129 |         except Exception as e:
130 |             logger.error("Chat request failed", exc_info=e)
131 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^
132 |
133 |     @fastapi_app.post("/v1/chat/completions")
    |

E501 Line too long (139 > 88)
   --> adaptivemind_core/server_simple.py:134:89
    |
133 | â€¦
134 | â€¦hatRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> OpenAIChatResponse:
    |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
135 | â€¦
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_simple.py:134:92
    |
133 |     @fastapi_app.post("/v1/chat/completions")
134 |     def openai_chat_completions(request: OpenAIChatRequest, app: AdaptiveMindApplication = Depends(_app_dependency)) -> OpenAIChatResâ€¦
    |                                                                                            ^^^^^^^^^^^^^^^^^^^^^^^^
135 |         import time
    |

E501 Line too long (89 > 88)
   --> adaptivemind_core/server_simple.py:137:89
    |
135 |         import time
136 |
137 |         persona = request.model if request.model in app.config.personas else "generalist"
    |                                                                                         ^
138 |
139 |         try:
    |

BLE001 Do not catch blind exception: `Exception`
   --> adaptivemind_core/server_simple.py:168:16
    |
166 |                 }
167 |             )
168 |         except Exception as e:
    |                ^^^^^^^^^
169 |             logger.error("OpenAI chat request failed", exc_info=e)
170 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> adaptivemind_core/server_simple.py:170:13
    |
168 |         except Exception as e:
169 |             logger.error("OpenAI chat request failed", exc_info=e)
170 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
171 |
172 |     @fastapi_app.get("/v1/models")
    |

E501 Line too long (112 > 88)
   --> adaptivemind_core/server_simple.py:170:89
    |
168 |         except Exception as e:
169 |             logger.error("OpenAI chat request failed", exc_info=e)
170 |             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Chat request failed")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^
171 |
172 |     @fastapi_app.get("/v1/models")
    |

B008 Do not perform function call `Depends` in argument defaults; instead, perform the call within the function, or read the default from a module-level singleton variable
   --> adaptivemind_core/server_simple.py:173:54
    |
172 |     @fastapi_app.get("/v1/models")
173 |     def openai_models(app: AdaptiveMindApplication = Depends(_app_dependency)):
    |                                                      ^^^^^^^^^^^^^^^^^^^^^^^^
174 |         import time
175 |         return {
    |

E501 Line too long (96 > 88)
   --> adaptivemind_core/server_simple.py:195:89
    |
193 |     <title>AdaptiveMind Local Assistant</title>
194 |     <style>
195 |         body { font-family: Arial, sans-serif; margin: 2rem; background: #111; color: #f5f5f5; }
    |                                                                                         ^^^^^^^^
196 |         h1 { color: #00e0ff; }
197 |         .container { max-width: 720px; margin: auto; }
    |

E501 Line too long (144 > 88)
   --> adaptivemind_core/server_simple.py:198:89
    |
196 | â€¦
197 | â€¦o; }
198 | â€¦ding: 1rem; background: #1b1b1b; color: #f5f5f5; border: 1px solid #333; border-radius: 8px; }
    |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
199 | â€¦em; background: #00e0ff; color: #111; border: none; border-radius: 6px; cursor: pointer; }
200 | â€¦1b1b1b; padding: 1rem; border-radius: 8px; border: 1px solid #333; }
    |

E501 Line too long (140 > 88)
   --> adaptivemind_core/server_simple.py:199:89
    |
197 | â€¦uto; }
198 | â€¦adding: 1rem; background: #1b1b1b; color: #f5f5f5; border: 1px solid #333; border-radius: 8px; }
199 | â€¦5rem; background: #00e0ff; color: #111; border: none; border-radius: 6px; cursor: pointer; }
    |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
200 | â€¦ #1b1b1b; padding: 1rem; border-radius: 8px; border: 1px solid #333; }
201 | â€¦; }
    |

E501 Line too long (118 > 88)
   --> adaptivemind_core/server_simple.py:200:89
    |
198 | â€¦     textarea { width: 100%; height: 160px; padding: 1rem; background: #1b1b1b; color: #f5f5f5; border: 1px solid #333; border-radiuâ€¦
199 | â€¦     button { padding: 0.5rem; margin-top: 0.5rem; background: #00e0ff; color: #111; border: none; border-radius: 6px; cursor: pointâ€¦
200 | â€¦     pre { white-space: pre-wrap; background: #1b1b1b; padding: 1rem; border-radius: 8px; border: 1px solid #333; }
    |                                                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
201 | â€¦     label { display: block; margin-top: 1rem; }
202 | â€¦     .status { margin-bottom: 1rem; padding: 0.5rem; border-radius: 4px; }
    |

E501 Line too long (110 > 88)
   --> adaptivemind_core/server_simple.py:222:89
    |
220 |                 const data = await response.json();
221 |                 const statusEl = document.getElementById('status');
222 |                 statusEl.textContent = `Status: ${data.status} | Models: ${data.available_models.join(', ')}`;
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
223 |                 statusEl.className = `status ${data.status}`;
224 |             } catch (error) {
    |

E501 Line too long (97 > 88)
   --> adaptivemind_core/server_simple.py:249:89
    |
248 |                 if (!response.ok) {
249 |                     output.textContent = 'Error: ' + response.status + ' ' + response.statusText;
    |                                                                                         ^^^^^^^^^
250 |                     return;
251 |                 }
    |

E501 Line too long (111 > 88)
   --> adaptivemind_core/server_simple.py:254:89
    |
253 |                 const data = await response.json();
254 |                 output.textContent = data.content + '\\n\\nTokens: ' + data.tokens + '\\nModel: ' + data.model;
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
255 |             } catch (error) {
256 |                 output.textContent = 'Error: ' + error.message;
    |

D103 Missing docstring in public function
  --> agent_scaling_laws/examples/architecture_selection.py:30:5
   |
30 | def main():
   |     ^^^^
31 |
32 |     selector = ArchitectureSelector()
   |

D103 Missing docstring in public function
  --> agent_scaling_laws/examples/basic_usage.py:37:5
   |
37 | def main():
   |     ^^^^
38 |
39 |     # Define task context
   |

D103 Missing docstring in public function
  --> agent_scaling_laws/examples/metrics_demo.py:31:5
   |
31 | def main():
   |     ^^^^
32 |
33 |     # Example 1: Efficient Multi-Agent System
   |

D205 1 blank line required between summary line and description
  --> agent_scaling_laws/src/agent_scaling_laws/__init__.py:17:1
   |
15 |   # See https://creativecommons.org/licenses/by/4.0/ for license terms.
16 |
17 | / """Agent Scaling Laws - Implementation of coordination architectures and scaling principles
18 | | for multi-agent systems based on the paper "Towards a Science of Scaling Agent Systems".
19 | | """
   | |___^
20 |
21 |   __version__ = "0.1.0"
   |
help: Insert single blank line

E501 Line too long (91 > 88)
  --> agent_scaling_laws/src/agent_scaling_laws/__init__.py:17:89
   |
15 | # See https://creativecommons.org/licenses/by/4.0/ for license terms.
16 |
17 | """Agent Scaling Laws - Implementation of coordination architectures and scaling principles
   |                                                                                         ^^^
18 | for multi-agent systems based on the paper "Towards a Science of Scaling Agent Systems".
19 | """
   |

E501 Line too long (91 > 88)
  --> agent_scaling_laws/src/agent_scaling_laws/architectures/base.py:58:89
   |
56 |         Args:
57 |             agent_id: Unique identifier for this agent
58 |             capabilities: Dictionary of agent capabilities (e.g., model type, token budget)
   |                                                                                         ^^^
59 |         """
60 |         self.agent_id = agent_id
   |

E501 Line too long (91 > 88)
  --> agent_scaling_laws/src/agent_scaling_laws/architectures/base.py:68:89
   |
67 |     @abstractmethod
68 |     def execute_task(self, task: Any, context: dict[str, Any] | None = None) -> TaskResult:
   |                                                                                         ^^^
69 |         """Execute a task and return the result.
   |

E501 Line too long (100 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/base.py:114:89
    |
112 |             "tasks_completed": self.tasks_completed,
113 |             "errors_count": self.errors_count,
114 |             "messages_sent": len([m for m in self.message_history if m.sender_id == self.agent_id]),
    |                                                                                         ^^^^^^^^^^^^
115 |             "messages_received": len([m for m in self.message_history if m.sender_id != self.agent_id]),
116 |         }
    |

E501 Line too long (104 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/base.py:115:89
    |
113 |             "errors_count": self.errors_count,
114 |             "messages_sent": len([m for m in self.message_history if m.sender_id == self.agent_id]),
115 |             "messages_received": len([m for m in self.message_history if m.sender_id != self.agent_id]),
    |                                                                                         ^^^^^^^^^^^^^^^^
116 |         }
    |

E501 Line too long (100 > 88)
  --> agent_scaling_laws/src/agent_scaling_laws/architectures/centralized.py:65:89
   |
63 |             self.agents.append(agent)
64 |
65 |     def _decompose_task(self, task: Any, context: dict[str, Any] | None) -> list[tuple[Agent, Any]]:
   |                                                                                         ^^^^^^^^^^^^
66 |         """Decompose task into subtasks and assign to agents.
   |

E501 Line too long (91 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/centralized.py:170:89
    |
168 |             )
169 |
170 |     def execute_task(self, task: Any, context: dict[str, Any] | None = None) -> TaskResult:
    |                                                                                         ^^^
171 |         """Execute task with centralized coordination.
    |

E501 Line too long (89 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/centralized.py:202:89
    |
200 |         agent_metrics = [agent.get_metrics() for agent in self.agents]
201 |         base_metrics["agents"] = agent_metrics
202 |         base_metrics["total_agent_tokens"] = sum(a["tokens_used"] for a in agent_metrics)
    |                                                                                         ^
203 |         base_metrics["coordination_overhead"] = self.tokens_used
    |

E501 Line too long (91 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/decentralized.py:182:89
    |
180 |             )
181 |
182 |     def execute_task(self, task: Any, context: dict[str, Any] | None = None) -> TaskResult:
    |                                                                                         ^^^
183 |         """Execute task with decentralized coordination.
    |

E501 Line too long (89 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/decentralized.py:211:89
    |
209 |         agent_metrics = [agent.get_metrics() for agent in self.agents]
210 |         base_metrics["agents"] = agent_metrics
211 |         base_metrics["total_agent_tokens"] = sum(a["tokens_used"] for a in agent_metrics)
    |                                                                                         ^
212 |         base_metrics["communication_overhead"] = self.tokens_used
213 |         base_metrics["messages_exchanged"] = len(self.shared_messages)
    |

E501 Line too long (92 > 88)
  --> agent_scaling_laws/src/agent_scaling_laws/architectures/hybrid.py:28:89
   |
27 |     Combines centralized strategic oversight with decentralized tactical execution.
28 |     High-level manager sets goals while semi-autonomous teams coordinate amongst themselves.
   |                                                                                         ^^^^
29 |
30 |     Characteristics (from paper):
   |

E501 Line too long (90 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/hybrid.py:197:89
    |
195 |         self.tokens_used += agg_tokens
196 |
197 |         successful_teams = [r for r in team_results if r.success and r.output is not None]
    |                                                                                         ^^
198 |         total_tokens = sum(r.tokens_used for r in team_results) + self.tokens_used
    |

SIM108 Use ternary operator `final_output = outputs[0] if len(outputs) == 1 else outputs` instead of `if`-`else`-block
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/hybrid.py:204:13
    |
202 |               outputs = [r.output for r in successful_teams]
203 |
204 | /             if len(outputs) == 1:
205 | |                 final_output = outputs[0]
206 | |             else:
207 | |                 # Combine outputs (could be more sophisticated)
208 | |                 final_output = outputs
    | |______________________________________^
209 |
210 |               self.tasks_completed += len(successful_teams)
    |
help: Replace `if`-`else`-block with `final_output = outputs[0] if len(outputs) == 1 else outputs`

E501 Line too long (91 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/hybrid.py:238:89
    |
236 |             )
237 |
238 |     def execute_task(self, task: Any, context: dict[str, Any] | None = None) -> TaskResult:
    |                                                                                         ^^^
239 |         """Execute task with hybrid coordination.
    |

E501 Line too long (96 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/hybrid.py:261:89
    |
259 |         # Team execution (decentralized within teams)
260 |         team_results = []
261 |         for team_idx, (team, team_task) in enumerate(zip(self.teams, team_tasks, strict=False)):
    |                                                                                         ^^^^^^^^
262 |             result = self._team_coordination(team, team_idx, team_task, context)
263 |             team_results.append(result)
    |

E501 Line too long (89 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/hybrid.py:287:89
    |
285 |             for i, team in enumerate(self.teams)
286 |         ]
287 |         base_metrics["total_agent_tokens"] = sum(a["tokens_used"] for a in agent_metrics)
    |                                                                                         ^
288 |         base_metrics["coordination_overhead"] = self.tokens_used
    |

E501 Line too long (91 > 88)
  --> agent_scaling_laws/src/agent_scaling_laws/architectures/independent.py:64:89
   |
62 |             self.agents.append(agent)
63 |
64 |     def execute_task(self, task: Any, context: dict[str, Any] | None = None) -> TaskResult:
   |                                                                                         ^^^
65 |         """Execute task with independent agents in parallel.
   |

BLE001 Do not catch blind exception: `Exception`
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/independent.py:100:24
    |
 98 |                         self.tasks_completed += 1
 99 |
100 |                 except Exception as e:
    |                        ^^^^^^^^^
101 |                     self.errors_count += 1
102 |                     errors.append(str(e))
    |

E501 Line too long (89 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/architectures/independent.py:142:89
    |
140 |         agent_metrics = [agent.get_metrics() for agent in self.agents]
141 |         base_metrics["agents"] = agent_metrics
142 |         base_metrics["total_agent_tokens"] = sum(a["tokens_used"] for a in agent_metrics)
    |                                                                                         ^
143 |
144 |         return base_metrics
    |

E501 Line too long (99 > 88)
  --> agent_scaling_laws/src/agent_scaling_laws/architectures/single_agent.py:36:89
   |
34 |     """
35 |
36 |     def __init__(self, agent_id: str = "single_agent", capabilities: dict[str, Any] | None = None):
   |                                                                                         ^^^^^^^^^^^
37 |         """Initialize a single agent.
   |

E501 Line too long (91 > 88)
  --> agent_scaling_laws/src/agent_scaling_laws/architectures/single_agent.py:45:89
   |
43 |         super().__init__(agent_id, capabilities)
44 |
45 |     def execute_task(self, task: Any, context: dict[str, Any] | None = None) -> TaskResult:
   |                                                                                         ^^^
46 |         """Execute a task independently.
   |

BLE001 Do not catch blind exception: `Exception`
  --> agent_scaling_laws/src/agent_scaling_laws/architectures/single_agent.py:73:16
   |
71 |                 }
72 |             )
73 |         except Exception as e:
   |                ^^^^^^^^^
74 |             self.errors_count += 1
75 |             return TaskResult(
   |

E501 Line too long (101 > 88)
  --> agent_scaling_laws/src/agent_scaling_laws/metrics/coordination_metrics.py:20:89
   |
19 | Based on "Towards a Science of Scaling Agent Systems" (arXiv 2512.08296v1).
20 | Implements empirical coordination metrics: Efficiency, Overhead, Error Amplification, and Redundancy.
   |                                                                                         ^^^^^^^^^^^^^
21 | """
   |

D105 Missing docstring in magic method
  --> agent_scaling_laws/src/agent_scaling_laws/metrics/coordination_metrics.py:48:9
   |
46 |         }
47 |
48 |     def __repr__(self) -> str:
   |         ^^^^^^^^
49 |         return (
50 |             f"CoordinationMetrics(\n"
   |

E501 Line too long (93 > 88)
  --> agent_scaling_laws/src/agent_scaling_laws/models/architecture_selector.py:28:89
   |
26 | import numpy as np
27 |
28 | ArchitectureType = Literal["single", "independent", "centralized", "decentralized", "hybrid"]
   |                                                                                         ^^^^^
   |

E501 Line too long (93 > 88)
  --> agent_scaling_laws/src/agent_scaling_laws/models/architecture_selector.py:87:89
   |
85 |         """Initialize the architecture selector with empirical coefficients."""
86 |         # Coefficients derived from paper's empirical study
87 |         # These are simplified versions - real implementation would use full regression model
   |                                                                                         ^^^^^
88 |
89 |         # Capability saturation threshold
   |

E501 Line too long (89 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/models/architecture_selector.py:159:89
    |
157 |             score += mods["parallel_bonus"] * task.parallelizable
158 |             # Error amplification hurts performance
159 |             score += mods["error_amplification"] * (1.0 - capabilities.baseline_accuracy)
    |                                                                                         ^
160 |
161 |         elif architecture == "centralized":
    |

E501 Line too long (89 > 88)
   --> agent_scaling_laws/src/agent_scaling_laws/models/architecture_selector.py:273:89
    |
271 |         if capabilities.baseline_accuracy > self.saturation_threshold:
272 |             reasoning.append(
273 |                 f"Single agent baseline accuracy ({capabilities.baseline_accuracy:.1%}) "
    |                                                                                         ^
274 |                 f"exceeds saturation threshold ({self.saturation_threshold:.1%}). "
275 |                 f"Multi-agent coordination may have diminishing returns."
    |

D102 Missing docstring in public method
  --> agent_scaling_laws/tests/architectures/test_base.py:25:9
   |
23 |     """Mock agent for testing."""
24 |
25 |     def execute_task(self, task, context=None):
   |         ^^^^^^^^^^^^
26 |         self.tasks_completed += 1
27 |         self.tokens_used += 50
   |

E501 Line too long (92 > 88)
  --> agent_scaling_laws/tests/metrics/test_coordination_metrics.py:48:89
   |
46 |     """Test overhead metric calculation."""
47 |     # No overhead
48 |     overhead = calculate_overhead(total_tokens=100, agent_tokens=100, coordination_tokens=0)
   |                                                                                         ^^^^
49 |     assert overhead == 0.0
   |

E501 Line too long (92 > 88)
  --> agent_scaling_laws/tests/metrics/test_coordination_metrics.py:52:89
   |
51 |     # 20% overhead
52 |     overhead = calculate_overhead(total_tokens=100, agent_tokens=80, coordination_tokens=20)
   |                                                                                         ^^^^
53 |     assert overhead == pytest.approx(0.2)
   |

E501 Line too long (94 > 88)
  --> agent_scaling_laws/tests/metrics/test_coordination_metrics.py:56:89
   |
55 |     # 50% overhead
56 |     overhead = calculate_overhead(total_tokens=200, agent_tokens=100, coordination_tokens=100)
   |                                                                                         ^^^^^^
57 |     assert overhead == pytest.approx(0.5)
   |

E501 Line too long (96 > 88)
  --> agent_scaling_laws/tests/metrics/test_coordination_metrics.py:63:89
   |
61 |     """Test error amplification calculation."""
62 |     # No amplification
63 |     amp = calculate_error_amplification(single_agent_error_rate=0.1, multi_agent_error_rate=0.1)
   |                                                                                         ^^^^^^^^
64 |     assert amp == pytest.approx(1.0)
   |

E501 Line too long (103 > 88)
  --> agent_scaling_laws/tests/metrics/test_coordination_metrics.py:67:89
   |
66 |     # Independent agents (17.2x from paper)
67 |     amp = calculate_error_amplification(single_agent_error_rate=0.1, multi_agent_error_rate=0.1 * 17.2)
   |                                                                                         ^^^^^^^^^^^^^^^
68 |     assert amp == pytest.approx(17.2, rel=0.01)
   |

E501 Line too long (102 > 88)
  --> agent_scaling_laws/tests/metrics/test_coordination_metrics.py:71:89
   |
70 |     # Centralized agents (4.4x from paper)
71 |     amp = calculate_error_amplification(single_agent_error_rate=0.1, multi_agent_error_rate=0.1 * 4.4)
   |                                                                                         ^^^^^^^^^^^^^^
72 |     assert amp == pytest.approx(4.4, rel=0.01)
   |

E501 Line too long (96 > 88)
  --> agent_scaling_laws/tests/metrics/test_coordination_metrics.py:75:89
   |
74 |     # Error reduction (< 1.0x)
75 |     amp = calculate_error_amplification(single_agent_error_rate=0.2, multi_agent_error_rate=0.1)
   |                                                                                         ^^^^^^^^
76 |     assert amp == pytest.approx(0.5)
   |

E501 Line too long (96 > 88)
   --> agent_scaling_laws/tests/metrics/test_coordination_metrics.py:157:89
    |
156 |     # Zero baseline error
157 |     amp = calculate_error_amplification(single_agent_error_rate=0.0, multi_agent_error_rate=0.0)
    |                                                                                         ^^^^^^^^
158 |     assert amp == pytest.approx(1.0)
    |

E501 Line too long (96 > 88)
   --> agent_scaling_laws/tests/metrics/test_coordination_metrics.py:160:89
    |
158 |     assert amp == pytest.approx(1.0)
159 |
160 |     amp = calculate_error_amplification(single_agent_error_rate=0.0, multi_agent_error_rate=0.1)
    |                                                                                         ^^^^^^^^
161 |     assert amp == pytest.approx(20.0)  # Capped
    |

E501 Line too long (98 > 88)
  --> apps/AdaptiveMind_Local/__init__.py:20:89
   |
18 | This is the relocated example runtime formerly located at the repository root
19 | under `Jarvis_Local/`. Import paths inside the repository have been updated to
20 | `apps.AdaptiveMind_Local`. A temporary compatibility shim at top-level `AdaptiveMind_Local_Compat`
   |                                                                                         ^^^^^^^^^^
21 | is provided to ease migration.
22 | """
   |

D101 Missing docstring in public class
  --> apps/AdaptiveMind_Local/agents/base_agent/agent.py:20:7
   |
20 | class BaseAgent:
   |       ^^^^^^^^^
21 |     def __init__(self, system_prompt=""):
22 |         self.system_prompt = system_prompt
   |

D102 Missing docstring in public method
  --> apps/AdaptiveMind_Local/agents/base_agent/agent.py:26:9
   |
24 |         log.info(f"Agent {self.__class__.__name__} initialized.")
25 |
26 |     def invoke(self, prompt):
   |         ^^^^^^
27 |         log.info(f"Invoking {self.__class__.__name__} with model {settings.ACTIVE_MODEL_NAME}...")
28 |         try:
   |

E501 Line too long (98 > 88)
  --> apps/AdaptiveMind_Local/agents/base_agent/agent.py:27:89
   |
26 |     def invoke(self, prompt):
27 |         log.info(f"Invoking {self.__class__.__name__} with model {settings.ACTIVE_MODEL_NAME}...")
   |                                                                                         ^^^^^^^^^^
28 |         try:
29 |             response = ollama.chat(
   |

D101 Missing docstring in public class
  --> apps/AdaptiveMind_Local/agents/meta_agent/agent.py:20:7
   |
20 | class MetaAgent(BaseAgent):
   |       ^^^^^^^^^
21 |     def __init__(self):
22 |         system_prompt = "You are J.A.R.V.I.S., a highly capable and intelligent AI assistant."
   |

E501 Line too long (94 > 88)
  --> apps/AdaptiveMind_Local/agents/meta_agent/agent.py:22:89
   |
20 | class MetaAgent(BaseAgent):
21 |     def __init__(self):
22 |         system_prompt = "You are J.A.R.V.I.S., a highly capable and intelligent AI assistant."
   |                                                                                         ^^^^^^
23 |         super().__init__(system_prompt=system_prompt)
   |

D101 Missing docstring in public class
  --> apps/AdaptiveMind_Local/agents/specialists/baseline_specialist/agent.py:15:7
   |
15 | class BaselineAgent(BaseAgent):
   |       ^^^^^^^^^^^^^
16 |     def __init__(self):
17 |         # Minimal system prompt - no chain of thought, no detailed instructions
   |

D101 Missing docstring in public class
  --> apps/AdaptiveMind_Local/agents/specialists/cloud_agent/agent.py:16:7
   |
16 | class CloudAgent(BaseAgent):
   |       ^^^^^^^^^^
17 |     def __init__(self):
18 |         super().__init__(system_prompt="You are a powerful cloud-based specialist.")
   |

BLE001 Do not catch blind exception: `Exception`
  --> apps/AdaptiveMind_Local/agents/specialists/cloud_agent/agent.py:21:16
   |
19 |         try:
20 |             self.mcp_client = MCPClient()
21 |         except Exception:
   |                ^^^^^^^^^
22 |             self.mcp_client = None
   |

D102 Missing docstring in public method
  --> apps/AdaptiveMind_Local/agents/specialists/cloud_agent/agent.py:24:9
   |
22 |             self.mcp_client = None
23 |
24 |     def invoke(self, prompt, history=None):
   |         ^^^^^^
25 |         if not self.mcp_client or not self.mcp_client.is_configured():
26 |             # Fallback to local model if cloud provider is not configured
   |

E501 Line too long (100 > 88)
  --> apps/AdaptiveMind_Local/agents/specialists/coding_specialist/agent.py:14:89
   |
12 | from AdaptiveMind_Local.logger_config import log
13 |
14 | # This prompt could benefit from abstracting the language to a variable, e.g. `programming_language`
   |                                                                                         ^^^^^^^^^^^^
15 |
16 | class CodingAgent(BaseAgent):
   |

D101 Missing docstring in public class
  --> apps/AdaptiveMind_Local/agents/specialists/coding_specialist/agent.py:16:7
   |
14 | # This prompt could benefit from abstracting the language to a variable, e.g. `programming_language`
15 |
16 | class CodingAgent(BaseAgent):
   |       ^^^^^^^^^^^
17 |     def __init__(self):
18 |         # Minimal rewrite: call BaseAgent once with the prompt
   |

D101 Missing docstring in public class
  --> apps/AdaptiveMind_Local/agents/specialists/research_specialist/agent.py:15:7
   |
15 | class ResearchAgent(BaseAgent):
   |       ^^^^^^^^^^^^^
16 |     def __init__(self):
17 |         system_prompt = """You are a powerful research specialist focused on accurate historical analysis and logical reasoning.
   |

E501 Line too long (128 > 88)
  --> apps/AdaptiveMind_Local/agents/specialists/research_specialist/agent.py:17:89
   |
15 | class ResearchAgent(BaseAgent):
16 |     def __init__(self):
17 |         system_prompt = """You are a powerful research specialist focused on accurate historical analysis and logical reasoning.
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
18 |
19 | When presented with tricky questions or riddles:
   |

E701 Multiple statements on one line (colon)
  --> apps/AdaptiveMind_Local/agents/utilities/confidence.py:34:36
   |
32 |     try:
33 |         token_logprobs = output['choices'][0]['logprobs']['token_logprobs']
34 |         if len(token_logprobs) <= 1: return 0.0
   |                                    ^
35 |
36 |         confidences = [-lp for lp in token_logprobs[1:]]
   |

E501 Line too long (91 > 88)
  --> apps/AdaptiveMind_Local/agents/utilities/confidence.py:68:89
   |
66 |         return 0.0
67 |     except (KeyError, IndexError, TypeError):
68 |         log.warning("Could not calculate single-token confidence due to missing logprobs.")
   |                                                                                         ^^^
69 |         return 0.0
   |

E501 Line too long (90 > 88)
  --> apps/AdaptiveMind_Local/config.py:22:89
   |
20 | # CRITICAL: Make sure this filename is EXACTLY correct.
21 | # Use a path relative to this file so the model path remains correct after moving.
22 | MODEL_PATH = str(Path(__file__).resolve().parent / "models" / "gemma-3-1b-it-Q4_K_M.gguf")
   |                                                                                         ^^
23 |
24 | # This MUST be 0 for CPU only setup, -1 to offload to GPU(if available)
   |

E501 Line too long (92 > 88)
  --> apps/AdaptiveMind_Local/evaluation.py:17:89
   |
15 | # --- Test Suite Definition ---
16 | # Each test is a dictionary with a name, a prompt, and a validator function.
17 | # The validator function takes the model's response and returns True (pass) or False (fail).
   |                                                                                         ^^^^
18 | TEST_SUITE = [
19 |     {
   |

E501 Line too long (121 > 88)
  --> apps/AdaptiveMind_Local/evaluation.py:23:89
   |
21 |         "prompt":
22 |         """
23 |         You are a meticulous logic and math expert. Your task is to solve the following problem by thinking step-by-step.
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24 |         1.  First, identify the known variables.
25 |         2.  Second, calculate the head start of the first vehicle.
   |

E501 Line too long (92 > 88)
  --> apps/AdaptiveMind_Local/evaluation.py:27:89
   |
25 |         2.  Second, calculate the head start of the first vehicle.
26 |         3.  Third, calculate the difference in speed (relative speed).
27 |         4.  Fourth, use the head start and relative speed to determine the time to catch up.
   |                                                                                         ^^^^
28 |         5.  Finally, add that time to the second vehicle's departure time to find the final answer.
   |

E501 Line too long (99 > 88)
  --> apps/AdaptiveMind_Local/evaluation.py:28:89
   |
26 |         3.  Third, calculate the difference in speed (relative speed).
27 |         4.  Fourth, use the head start and relative speed to determine the time to catch up.
28 |         5.  Finally, add that time to the second vehicle's departure time to find the final answer.
   |                                                                                         ^^^^^^^^^^^
29 |
30 |         Problem: A train leaves City A at 8 AM traveling at 60 mph, and a car leaves City A at 9 AM traveling at 70 mph in the same diâ€¦
   |

E501 Line too long (191 > 88)
  --> apps/AdaptiveMind_Local/evaluation.py:30:89
   |
28 | â€¦ to find the final answer.
29 | â€¦
30 | â€¦ car leaves City A at 9 AM traveling at 70 mph in the same direction. At what time will the car catch up to the train?
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
31 | â€¦
32 | â€¦
   |

E501 Line too long (97 > 88)
  --> apps/AdaptiveMind_Local/evaluation.py:38:89
   |
36 |     {
37 |         "name": "Basic Code Generation",
38 |         "prompt": "Write a simple python function that takes two numbers and returns their sum.",
   |                                                                                         ^^^^^^^^^
39 |         "validator": lambda response: "def" in response and "return" in response and "+" in response
40 |     },
   |

E501 Line too long (100 > 88)
  --> apps/AdaptiveMind_Local/evaluation.py:39:89
   |
37 |         "name": "Basic Code Generation",
38 |         "prompt": "Write a simple python function that takes two numbers and returns their sum.",
39 |         "validator": lambda response: "def" in response and "return" in response and "+" in response
   |                                                                                         ^^^^^^^^^^^^
40 |     },
41 |     {
   |

E501 Line too long (96 > 88)
  --> apps/AdaptiveMind_Local/evaluation.py:43:89
   |
41 |     {
42 |         "name": "Instruction Following",
43 |         "prompt": "Respond to this question with a single word: What is the capital of France?",
   |                                                                                         ^^^^^^^^
44 |         "validator": lambda response: len(response.split()) <= 2 and "paris" in response.lower()
45 |     },
   |

E501 Line too long (96 > 88)
  --> apps/AdaptiveMind_Local/evaluation.py:44:89
   |
42 |         "name": "Instruction Following",
43 |         "prompt": "Respond to this question with a single word: What is the capital of France?",
44 |         "validator": lambda response: len(response.split()) <= 2 and "paris" in response.lower()
   |                                                                                         ^^^^^^^^
45 |     },
46 |     {
   |

E501 Line too long (93 > 88)
  --> apps/AdaptiveMind_Local/evaluation.py:49:89
   |
47 |         "name": "Specialist Code Test",
48 |         "prompt": "Please write a python script that prints the numbers from 1 to 10.",
49 |         "validator": lambda response: "for i in range" in response and "print(i)" in response
   |                                                                                         ^^^^^
50 |     },
51 |     # ... Add more tests as you think of them ...
   |

D103 Missing docstring in public function
  --> apps/AdaptiveMind_Local/evaluation.py:54:5
   |
52 | ]
53 |
54 | def run_evaluation():
   |     ^^^^^^^^^^^^^^
55 |     log.info("--- STARTING EVALUATION HARNESS ---")
56 |     orchestrator = Orchestrator()
   |

BLE001 Do not catch blind exception: `Exception`
  --> apps/AdaptiveMind_Local/evaluation.py:84:16
   |
82 |                 log.warning(f"   - Response was: {response}")
83 |                 failed_tests.append(test_name)
84 |         except Exception as e:
   |                ^^^^^^^^^
85 |             log.error("--- RESULT: ERROR ---")
86 |             log.error(f"   - Validator function failed with error: {e}")
   |

E501 Line too long (107 > 88)
  --> apps/AdaptiveMind_Local/evaluation.py:91:89
   |
90 |     log.info("--- EVALUATION HARNESS COMPLETE ---")
91 |     log.info(f"--- FINAL SCORE: {passed_count} / {total_count} | Total Token Cost: {total_token_cost} ---")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^
92 |
93 |     # --- Returning a dictionary with results ---
   |

D103 Missing docstring in public function
  --> apps/AdaptiveMind_Local/logger_config.py:15:5
   |
15 | def setup_logger():
   |     ^^^^^^^^^^^^
16 |     logger = logging.getLogger('J.A.R.V.I.S.')
17 |     logger.setLevel(logging.INFO)
   |

E501 Line too long (93 > 88)
  --> apps/AdaptiveMind_Local/logger_config.py:26:89
   |
24 |         ch.setLevel(logging.INFO)
25 |         # Formatter
26 |         formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
   |                                                                                         ^^^^^
27 |         fh.setFormatter(formatter)
28 |         ch.setFormatter(formatter)
   |

D102 Missing docstring in public method
  --> apps/AdaptiveMind_Local/orchestrator.py:35:9
   |
33 |         log.info("Orchestrator initialization complete.")
34 |
35 |     def handle_request(self, request: str):
   |         ^^^^^^^^^^^^^^
36 |         # Minimal demonstration: call the meta agent synchronously and return a result
37 |         # that matches the expected (text, tokens, confidence) tuple used by the UI.
   |

N807 Function name should not start and end with `__`
  --> apps/AdaptiveMind_Local/orchestrator.py:46:5
   |
44 | # Import other agents as needed
45 |
46 | def __init__(self):
   |     ^^^^^^^^
47 |     log.info("Initializing Orchestrator and agents...")
48 |     # No more model loading! It's handled by Ollama.
   |

E501 Line too long (107 > 88)
  --> apps/AdaptiveMind_Local/settings.py:18:89
   |
16 | DEEPCONF_ENABLED = False # Disabled until streeaming redone for ollama
17 | CONFIDENCE_THRESHOLD = 0.21 # Start with a reasonable default
18 | RELIABILITY_THRESHOLD = 0.25 # The minimum group_low_conf for a response to be accepted without remediation
   |                                                                                         ^^^^^^^^^^^^^^^^^^^
19 | # --- Model Configuration ---
20 | # Define your models here as they appear in `ollama list`
   |

W191 Indentation contains tabs
  --> apps/AdaptiveMind_Local/settings.py:29:1
   |
28 | def get_active_model_path() -> str:
29 |     """Return a model path that tests can resolve.
   | ^^^^
30 |
31 |     Prefer the explicit `apps/AdaptiveMind_Local/active_model.cfg` (located next to
   |

D206 Docstring should be indented with spaces, not tabs
  --> apps/AdaptiveMind_Local/settings.py:29:2
   |
28 |   def get_active_model_path() -> str:
29 | /     """Return a model path that tests can resolve.
30 | |
31 | |     Prefer the explicit `apps/AdaptiveMind_Local/active_model.cfg` (located next to
32 | |     this file) if present, otherwise return the declared `ACTIVE_MODEL_NAME`.
33 | |     """
   | |_______^
34 |       cfg_path = Path(__file__).resolve().parent / "active_model.cfg"
35 |       if cfg_path.exists():
   |

W191 Indentation contains tabs
  --> apps/AdaptiveMind_Local/settings.py:34:1
   |
32 |     this file) if present, otherwise return the declared `ACTIVE_MODEL_NAME`.
33 |     """
34 |     cfg_path = Path(__file__).resolve().parent / "active_model.cfg"
   | ^^^^
35 |     if cfg_path.exists():
36 |         return str(cfg_path)
   |

W191 Indentation contains tabs
  --> apps/AdaptiveMind_Local/settings.py:35:1
   |
33 |     """
34 |     cfg_path = Path(__file__).resolve().parent / "active_model.cfg"
35 |     if cfg_path.exists():
   | ^^^^
36 |         return str(cfg_path)
37 |     return ACTIVE_MODEL_NAME
   |

W191 Indentation contains tabs
  --> apps/AdaptiveMind_Local/settings.py:36:1
   |
34 |     cfg_path = Path(__file__).resolve().parent / "active_model.cfg"
35 |     if cfg_path.exists():
36 |         return str(cfg_path)
   | ^^^^^^^^
37 |     return ACTIVE_MODEL_NAME
   |

W191 Indentation contains tabs
  --> apps/AdaptiveMind_Local/settings.py:37:1
   |
35 |     if cfg_path.exists():
36 |         return str(cfg_path)
37 |     return ACTIVE_MODEL_NAME
   | ^^^^
   |

W191 Indentation contains tabs
  --> apps/AdaptiveMind_Local/settings.py:42:1
   |
40 | # Mapping of available model names to their identifiers for UI
41 | AVAILABLE_MODELS = {
42 |     "Verifier": VERIFIER_MODEL,
   | ^^^^
43 |     "Draft": DRAFT_MODEL,
44 | }
   |

W191 Indentation contains tabs
  --> apps/AdaptiveMind_Local/settings.py:43:1
   |
41 | AVAILABLE_MODELS = {
42 |     "Verifier": VERIFIER_MODEL,
43 |     "Draft": DRAFT_MODEL,
   | ^^^^
44 | }
   |

D103 Missing docstring in public function
  --> apps/AdaptiveMind_Local/setup_api_key.py:17:5
   |
17 | def main():
   |     ^^^^
18 |
19 |     api_key = input("Enter your OpenAI API key: ").strip()
   |

D103 Missing docstring in public function
  --> apps/AdaptiveMind_Local/tools/autotune.py:18:5
   |
18 | def find_optimal_threshold():
   |     ^^^^^^^^^^^^^^^^^^^^^^
19 |     threshold_range = [i * 0.5 for i in range(2, 31)]
   |

E501 Line too long (112 > 88)
  --> apps/AdaptiveMind_Local/tools/autotune.py:28:89
   |
27 |     log.info("--- STARTING COST-AWARE AUTO-TUNER ---")
28 |     log.info(f"Testing {len(threshold_range)} thresholds from {threshold_range[0]} to {threshold_range[-1]}...")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^
29 |
30 |     for threshold in threshold_range:
   |

E501 Line too long (133 > 88)
  --> apps/AdaptiveMind_Local/tools/autotune.py:38:89
   |
36 |         # We are looking for the CHEAPEST way to get the HIGHEST score.
37 |         is_better_score = results["passed"] > best_result["score"]
38 |         is_same_score_but_cheaper = (results["passed"] == best_result["score"]) and (results["total_tokens"] < best_result["tokens"])
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
39 |
40 |         if is_better_score or is_same_score_but_cheaper:
   |

E501 Line too long (146 > 88)
  --> apps/AdaptiveMind_Local/tools/autotune.py:44:89
   |
42 | â€¦tokens"]
43 | â€¦]
44 | â€¦{threshold}, Score: {results['passed']}/{results['total']}, Tokens: {results['total_tokens']}")
   |                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
45 | â€¦
46 | â€¦
   |

E501 Line too long (164 > 88)
  --> apps/AdaptiveMind_Local/tools/autotune.py:49:89
   |
48 | â€¦
49 | â€¦old']:.2f}, achieving a score of {best_result['score']} with a cost of {best_result['tokens']} tokens.")
   |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
50 | â€¦
51 | â€¦
   |

E501 Line too long (121 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:17:89
   |
15 | from orchestrator import Orchestrator
16 |
17 | DEMO_PROMPT = "If Napoleon had won the Battle of Waterloo, what would the 16th President's grandfather's name have been?"
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
18 |
19 | def run_demo(update_callback):
   |

E501 Line too long (148 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:23:88
   |
21 | â€¦
22 | â€¦E DEMO ---")
23 | â€¦ad won the Battle of Waterloo, what would the 16th President's grandfather's name have been?'")
   |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24 | â€¦uzzle requiring historical and hypothetical reasoning...")
   |

E501 Line too long (111 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:24:88
   |
22 |         update_callback("--- STARTING NAPOLEON RIDDLE DEMO ---")
23 |         update_callback("ðŸ¤” Analyzing: 'If Napoleon had won the Battle of Waterloo, what would the 16th President's grandfather's name â€¦
24 |         update_callback("ðŸ’­ This is a classic logic puzzle requiring historical and hypothetical reasoning...")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
25 |
26 |         # --- Run 1: Baseline ---
   |

E501 Line too long (99 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:28:88
   |
26 |         # --- Run 1: Baseline ---
27 |         update_callback("\n[1/2] ðŸƒ BASELINE MODE - Minimal agent, no remediation")
28 |         update_callback("ðŸ“Š Settings: 1 response, confidence threshold disabled, no deep analysis")
   |                                                                                         ^^^^^^^^^^^
29 |         settings.BASELINE_MODE = True     # Force use of the BaselineAgent with minimal prompt
30 |         settings.RELIABILITY_THRESHOLD = 0.2 # Effectively disable remediation
   |

E501 Line too long (94 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:29:89
   |
27 |         update_callback("\n[1/2] ðŸƒ BASELINE MODE - Minimal agent, no remediation")
28 |         update_callback("ðŸ“Š Settings: 1 response, confidence threshold disabled, no deep analysis")
29 |         settings.BASELINE_MODE = True     # Force use of the BaselineAgent with minimal prompt
   |                                                                                         ^^^^^^
30 |         settings.RELIABILITY_THRESHOLD = 0.2 # Effectively disable remediation
31 |         settings.DEEPCONF_ENABLED = False
   |

E501 Line too long (106 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:40:89
   |
39 |         update_callback("ðŸŽ¯ Routing to initial agent for riddle analysis...")
40 |         baseline_response, baseline_tokens, baseline_confidence = orchestrator.handle_request(DEMO_PROMPT)
   |                                                                                         ^^^^^^^^^^^^^^^^^^
41 |
42 |         update_callback(f"ðŸ“ˆ Baseline result: {baseline_tokens} tokens used, confidence: {baseline_confidence:.4f}")
   |

E501 Line too long (116 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:42:88
   |
40 |         baseline_response, baseline_tokens, baseline_confidence = orchestrator.handle_request(DEMO_PROMPT)
41 |
42 |         update_callback(f"ðŸ“ˆ Baseline result: {baseline_tokens} tokens used, confidence: {baseline_confidence:.4f}")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
43 |         update_callback("ðŸ’¡ Baseline thinking complete - moving to optimized mode...")
   |

E501 Line too long (101 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:46:88
   |
45 |         # --- Run 2: Optimized J.A.R.V.I.S. ---
46 |         update_callback("\n[2/2] ðŸš€ OPTIMIZED J.A.R.V.I.S. FRAMEWORK - Multi-agent with remediation")
   |                                                                                         ^^^^^^^^^^^^^
47 |         update_callback("ðŸ“Š Settings: Multi-response voting, confidence analysis enabled, remediation active")
48 |         settings.BASELINE_MODE = False    # Disable baseline mode for full J.A.R.V.I.S. framework
   |

E501 Line too long (110 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:47:88
   |
45 |         # --- Run 2: Optimized J.A.R.V.I.S. ---
46 |         update_callback("\n[2/2] ðŸš€ OPTIMIZED J.A.R.V.I.S. FRAMEWORK - Multi-agent with remediation")
47 |         update_callback("ðŸ“Š Settings: Multi-response voting, confidence analysis enabled, remediation active")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
48 |         settings.BASELINE_MODE = False    # Disable baseline mode for full J.A.R.V.I.S. framework
49 |         settings.RELIABILITY_THRESHOLD = 0.7 # Tuned to trigger remediation when needed
   |

E501 Line too long (97 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:48:89
   |
46 |         update_callback("\n[2/2] ðŸš€ OPTIMIZED J.A.R.V.I.S. FRAMEWORK - Multi-agent with remediation")
47 |         update_callback("ðŸ“Š Settings: Multi-response voting, confidence analysis enabled, remediation active")
48 |         settings.BASELINE_MODE = False    # Disable baseline mode for full J.A.R.V.I.S. framework
   |                                                                                         ^^^^^^^^^
49 |         settings.RELIABILITY_THRESHOLD = 0.7 # Tuned to trigger remediation when needed
50 |         settings.DEEPCONF_ENABLED = True
   |

E501 Line too long (96 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:51:89
   |
49 |         settings.RELIABILITY_THRESHOLD = 0.7 # Tuned to trigger remediation when needed
50 |         settings.DEEPCONF_ENABLED = True
51 |         settings.CONFIDENCE_THRESHOLD = 0.2 # Enable confidence filtering but not too aggressive
   |                                                                                         ^^^^^^^^
52 |         settings.NUM_RESPONSES = 2 # Multiple responses for optimized mode
53 |         settings.MAX_TOKENS = 750  # Limit token generation to avoid excessive responses
   |

E501 Line too long (90 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:59:88
   |
58 |         update_callback("ðŸŽ¯ Starting multi-agent analysis of Napoleon riddle...")
59 |         update_callback("ðŸ§  MetaAgent analyzing riddle structure and routing decision...")
   |                                                                                         ^^
60 |         update_callback("ðŸ” ResearchAgent gathering historical context and logical reasoning...")
61 |         update_callback("âš–ï¸ Confidence analysis and voting system activated...")
   |

E501 Line too long (97 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:60:88
   |
58 |         update_callback("ðŸŽ¯ Starting multi-agent analysis of Napoleon riddle...")
59 |         update_callback("ðŸ§  MetaAgent analyzing riddle structure and routing decision...")
60 |         update_callback("ðŸ” ResearchAgent gathering historical context and logical reasoning...")
   |                                                                                         ^^^^^^^^^
61 |         update_callback("âš–ï¸ Confidence analysis and voting system activated...")
   |

E501 Line too long (119 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:63:89
   |
61 |         update_callback("âš–ï¸ Confidence analysis and voting system activated...")
62 |
63 |         optimized_response, optimized_tokens, optimized_confidence = optimized_orchestrator.handle_request(DEMO_PROMPT)
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
64 |
65 |         update_callback(f"ðŸ“ˆ Optimized result: {optimized_tokens} tokens used, confidence: {optimized_confidence:.4f}")
   |

E501 Line too long (119 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:65:88
   |
63 |         optimized_response, optimized_tokens, optimized_confidence = optimized_orchestrator.handle_request(DEMO_PROMPT)
64 |
65 |         update_callback(f"ðŸ“ˆ Optimized result: {optimized_tokens} tokens used, confidence: {optimized_confidence:.4f}")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
66 |         update_callback("ðŸŽ‰ Analysis complete - comparing baseline vs optimized approaches...")
   |

E501 Line too long (95 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:66:88
   |
65 |         update_callback(f"ðŸ“ˆ Optimized result: {optimized_tokens} tokens used, confidence: {optimized_confidence:.4f}")
66 |         update_callback("ðŸŽ‰ Analysis complete - comparing baseline vs optimized approaches...")
   |                                                                                         ^^^^^^^
67 |
68 |         # --- Format Final Comparison ---
   |

E501 Line too long (92 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:70:89
   |
68 |         # --- Format Final Comparison ---
69 |         result_string = "\n" + "="*80
70 |         result_string += "\n                      J.A.R.V.I.S. NAPOLEON RIDDLE DEMO RESULTS"
   |                                                                                         ^^^^
71 |         result_string += "\n" + "="*80
72 |         result_string += f"\n\n--- PROMPT ---\n{DEMO_PROMPT}"
   |

E501 Line too long (98 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:75:89
   |
74 |         # Determine if the answers are correct
75 |         baseline_correct = "napoleon" in baseline_response.lower() if baseline_response else False
   |                                                                                         ^^^^^^^^^^
76 |         optimized_correct = "napoleon" in optimized_response.lower() if optimized_response else False
   |

E501 Line too long (101 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:76:89
   |
74 |         # Determine if the answers are correct
75 |         baseline_correct = "napoleon" in baseline_response.lower() if baseline_response else False
76 |         optimized_correct = "napoleon" in optimized_response.lower() if optimized_response else False
   |                                                                                         ^^^^^^^^^^^^^
77 |
78 |         # Format baseline results with correctness indicator
   |

E501 Line too long (89 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:82:87
   |
80 |         result_string += f"\nToken Cost: {baseline_tokens}"
81 |         result_string += f"\nConfidence: {baseline_confidence:.4f}"
82 |         result_string += f"\nCorrect Answer: {'âœ… YES' if baseline_correct else 'âŒ NO'}"
   |                                                                                         ^
83 |         result_string += f"\nResponse: {baseline_response}"
   |

E501 Line too long (90 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:89:87
   |
87 |         result_string += f"\nToken Cost: {optimized_tokens}"
88 |         result_string += f"\nConfidence: {optimized_confidence:.4f}"
89 |         result_string += f"\nCorrect Answer: {'âœ… YES' if optimized_correct else 'âŒ NO'}"
   |                                                                                         ^^
90 |         result_string += f"\nResponse: {optimized_response}"
   |

E501 Line too long (164 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:94:88
   |
92 | â€¦
93 | â€¦"
94 | â€¦f optimized_tokens < baseline_tokens else 'âŒ Worse'} ({baseline_tokens - optimized_tokens:+d} tokens)"
   |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
95 | â€¦mized_confidence > baseline_confidence else 'âŒ Worse'} ({optimized_confidence - baseline_confidence:+.4f})"
96 | â€¦rect' if baseline_correct and optimized_correct else 'Both incorrect' if not baseline_correct and not optimized_correct else 'Only opâ€¦
   |

E501 Line too long (169 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:95:88
   |
93 | â€¦
94 | â€¦optimized_tokens < baseline_tokens else 'âŒ Worse'} ({baseline_tokens - optimized_tokens:+d} tokens)"
95 | â€¦zed_confidence > baseline_confidence else 'âŒ Worse'} ({optimized_confidence - baseline_confidence:+.4f})"
   |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
96 | â€¦ct' if baseline_correct and optimized_correct else 'Both incorrect' if not baseline_correct and not optimized_correct else 'Only optiâ€¦
   |

E501 Line too long (262 > 88)
  --> apps/AdaptiveMind_Local/tools/demo_runner.py:96:89
   |
94 | â€¦seline_tokens else 'âŒ Worse'} ({baseline_tokens - optimized_tokens:+d} tokens)"
95 | â€¦line_confidence else 'âŒ Worse'} ({optimized_confidence - baseline_confidence:+.4f})"
96 | â€¦ct and optimized_correct else 'Both incorrect' if not baseline_correct and not optimized_correct else 'Only optimized correct' if optimized_correct else 'Only baseline correct')}"
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
97 | â€¦
98 | â€¦
   |

BLE001 Do not catch blind exception: `Exception`
   --> apps/AdaptiveMind_Local/tools/demo_runner.py:102:12
    |
100 |         update_callback(result_string)
101 |
102 |     except Exception as e:
    |            ^^^^^^^^^
103 |         log.error("Demo runner failed with an exception.", exc_info=True)
104 |         update_callback(f"Demo Runner ERROR: {e}")
    |

BLE001 Do not catch blind exception: `Exception`
  --> apps/AdaptiveMind_Local/tools/key_manager.py:25:12
   |
23 |         log.info("OpenAI API key has been securely saved to the system keyring.")
24 |         return True
25 |     except Exception as e:
   |            ^^^^^^^^^
26 |         log.error(f"Failed to save API key to keyring: {e}", exc_info=True)
27 |         return False
   |

BLE001 Do not catch blind exception: `Exception`
  --> apps/AdaptiveMind_Local/tools/key_manager.py:39:12
   |
37 |             log.warning("OpenAI API key not found in system keyring.")
38 |             return None
39 |     except Exception as e:
   |            ^^^^^^^^^
40 |         log.error(f"Failed to load API key from keyring: {e}", exc_info=True)
41 |         return None
   |

D101 Missing docstring in public class
  --> apps/AdaptiveMind_Local/tools/mcp_client.py:18:7
   |
18 | class MCPClient:
   |       ^^^^^^^^^
19 |     def __init__(self):
20 |         self.api_key = load_api_key()
   |

E501 Line too long (100 > 88)
  --> apps/AdaptiveMind_Local/tools/mcp_client.py:22:89
   |
20 |         self.api_key = load_api_key()
21 |         if not self.api_key:
22 |             log.warning("MCP Initialization without API key - OpenAI features will be unavailable.")
   |                                                                                         ^^^^^^^^^^^^
23 |             self.client = None
24 |         else:
   |

D102 Missing docstring in public method
  --> apps/AdaptiveMind_Local/tools/mcp_client.py:31:9
   |
29 |         return self.client is not None
30 |
31 |     def invoke(self, prompt, system_prompt="You are a helpful assistant.", model="gpt-4o"):
   |         ^^^^^^
32 |         if not self.is_configured():
33 |             return "error: OpenAI API key not configured, please add it.", 0
   |

E501 Line too long (91 > 88)
  --> apps/AdaptiveMind_Local/tools/mcp_client.py:31:89
   |
29 |         return self.client is not None
30 |
31 |     def invoke(self, prompt, system_prompt="You are a helpful assistant.", model="gpt-4o"):
   |                                                                                         ^^^
32 |         if not self.is_configured():
33 |             return "error: OpenAI API key not configured, please add it.", 0
   |

BLE001 Do not catch blind exception: `Exception`
  --> apps/AdaptiveMind_Local/tools/mcp_client.py:48:16
   |
46 |             log.info(f"MCP Client: Received response. Tokens used: {tokens}")
47 |             return response, tokens
48 |         except Exception as e:
   |                ^^^^^^^^^
49 |             log.error("MCP Client failed to get response from cloud model.", exc_info=True)
50 |             return f"Error: Could not contact cloud API. {e}", 0
   |

E501 Line too long (91 > 88)
  --> apps/AdaptiveMind_Local/tools/mcp_client.py:49:89
   |
47 |             return response, tokens
48 |         except Exception as e:
49 |             log.error("MCP Client failed to get response from cloud model.", exc_info=True)
   |                                                                                         ^^^
50 |             return f"Error: Could not contact cloud API. {e}", 0
   |

BLE001 Do not catch blind exception: `Exception`
  --> apps/AdaptiveMind_Local/tools/note_manager.py:24:12
   |
22 |             f.write(content)
23 |         return f"Successfully saved note to {filename}."
24 |     except Exception as e:
   |            ^^^^^^^^^
25 |         return f"Error saving note: {e}"
   |

F401 `adaptivemind_core.config.ContextPipelineConfig` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> config/config_loader.py:37:9
   |
35 |     from adaptivemind_core.config import (
36 |         AppConfig,
37 |         ContextPipelineConfig,
   |         ^^^^^^^^^^^^^^^^^^^^^
38 |         MonitoringConfig,
39 |         OllamaConfig,
   |
help: Remove unused import

F401 `adaptivemind_core.config.MonitoringConfig` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> config/config_loader.py:38:9
   |
36 |         AppConfig,
37 |         ContextPipelineConfig,
38 |         MonitoringConfig,
   |         ^^^^^^^^^^^^^^^^
39 |         OllamaConfig,
40 |         OpenRouterConfig,
   |
help: Remove unused import

F401 `adaptivemind_core.config.OllamaConfig` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> config/config_loader.py:39:9
   |
37 |         ContextPipelineConfig,
38 |         MonitoringConfig,
39 |         OllamaConfig,
   |         ^^^^^^^^^^^^
40 |         OpenRouterConfig,
41 |         PersonaConfig,
   |
help: Remove unused import

F401 `adaptivemind_core.config.OpenRouterConfig` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> config/config_loader.py:40:9
   |
38 |         MonitoringConfig,
39 |         OllamaConfig,
40 |         OpenRouterConfig,
   |         ^^^^^^^^^^^^^^^^
41 |         PersonaConfig,
42 |         SecurityConfig,
   |
help: Remove unused import

F401 `adaptivemind_core.config.PersonaConfig` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> config/config_loader.py:41:9
   |
39 |         OllamaConfig,
40 |         OpenRouterConfig,
41 |         PersonaConfig,
   |         ^^^^^^^^^^^^^
42 |         SecurityConfig,
43 |         WindowsMLConfig,
   |
help: Remove unused import

F401 `adaptivemind_core.config.SecurityConfig` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> config/config_loader.py:42:9
   |
40 |         OpenRouterConfig,
41 |         PersonaConfig,
42 |         SecurityConfig,
   |         ^^^^^^^^^^^^^^
43 |         WindowsMLConfig,
44 |     )
   |
help: Remove unused import

F401 `adaptivemind_core.config.WindowsMLConfig` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> config/config_loader.py:43:9
   |
41 |         PersonaConfig,
42 |         SecurityConfig,
43 |         WindowsMLConfig,
   |         ^^^^^^^^^^^^^^^
44 |     )
45 |     COMPREHENSIVE_CONFIG_AVAILABLE = True
   |
help: Remove unused import

E501 Line too long (147 > 88)
   --> config/config_loader.py:143:89
    |
141 | â€¦
142 | â€¦ersona",
143 | â€¦nd, a local-first research assistant. Provide concise, factual answers and highlight sources.",
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
144 | â€¦
145 | â€¦
    |

E501 Line too long (98 > 88)
 --> scripts/add_copyright_headers.py:2:89
  |
1 | #!/usr/bin/env python3
2 | """Walk the repository and add a simple CC-BY 4.0 notice header to text files that are missing it.
  |                                                                                         ^^^^^^^^^^
3 |
4 | This is a helper script for zero-cost IP protection. Use carefully â€” review diffs before committing.
  |

E501 Line too long (100 > 88)
 --> scripts/add_copyright_headers.py:4:89
  |
2 | """Walk the repository and add a simple CC-BY 4.0 notice header to text files that are missing it.
3 |
4 | This is a helper script for zero-cost IP protection. Use carefully â€” review diffs before committing.
  |                                                                                         ^^^^^^^^^^^^
5 | """
6 | import os
  |

D103 Missing docstring in public function
  --> scripts/add_copyright_headers.py:19:5
   |
19 | def should_process(path: Path) -> bool:
   |     ^^^^^^^^^^^^^^
20 |     if not path.is_file():
21 |         return False
   |

D103 Missing docstring in public function
  --> scripts/add_copyright_headers.py:27:5
   |
27 | def has_header(text: str) -> bool:
   |     ^^^^^^^^^^
28 |     return "Copyright (c)" in text or "Creative Commons" in text
   |

D103 Missing docstring in public function
  --> scripts/add_copyright_headers.py:31:5
   |
31 | def add_header(path: Path) -> bool:
   |     ^^^^^^^^^^
32 |     text = path.read_text(encoding="utf-8", errors="ignore")
33 |     if has_header(text):
   |

D103 Missing docstring in public function
  --> scripts/add_copyright_headers.py:40:5
   |
40 | def main(root: str = "."):
   |     ^^^^
41 |     rootp = Path(root)
42 |     modified = []
   |

S112 `try`-`except`-`continue` detected, consider logging the exception
  --> scripts/add_copyright_headers.py:47:9
   |
45 |               if should_process(p) and add_header(p):
46 |                   modified.append(str(p))
47 | /         except Exception:
48 | |             continue
   | |____________________^
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/add_copyright_headers.py:47:16
   |
45 |             if should_process(p) and add_header(p):
46 |                 modified.append(str(p))
47 |         except Exception:
   |                ^^^^^^^^^
48 |             continue
   |

E501 Line too long (97 > 88)
  --> scripts/add_copyright_headers.py:61:89
   |
59 | """
60 | Add copyright headers to all code files in the AdaptiveMind framework.
61 | This script adds the required copyright notice to Python, JavaScript, YAML, and other code files.
   |                                                                                         ^^^^^^^^^
62 | """
   |

E402 Module level import not at top of file
  --> scripts/add_copyright_headers.py:64:1
   |
62 | """
63 |
64 | from pathlib import Path
   | ^^^^^^^^^^^^^^^^^^^^^^^^
65 |
66 | # Copyright header template
   |

BLE001 Do not catch blind exception: `Exception`
   --> scripts/add_copyright_headers.py:122:12
    |
120 |             return False
121 |
122 |     except Exception:
    |            ^^^^^^^^^
123 |         return False
    |

D103 Missing docstring in public function
  --> scripts/debug/debug_chat.py:8:5
   |
 8 | def debug_chat():
   |     ^^^^^^^^^^
 9 |
10 |     try:
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/debug/debug_chat.py:41:16
   |
39 |             )
40 |
41 |         except Exception:
   |                ^^^^^^^^^
42 |             import traceback
43 |             traceback.print_exc()
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/debug/debug_chat.py:48:12
   |
46 |         app.shutdown()
47 |
48 |     except Exception:
   |            ^^^^^^^^^
49 |         import traceback
50 |         traceback.print_exc()
   |

D103 Missing docstring in public function
 --> scripts/debug/debug_config.py:7:5
  |
7 | def debug_config():
  |     ^^^^^^^^^^^^
8 |
9 |     try:
  |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/debug/debug_config.py:18:12
   |
16 |         # Check environment variables
17 |
18 |     except Exception:
   |            ^^^^^^^^^
19 |         import traceback
20 |         traceback.print_exc()
   |

S110 `try`-`except`-`pass` detected, consider logging the exception
  --> scripts/debug/debug_ollama.py:26:5
   |
24 |           else:
25 |               pass
26 | /     except Exception:
27 | |         pass
   | |____________^
28 |
29 |       # Test 2: Check if /api/chat works (we know this works)
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/debug/debug_ollama.py:26:12
   |
24 |         else:
25 |             pass
26 |     except Exception:
   |            ^^^^^^^^^
27 |         pass
   |

E501 Line too long (89 > 88)
  --> scripts/debug/debug_ollama.py:35:89
   |
33 | â€¦                     "model": "qwen3:0.6b",
34 | â€¦                     "messages": [
35 | â€¦                         {"role": "user", "content": "Hello! How are you?"}
   |                                                                            ^
36 | â€¦                     ],
37 | â€¦                     "stream": False
   |

S110 `try`-`except`-`pass` detected, consider logging the exception
  --> scripts/debug/debug_ollama.py:44:5
   |
42 |           else:
43 |               pass
44 | /     except Exception:
45 | |         pass
   | |____________^
46 |
47 |       # Test 3: Test with default model "llama3"
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/debug/debug_ollama.py:44:12
   |
42 |         else:
43 |             pass
44 |     except Exception:
   |            ^^^^^^^^^
45 |         pass
   |

S110 `try`-`except`-`pass` detected, consider logging the exception
  --> scripts/debug/debug_ollama.py:62:5
   |
60 |           else:
61 |               pass
62 | /     except Exception:
63 | |         pass
   | |____________^
64 |
65 |   def test_adaptivemind_backend():
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/debug/debug_ollama.py:62:12
   |
60 |         else:
61 |             pass
62 |     except Exception:
   |            ^^^^^^^^^
63 |         pass
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/debug/debug_ollama.py:95:12
   |
93 |             pass
94 |
95 |     except Exception:
   |            ^^^^^^^^^
96 |         import traceback
97 |         traceback.print_exc()
   |

D103 Missing docstring in public function
   --> scripts/debug/debug_ollama.py:99:5
    |
 97 |         traceback.print_exc()
 98 |
 99 | def main():
    |     ^^^^
100 |     test_ollama_endpoints()
101 |     test_adaptivemind_backend()
    |

D205 1 blank line required between summary line and description
  --> scripts/demo/simple_demo.py:18:1
   |
17 |   #!/usr/bin/env python3
18 | / """Simple standalone HTTP server for AdaptiveMind demonstration.
19 | | This bypasses all FastAPI middleware issues by using Python's built-in HTTP server.
20 | | """
   | |___^
21 |
22 |   import json
   |
help: Insert single blank line

D101 Missing docstring in public class
  --> scripts/demo/simple_demo.py:30:7
   |
30 | class AdaptiveMindHandler(BaseHTTPRequestHandler):
   |       ^^^^^^^^^^^^^^^^^^^
31 |     def __init__(self, *args, jarvis_app=None, **kwargs):
32 |         self.jarvis_app = jarvis_app
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/demo/simple_demo.py:70:16
   |
68 |             }
69 |             self._send_json_response(response_data)
70 |         except Exception as e:
   |                ^^^^^^^^^
71 |             self._send_error(500, f"Health check failed: {e!s}")
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/demo/simple_demo.py:78:16
   |
76 |             models = self.jarvis_app.models()
77 |             self._send_json_response(models)
78 |         except Exception as e:
   |                ^^^^^^^^^
79 |             self._send_error(500, f"Failed to get models: {e!s}")
   |

E501 Line too long (104 > 88)
   --> scripts/demo/simple_demo.py:102:89
    |
100 |             if persona not in self.jarvis_app.config.personas:
101 |                 available_personas = list(self.jarvis_app.config.personas.keys())
102 |                 self._send_error(400, f"Persona '{persona}' not found. Available: {available_personas}")
    |                                                                                         ^^^^^^^^^^^^^^^^
103 |                 return
    |

BLE001 Do not catch blind exception: `Exception`
   --> scripts/demo/simple_demo.py:118:16
    |
116 |         except json.JSONDecodeError:
117 |             self._send_error(400, "Invalid JSON in request body")
118 |         except Exception as e:
    |                ^^^^^^^^^
119 |             self._send_error(500, f"Chat request failed: {e!s}")
    |

BLE001 Do not catch blind exception: `Exception`
   --> scripts/demo/simple_demo.py:163:12
    |
161 |         config = load_config()
162 |         jarvis_app = AdaptiveMindApplication(config=config)
163 |     except Exception:
    |            ^^^^^^^^^
164 |         return
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/demo/simple_demo.py:177:5
    |
175 |           server.shutdown()
176 |           jarvis_app.shutdown()
177 | /     except Exception:
178 | |         pass
    | |____________^
179 |
180 |   _INDEX_HTML = """
    |

BLE001 Do not catch blind exception: `Exception`
   --> scripts/demo/simple_demo.py:177:12
    |
175 |         server.shutdown()
176 |         jarvis_app.shutdown()
177 |     except Exception:
    |            ^^^^^^^^^
178 |         pass
    |

E501 Line too long (91 > 88)
   --> scripts/demo/simple_demo.py:189:89
    |
187 |         * { box-sizing: border-box; }
188 |         body {
189 |             font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    |                                                                                         ^^^
190 |             margin: 0;
191 |             padding: 0;
    |

E501 Line too long (97 > 88)
   --> scripts/demo/simple_demo.py:228:89
    |
226 |         }
227 |         .status.ok {
228 |             background: linear-gradient(135deg, rgba(40, 167, 69, 0.2), rgba(32, 201, 151, 0.2));
    |                                                                                         ^^^^^^^^^
229 |             border: 1px solid rgba(40, 167, 69, 0.5);
230 |             color: #d4edda;
    |

E501 Line too long (97 > 88)
   --> scripts/demo/simple_demo.py:233:89
    |
231 |         }
232 |         .status.degraded {
233 |             background: linear-gradient(135deg, rgba(255, 193, 7, 0.2), rgba(253, 126, 20, 0.2));
    |                                                                                         ^^^^^^^^^
234 |             border: 1px solid rgba(255, 193, 7, 0.5);
235 |             color: #fff3cd;
    |

E501 Line too long (96 > 88)
   --> scripts/demo/simple_demo.py:238:89
    |
236 |         }
237 |         .status.error {
238 |             background: linear-gradient(135deg, rgba(220, 53, 69, 0.2), rgba(248, 69, 58, 0.2));
    |                                                                                         ^^^^^^^^
239 |             border: 1px solid rgba(220, 53, 69, 0.5);
240 |             color: #f8d7da;
    |

E501 Line too long (134 > 88)
   --> scripts/demo/simple_demo.py:335:89
    |
333 |         <div class="input-section">
334 |             <label for="prompt">ðŸ’¬ Ask AdaptiveMind anything:</label>
335 |             <textarea id="prompt" placeholder="Type your question here... (Press Enter to send, Shift+Enter for new line)"></textarea>
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
336 |         </div>
    |

E501 Line too long (116 > 88)
   --> scripts/demo/simple_demo.py:353:88
    |
352 |                 if (response.ok) {
353 |                     statusEl.textContent = `âœ… System ${data.status} | Models: ${data.available_models.join(', ')}`;
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
354 |                     statusEl.className = `status ${data.status}`;
355 |                 } else {
    |

E501 Line too long (93 > 88)
   --> scripts/demo/simple_demo.py:377:88
    |
376 |             // UI updates
377 |             output.innerHTML = '<span class="loading">ðŸ¤”</span> AdaptiveMind is thinking...';
    |                                                                                         ^^^^^
378 |             button.innerHTML = '<span class="loading">â³</span> Processing...';
379 |             button.disabled = true;
    |

D205 1 blank line required between summary line and description
  --> scripts/demo/working_demo.py:18:1
   |
17 |   #!/usr/bin/env python3
18 | / """Working AdaptiveMind demonstration with fixed router.
19 | | This script demonstrates a fully functional AdaptiveMind assistant.
20 | | """
   | |___^
21 |
22 |   import contextlib
   |
help: Insert single blank line

D101 Missing docstring in public class
  --> scripts/demo/working_demo.py:31:7
   |
31 | class AdaptiveMindDemoHandler(BaseHTTPRequestHandler):
   |       ^^^^^^^^^^^^^^^^^^^^^^^
32 |     def __init__(self, *args, jarvis_app=None, **kwargs):
33 |         self.jarvis_app = jarvis_app
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/demo/working_demo.py:61:16
   |
59 |             }
60 |             self._send_json_response(response_data)
61 |         except Exception as e:
   |                ^^^^^^^^^
62 |             self._send_error(500, f"Health check failed: {e!s}")
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/demo/working_demo.py:92:16
   |
90 |             self._send_json_response(payload)
91 |
92 |         except Exception as e:
   |                ^^^^^^^^^
93 |             self._send_error(500, f"Chat request failed: {e!s}")
   |

E501 Line too long (111 > 88)
   --> scripts/demo/working_demo.py:259:89
    |
258 |                 const data = await response.json();
259 |                 output.textContent = data.content + '\\n\\nModel: ' + data.model + ' | Tokens: ' + data.tokens;
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
260 |
261 |             } catch (error) {
    |

D205 1 blank line required between summary line and description
  --> scripts/docs/check_md.py:13:1
   |
13 | / """Simple markdown checks used by the docs-lint GitHub Action.
14 | | Checks:
15 | |  - No trailing whitespace
16 | |  - No tabs
17 | |  - Max line length 120
18 | |  - Files under docs/ and README.md.
19 | | """
   | |___^
20 |   import sys
21 |   from pathlib import Path
   |
help: Insert single blank line

E402 Module level import not at top of file
  --> scripts/docs/check_md.py:24:1
   |
23 | ROOT = Path(__file__).resolve().parents[2]
24 | import argparse
   | ^^^^^^^^^^^^^^^
25 |
26 | parser = argparse.ArgumentParser()
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/docs/check_md.py:38:12
   |
36 |     try:
37 |         text = p.read_text(encoding='utf-8').splitlines()
38 |     except Exception as e:
   |            ^^^^^^^^^
39 |         errors.append(f'FAIL: Could not read {p}: {e}')
40 |         continue
   |

E501 Line too long (95 > 88)
  --> scripts/rebrand_to_adaptivemind.py:90:89
   |
89 |     # Only process text files
90 |     return path.suffix not in {'.pyc', '.png', '.jpg', '.jpeg', '.gif', '.zip', '.tar', '.ico'}
   |                                                                                         ^^^^^^^
91 |
92 | def apply_replacements(content: str) -> tuple[str, int]:
   |

BLE001 Do not catch blind exception: `Exception`
   --> scripts/rebrand_to_adaptivemind.py:117:12
    |
116 |         return False
117 |     except Exception:
    |            ^^^^^^^^^
118 |         return False
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/rebrand_to_adaptivemind.py:141:13
    |
139 |                       files_modified += 1
140 |                       total_replacements += count
141 | /             except Exception:
142 | |                 pass
    | |____________________^
    |

BLE001 Do not catch blind exception: `Exception`
   --> scripts/rebrand_to_adaptivemind.py:141:20
    |
139 |                     files_modified += 1
140 |                     total_replacements += count
141 |             except Exception:
    |                    ^^^^^^^^^
142 |                 pass
    |

D101 Missing docstring in public class
  --> scripts/redis.py:13:7
   |
11 | """Minimal redis shim for CI testing."""
12 |
13 | class RedisError(Exception):
   |       ^^^^^^^^^^
14 |     pass
   |

D101 Missing docstring in public class
  --> scripts/redis.py:16:7
   |
14 |     pass
15 |
16 | class Redis:
   |       ^^^^^
17 |     def __init__(self, host=None, port=None, db=None, decode_responses=None):
18 |         pass
   |

D102 Missing docstring in public method
  --> scripts/redis.py:20:9
   |
18 |         pass
19 |
20 |     def rpush(self, name, value):
   |         ^^^^^
21 |         pass
   |

D102 Missing docstring in public method
  --> scripts/redis.py:23:9
   |
21 |         pass
22 |
23 |     def lpop(self, name):
   |         ^^^^
24 |         return None
   |

D102 Missing docstring in public method
  --> scripts/redis.py:26:9
   |
24 |         return None
25 |
26 |     def llen(self, name):
   |         ^^^^
27 |         return 0
   |

D103 Missing docstring in public function
  --> scripts/run_local_ws_server.py:19:11
   |
19 | async def handler(ws, path):
   |           ^^^^^^^
20 |     log.info("Connection to path: %s", path)
21 |     if path != "/ws/pytest_client":
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/run_local_ws_server.py:29:20
   |
27 |             try:
28 |                 data = json.loads(msg)
29 |             except Exception:
   |                    ^^^^^^^^^
30 |                 data = None
31 |             if isinstance(data, dict) and data.get("type") == "ping":
   |

D103 Missing docstring in public function
  --> scripts/run_local_ws_server.py:40:11
   |
40 | async def main():
   |           ^^^^
41 |     server = await websockets.serve(handler, "127.0.0.1", 8000)
42 |     log.info("WebSocket test server listening on ws://127.0.0.1:8000/ws/pytest_client")
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/server/start_fixed_server.py:59:12
   |
57 |         return config
58 |
59 |     except Exception:
   |            ^^^^^^^^^
60 |         import traceback
61 |         traceback.print_exc()
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/server/start_fixed_server.py:72:12
   |
70 |         from adaptivemind_core.server import build_app
71 |         app = build_app(config)
72 |     except Exception:
   |            ^^^^^^^^^
73 |         import traceback
74 |         traceback.print_exc()
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/server/start_fixed_server.py:92:12
   |
90 |     except KeyboardInterrupt:
91 |         pass
92 |     except Exception:
   |            ^^^^^^^^^
93 |         import traceback
94 |         traceback.print_exc()
   |

F401 `fastapi` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> scripts/start_server.py:42:16
   |
40 |     # Try to import dependencies
41 |     try:
42 |         import fastapi
   |                ^^^^^^^
43 |         import pydantic
44 |         import uvicorn
   |
help: Remove unused import: `fastapi`

F401 `pydantic` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> scripts/start_server.py:43:16
   |
41 |     try:
42 |         import fastapi
43 |         import pydantic
   |                ^^^^^^^^
44 |         import uvicorn
45 |     except ImportError:
   |
help: Remove unused import: `pydantic`

F401 `uvicorn` imported but unused; consider using `importlib.util.find_spec` to test for availability
  --> scripts/start_server.py:44:16
   |
42 |         import fastapi
43 |         import pydantic
44 |         import uvicorn
   |                ^^^^^^^
45 |     except ImportError:
46 |         os.system(f"{sys.executable} -m pip install -r requirements.txt")
   |
help: Remove unused import: `uvicorn`

S605 Starting a process with a shell, possible injection detected
  --> scripts/start_server.py:46:9
   |
44 |         import uvicorn
45 |     except ImportError:
46 |         os.system(f"{sys.executable} -m pip install -r requirements.txt")
   |         ^^^^^^^^^
47 |
48 |     return True
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/start_server.py:59:16
   |
57 |             config = load_config()
58 |             return config
59 |         except Exception:
   |                ^^^^^^^^^
60 |
61 |             # Create default configuration
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/start_server.py:83:12
   |
81 |             return config
82 |
83 |     except Exception:
   |            ^^^^^^^^^
84 |
85 |         # Create minimal working configuration
   |

BLE001 Do not catch blind exception: `Exception`
   --> scripts/start_server.py:115:12
    |
113 |         from adaptivemind_core.server import build_app
114 |         app = build_app(config)
115 |     except Exception:
    |            ^^^^^^^^^
116 |
117 |         # Create minimal server as fallback
    |

BLE001 Do not catch blind exception: `Exception`
   --> scripts/start_server.py:159:12
    |
157 |     except KeyboardInterrupt:
158 |         pass
159 |     except Exception:
    |            ^^^^^^^^^
160 |         sys.exit(1)
    |

D103 Missing docstring in public function
  --> scripts/update_copyright_info.py:24:5
   |
24 | def replace_header(path: Path, new_name: str) -> bool:
   |     ^^^^^^^^^^^^^^
25 |     text = path.read_text(encoding="utf-8", errors="ignore")
26 |     if "Copyright (c)" not in text:
   |

D103 Missing docstring in public function
  --> scripts/update_copyright_info.py:35:5
   |
35 | def main(root: str = ".", new_name: str = TARGET):
   |     ^^^^
36 |     rootp = Path(root)
37 |     modified = []
   |

S112 `try`-`except`-`continue` detected, consider logging the exception
  --> scripts/update_copyright_info.py:42:9
   |
40 |               if p.is_file() and replace_header(p, new_name):
41 |                   modified.append(str(p))
42 | /         except Exception:
43 | |             continue
   | |____________________^
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/update_copyright_info.py:42:16
   |
40 |             if p.is_file() and replace_header(p, new_name):
41 |                 modified.append(str(p))
42 |         except Exception:
   |                ^^^^^^^^^
43 |             continue
   |

E501 Line too long (89 > 88)
  --> scripts/update_copyright_info.py:56:89
   |
54 | #!/usr/bin/env python3
55 | """
56 | Update copyright information in all files to replace placeholder names with actual names.
   |                                                                                         ^
57 | """
   |

E402 Module level import not at top of file
  --> scripts/update_copyright_info.py:59:1
   |
57 | """
58 |
59 | import os
   | ^^^^^^^^^
60 | import re
61 | from pathlib import Path
   |

E402 Module level import not at top of file
  --> scripts/update_copyright_info.py:60:1
   |
59 | import os
60 | import re
   | ^^^^^^^^^
61 | from pathlib import Path
   |

E402 Module level import not at top of file
  --> scripts/update_copyright_info.py:61:1
   |
59 | import os
60 | import re
61 | from pathlib import Path
   | ^^^^^^^^^^^^^^^^^^^^^^^^
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/update_copyright_info.py:88:12
   |
86 |             return False
87 |
88 |     except Exception:
   |            ^^^^^^^^^
89 |         return False
   |

E501 Line too long (190 > 88)
   --> scripts/update_copyright_info.py:124:89
    |
123 | â€¦
124 | â€¦, '.exe', '.png', '.jpg', '.jpeg', '.gif', '.ico', '.woff', '.woff2', '.ttf', '.eot', '.pdf', '.zip', '.tar', '.gz'}:
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
125 | â€¦
    |

D103 Missing docstring in public function
  --> scripts/yaml.py:20:5
   |
20 | def safe_load(stream: IO | str | None) -> Any:
   |     ^^^^^^^^^
21 |     # Accept file-like object or string; return empty mapping when not present.
22 |     if stream is None:
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/yaml.py:33:16
   |
31 |         try:
32 |             return json.loads(data)
33 |         except Exception:
   |                ^^^^^^^^^
34 |             return {}
35 |     except Exception:
   |

BLE001 Do not catch blind exception: `Exception`
  --> scripts/yaml.py:35:12
   |
33 |         except Exception:
34 |             return {}
35 |     except Exception:
   |            ^^^^^^^^^
36 |         return {}
   |

E501 Line too long (89 > 88)
  --> sdk/python/adaptivemind_sdk/client.py:29:89
   |
27 |     Example:
28 |         from adaptivemind_sdk.client import AdaptiveMindClient
29 |         client = AdaptiveMindClient(base_url="http://127.0.0.1:8000", api_key="YOUR_KEY")
   |                                                                                         ^
30 |         health = client.health()
31 |         models = client.models()
   |

E501 Line too long (99 > 88)
  --> sdk/python/adaptivemind_sdk/client.py:35:89
   |
33 |     """
34 |
35 |     def __init__(self, base_url: str | None = None, api_key: str | None = None, timeout: int = 30):
   |                                                                                         ^^^^^^^^^^^
36 |         self.base_url = (base_url or os.getenv("ADAPTIVEMIND_TEST_BASE_URL") or "http://127.0.0.1:8000").rstrip("/")
37 |         self.api_key = api_key or os.getenv("ADAPTIVEMIND_API_KEY")
   |

FBT001 Boolean-typed positional argument in function definition
  --> sdk/python/adaptivemind_sdk/client.py:52:61
   |
50 |         return self._session.get(self._url(path), params=params, timeout=self.timeout)
51 |
52 |     def _post(self, path: str, payload: dict | None = None, stream: bool = False) -> requests.Response:
   |                                                             ^^^^^^
53 |         data = json.dumps(payload or {})
54 |         return self._session.post(self._url(path), data=data, timeout=self.timeout, stream=stream)
   |

FBT002 Boolean default positional argument in function definition
  --> sdk/python/adaptivemind_sdk/client.py:52:61
   |
50 |         return self._session.get(self._url(path), params=params, timeout=self.timeout)
51 |
52 |     def _post(self, path: str, payload: dict | None = None, stream: bool = False) -> requests.Response:
   |                                                             ^^^^^^
53 |         data = json.dumps(payload or {})
54 |         return self._session.post(self._url(path), data=data, timeout=self.timeout, stream=stream)
   |

E501 Line too long (103 > 88)
  --> sdk/python/adaptivemind_sdk/client.py:52:89
   |
50 |         return self._session.get(self._url(path), params=params, timeout=self.timeout)
51 |
52 |     def _post(self, path: str, payload: dict | None = None, stream: bool = False) -> requests.Response:
   |                                                                                         ^^^^^^^^^^^^^^^
53 |         data = json.dumps(payload or {})
54 |         return self._session.post(self._url(path), data=data, timeout=self.timeout, stream=stream)
   |

E501 Line too long (98 > 88)
  --> sdk/python/adaptivemind_sdk/client.py:54:89
   |
52 |     def _post(self, path: str, payload: dict | None = None, stream: bool = False) -> requests.Response:
53 |         data = json.dumps(payload or {})
54 |         return self._session.post(self._url(path), data=data, timeout=self.timeout, stream=stream)
   |                                                                                         ^^^^^^^^^^
55 |
56 |     # -------------------- Health & Models --------------------
   |

E501 Line too long (140 > 88)
  --> sdk/python/adaptivemind_sdk/client.py:70:89
   |
69 | â€¦----
70 | â€¦str | None = None, temperature: float | None = None, max_tokens: int | None = None) -> dict:
   |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
71 | â€¦
   |

E501 Line too long (158 > 88)
  --> sdk/python/adaptivemind_sdk/client.py:92:89
   |
90 | â€¦
91 | â€¦
92 | â€¦r | None = None, temperature: float | None = None, max_tokens: int | None = None) -> t.Iterator[str]:
   |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
93 | â€¦"""
94 | â€¦}
   |

E501 Line too long (137 > 88)
   --> sdk/python/adaptivemind_sdk/client.py:114:89
    |
112 | â€¦
113 | â€¦
114 | â€¦jective: str, context: dict | None = None, priority: int = 1, timeout: int = 300) -> dict:
    |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
115 | â€¦type."""
116 | â€¦
    |

E501 Line too long (110 > 88)
   --> sdk/python/adaptivemind_sdk/client.py:127:89
    |
125 |         return r.json()
126 |
127 |     def agents_collaborate(self, agent_types: list[str], objective: str, context: dict | None = None) -> dict:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
128 |         """Execute a collaboration between agents."""
129 |         payload = {
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:145:9
    |
144 |     # -------------------- Memory --------------------
145 |     def memory_stats(self) -> dict:
    |         ^^^^^^^^^^^^
146 |         r = self._get("/memory/stats")
147 |         r.raise_for_status()
    |

FBT001 Boolean-typed positional argument in function definition
   --> sdk/python/adaptivemind_sdk/client.py:150:46
    |
148 |         return r.json()
149 |
150 |     def feed_ingest(self, items: list[dict], persist_to_knowledge: bool = True, persist_to_memory: bool = True) -> dict:
    |                                              ^^^^^^^^^^^^^^^^^^^^
151 |         """Ingest feed items into memory/knowledge graph."""
152 |         payload = {
    |

FBT002 Boolean default positional argument in function definition
   --> sdk/python/adaptivemind_sdk/client.py:150:46
    |
148 |         return r.json()
149 |
150 |     def feed_ingest(self, items: list[dict], persist_to_knowledge: bool = True, persist_to_memory: bool = True) -> dict:
    |                                              ^^^^^^^^^^^^^^^^^^^^
151 |         """Ingest feed items into memory/knowledge graph."""
152 |         payload = {
    |

FBT001 Boolean-typed positional argument in function definition
   --> sdk/python/adaptivemind_sdk/client.py:150:81
    |
148 |         return r.json()
149 |
150 |     def feed_ingest(self, items: list[dict], persist_to_knowledge: bool = True, persist_to_memory: bool = True) -> dict:
    |                                                                                 ^^^^^^^^^^^^^^^^^
151 |         """Ingest feed items into memory/knowledge graph."""
152 |         payload = {
    |

FBT002 Boolean default positional argument in function definition
   --> sdk/python/adaptivemind_sdk/client.py:150:81
    |
148 |         return r.json()
149 |
150 |     def feed_ingest(self, items: list[dict], persist_to_knowledge: bool = True, persist_to_memory: bool = True) -> dict:
    |                                                                                 ^^^^^^^^^^^^^^^^^
151 |         """Ingest feed items into memory/knowledge graph."""
152 |         payload = {
    |

E501 Line too long (120 > 88)
   --> sdk/python/adaptivemind_sdk/client.py:150:89
    |
148 |         return r.json()
149 |
150 |     def feed_ingest(self, items: list[dict], persist_to_knowledge: bool = True, persist_to_memory: bool = True) -> dict:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
151 |         """Ingest feed items into memory/knowledge graph."""
152 |         payload = {
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:162:9
    |
161 |     # -------------------- Workflows --------------------
162 |     def workflow_execute(self, workflow_type: str, parameters: dict | None = None, priority: int = 1, timeout: int = 600) -> dict:
    |         ^^^^^^^^^^^^^^^^
163 |         payload = {
164 |             "workflow_type": workflow_type,
    |

E501 Line too long (130 > 88)
   --> sdk/python/adaptivemind_sdk/client.py:162:89
    |
161 |     # -------------------- Workflows --------------------
162 |     def workflow_execute(self, workflow_type: str, parameters: dict | None = None, priority: int = 1, timeout: int = 600) -> dict:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
163 |         payload = {
164 |             "workflow_type": workflow_type,
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:173:9
    |
171 |         return r.json()
172 |
173 |     def workflow_capabilities(self) -> dict:
    |         ^^^^^^^^^^^^^^^^^^^^^
174 |         r = self._get("/workflows/capabilities")
175 |         r.raise_for_status()
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:178:9
    |
176 |         return r.json()
177 |
178 |     def workflows_active(self) -> dict:
    |         ^^^^^^^^^^^^^^^^
179 |         r = self._get("/workflows/active")
180 |         r.raise_for_status()
    |

E501 Line too long (93 > 88)
   --> sdk/python/adaptivemind_sdk/client.py:184:89
    |
183 |     # -------------------- Jobs --------------------
184 |     def jobs_submit(self, mode: str, payload: dict, callback_url: str | None = None) -> dict:
    |                                                                                         ^^^^^
185 |         """Submit an async job (chat|agent|workflow)."""
186 |         req = {"mode": mode, "payload": payload}
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:193:9
    |
191 |         return r.json()
192 |
193 |     def job_status(self, job_id: str) -> dict:
    |         ^^^^^^^^^^
194 |         r = self._get(f"/jobs/{job_id}")
195 |         r.raise_for_status()
    |

E501 Line too long (118 > 88)
   --> sdk/python/adaptivemind_sdk/client.py:198:89
    |
196 |         return r.json()
197 |
198 |     def jobs_submit_and_wait(self, mode: str, payload: dict, poll_interval: float = 1.0, timeout_s: int = 60) -> dict:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
199 |         """Submit a job and wait for completion (simple poller)."""
200 |         submit = self.jobs_submit(mode, payload)
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:211:9
    |
210 |     # -------------------- Security --------------------
211 |     def security_validate(self, agent_id: str, action: str, context: dict | None = None) -> dict:
    |         ^^^^^^^^^^^^^^^^^
212 |         payload = {"agent_id": agent_id, "action": action, "context": context or {}}
213 |         r = self._post("/security/validate", payload)
    |

E501 Line too long (97 > 88)
   --> sdk/python/adaptivemind_sdk/client.py:211:89
    |
210 |     # -------------------- Security --------------------
211 |     def security_validate(self, agent_id: str, action: str, context: dict | None = None) -> dict:
    |                                                                                         ^^^^^^^^^
212 |         payload = {"agent_id": agent_id, "action": action, "context": context or {}}
213 |         r = self._post("/security/validate", payload)
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:217:9
    |
215 |         return r.json()
216 |
217 |     def security_events(self, limit: int = 100) -> dict:
    |         ^^^^^^^^^^^^^^^
218 |         r = self._get("/security/events", params={"limit": limit})
219 |         r.raise_for_status()
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:222:9
    |
220 |         return r.json()
221 |
222 |     def security_stats(self) -> dict:
    |         ^^^^^^^^^^^^^^
223 |         r = self._get("/security/stats")
224 |         r.raise_for_status()
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:227:9
    |
225 |         return r.json()
226 |
227 |     def security_audit(self) -> dict:
    |         ^^^^^^^^^^^^^^
228 |         r = self._post("/security/audit", {})
229 |         r.raise_for_status()
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:233:9
    |
232 |     # -------------------- Monitoring --------------------
233 |     def monitoring_metrics(self) -> dict:
    |         ^^^^^^^^^^^^^^^^^^
234 |         r = self._get("/monitoring/metrics")
235 |         r.raise_for_status()
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:238:9
    |
236 |         return r.json()
237 |
238 |     def monitoring_summary(self, time_window_minutes: int = 60) -> dict:
    |         ^^^^^^^^^^^^^^^^^^
239 |         r = self._get("/monitoring/summary", params={"time_window_minutes": time_window_minutes})
240 |         r.raise_for_status()
    |

E501 Line too long (97 > 88)
   --> sdk/python/adaptivemind_sdk/client.py:239:89
    |
238 |     def monitoring_summary(self, time_window_minutes: int = 60) -> dict:
239 |         r = self._get("/monitoring/summary", params={"time_window_minutes": time_window_minutes})
    |                                                                                         ^^^^^^^^^
240 |         r.raise_for_status()
241 |         return r.json()
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:243:9
    |
241 |         return r.json()
242 |
243 |     def monitoring_health(self) -> dict:
    |         ^^^^^^^^^^^^^^^^^
244 |         r = self._get("/monitoring/health")
245 |         r.raise_for_status()
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:248:9
    |
246 |         return r.json()
247 |
248 |     def monitoring_performance(self) -> dict:
    |         ^^^^^^^^^^^^^^^^^^^^^^
249 |         r = self._get("/monitoring/performance")
250 |         r.raise_for_status()
    |

D102 Missing docstring in public method
   --> sdk/python/adaptivemind_sdk/client.py:253:9
    |
251 |         return r.json()
252 |
253 |     def monitoring_export(self, format: str = "json") -> dict:
    |         ^^^^^^^^^^^^^^^^^
254 |         r = self._get("/monitoring/export", params={"format": format})
255 |         r.raise_for_status()
    |

D101 Missing docstring in public class
  --> sentence_transformers/__init__.py:23:7
   |
23 | class SentenceTransformer:
   |       ^^^^^^^^^^^^^^^^^^^
24 |     def __init__(self, model_name: str = "dummy"):
25 |         self.model_name = model_name
   |

D102 Missing docstring in public method
  --> sentence_transformers/__init__.py:27:9
   |
25 |         self.model_name = model_name
26 |
27 |     def encode(self, texts, convert_to_tensor: bool = False):
   |         ^^^^^^
28 |         # Return deterministic zero embeddings with small dimension.
29 |         n = len(texts) if hasattr(texts, "__len__") else 1
   |

FBT001 Boolean-typed positional argument in function definition
  --> sentence_transformers/__init__.py:27:29
   |
25 |         self.model_name = model_name
26 |
27 |     def encode(self, texts, convert_to_tensor: bool = False):
   |                             ^^^^^^^^^^^^^^^^^
28 |         # Return deterministic zero embeddings with small dimension.
29 |         n = len(texts) if hasattr(texts, "__len__") else 1
   |

FBT002 Boolean default positional argument in function definition
  --> sentence_transformers/__init__.py:27:29
   |
25 |         self.model_name = model_name
26 |
27 |     def encode(self, texts, convert_to_tensor: bool = False):
   |                             ^^^^^^^^^^^^^^^^^
28 |         # Return deterministic zero embeddings with small dimension.
29 |         n = len(texts) if hasattr(texts, "__len__") else 1
   |

N801 Class name `util` should use CapWords convention
  --> sentence_transformers/__init__.py:37:7
   |
36 | # Provide a lightweight util module with cos_sim
37 | class util:  # pragma: no cover - simple shim
   |       ^^^^
38 |     @staticmethod
39 |     def cos_sim(a, b):
   |

D101 Missing docstring in public class
  --> sentence_transformers/__init__.py:37:7
   |
36 | # Provide a lightweight util module with cos_sim
37 | class util:  # pragma: no cover - simple shim
   |       ^^^^
38 |     @staticmethod
39 |     def cos_sim(a, b):
   |

D102 Missing docstring in public method
  --> sentence_transformers/__init__.py:39:9
   |
37 | class util:  # pragma: no cover - simple shim
38 |     @staticmethod
39 |     def cos_sim(a, b):
   |         ^^^^^^^
40 |         # a, b expected as numpy arrays
41 |         a = np.asarray(a)
   |

E501 Line too long (91 > 88)
  --> tests/_test_server.py:34:89
   |
32 |         },
33 |         allowed_personas=["generalist"],
34 |         monitoring=MonitoringConfig(enable_metrics_harvest=False, harvest_interval_s=60.0),
   |                                                                                         ^^^
35 |     )
36 |     return build_app(config=config)
   |

S112 `try`-`except`-`continue` detected, consider logging the exception
  --> tests/_test_server.py:56:17
   |
54 |                   try:
55 |                       msg = json.loads(msg_text)
56 | /                 except Exception:
57 | |                     continue
   | |____________________________^
58 |                   if msg.get("type") == "ping":
59 |                       await websocket.send_text(json.dumps({"type": "pong"}))
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/_test_server.py:56:24
   |
54 |                 try:
55 |                     msg = json.loads(msg_text)
56 |                 except Exception:
   |                        ^^^^^^^^^
57 |                     continue
58 |                 if msg.get("type") == "ping":
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/_test_server.py:60:16
   |
58 |                 if msg.get("type") == "ping":
59 |                     await websocket.send_text(json.dumps({"type": "pong"}))
60 |         except Exception:
   |                ^^^^^^^^^
61 |             with contextlib.suppress(Exception):
62 |                 await websocket.close()
   |

E501 Line too long (90 > 88)
  --> tests/comprehensive_api_test.py:21:89
   |
19 | Comprehensive AdaptiveMind AI API Testing Suite
20 |
21 | This script performs comprehensive testing of all AdaptiveMind AI API endpoints including:
   |                                                                                         ^^
22 | - Schema validation
23 | - Endpoint functionality testing
   |

E501 Line too long (92 > 88)
  --> tests/comprehensive_api_test.py:74:89
   |
72 |     """Comprehensive API testing suite for AdaptiveMind AI."""
73 |
74 |     def __init__(self, base_url: str = "http://127.0.0.1:8000", api_key: str | None = None):
   |                                                                                         ^^^^
75 |         self.base_url = base_url.rstrip('/')
76 |         self.api_key = api_key
   |

E501 Line too long (92 > 88)
  --> tests/comprehensive_api_test.py:97:89
   |
95 |         return {
96 |             "paths": {
97 |                 "/health": {"get": {"responses": {"200": {"description": "Health check"}}}},
   |                                                                                         ^^^^
98 |                 "/api/v1/models": {"get": {"responses": {"200": {"description": "List models"}}}},
99 |                 "/api/v1/personas": {"get": {"responses": {"200": {"description": "List personas"}}}},
   |

E501 Line too long (98 > 88)
   --> tests/comprehensive_api_test.py:98:89
    |
 96 |             "paths": {
 97 |                 "/health": {"get": {"responses": {"200": {"description": "Health check"}}}},
 98 |                 "/api/v1/models": {"get": {"responses": {"200": {"description": "List models"}}}},
    |                                                                                         ^^^^^^^^^^
 99 |                 "/api/v1/personas": {"get": {"responses": {"200": {"description": "List personas"}}}},
100 |                 "/api/v1/chat": {"post": {"responses": {"200": {"description": "Chat completion"}}}},
    |

E501 Line too long (102 > 88)
   --> tests/comprehensive_api_test.py:99:89
    |
 97 |                 "/health": {"get": {"responses": {"200": {"description": "Health check"}}}},
 98 |                 "/api/v1/models": {"get": {"responses": {"200": {"description": "List models"}}}},
 99 |                 "/api/v1/personas": {"get": {"responses": {"200": {"description": "List personas"}}}},
    |                                                                                         ^^^^^^^^^^^^^^
100 |                 "/api/v1/chat": {"post": {"responses": {"200": {"description": "Chat completion"}}}},
101 |                 "/api/v1/monitoring/metrics": {"get": {"responses": {"200": {"description": "Get metrics"}}}},
    |

E501 Line too long (101 > 88)
   --> tests/comprehensive_api_test.py:100:89
    |
 98 |                 "/api/v1/models": {"get": {"responses": {"200": {"description": "List models"}}}},
 99 |                 "/api/v1/personas": {"get": {"responses": {"200": {"description": "List personas"}}}},
100 |                 "/api/v1/chat": {"post": {"responses": {"200": {"description": "Chat completion"}}}},
    |                                                                                         ^^^^^^^^^^^^^
101 |                 "/api/v1/monitoring/metrics": {"get": {"responses": {"200": {"description": "Get metrics"}}}},
102 |                 "/api/v1/monitoring/traces": {"get": {"responses": {"200": {"description": "Get traces"}}}},
    |

E501 Line too long (110 > 88)
   --> tests/comprehensive_api_test.py:101:89
    |
 99 |                 "/api/v1/personas": {"get": {"responses": {"200": {"description": "List personas"}}}},
100 |                 "/api/v1/chat": {"post": {"responses": {"200": {"description": "Chat completion"}}}},
101 |                 "/api/v1/monitoring/metrics": {"get": {"responses": {"200": {"description": "Get metrics"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
102 |                 "/api/v1/monitoring/traces": {"get": {"responses": {"200": {"description": "Get traces"}}}},
103 |                 "/api/v1/management/system/status": {"get": {"responses": {"200": {"description": "System status"}}}},
    |

E501 Line too long (108 > 88)
   --> tests/comprehensive_api_test.py:102:89
    |
100 |                 "/api/v1/chat": {"post": {"responses": {"200": {"description": "Chat completion"}}}},
101 |                 "/api/v1/monitoring/metrics": {"get": {"responses": {"200": {"description": "Get metrics"}}}},
102 |                 "/api/v1/monitoring/traces": {"get": {"responses": {"200": {"description": "Get traces"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^
103 |                 "/api/v1/management/system/status": {"get": {"responses": {"200": {"description": "System status"}}}},
104 |                 "/api/v1/management/routing/config": {"get": {"responses": {"200": {"description": "Get routing config"}}}},
    |

E501 Line too long (118 > 88)
   --> tests/comprehensive_api_test.py:103:89
    |
101 |                 "/api/v1/monitoring/metrics": {"get": {"responses": {"200": {"description": "Get metrics"}}}},
102 |                 "/api/v1/monitoring/traces": {"get": {"responses": {"200": {"description": "Get traces"}}}},
103 |                 "/api/v1/management/system/status": {"get": {"responses": {"200": {"description": "System status"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
104 |                 "/api/v1/management/routing/config": {"get": {"responses": {"200": {"description": "Get routing config"}}}},
105 |                 "/api/v1/management/config/routing": {"put": {"responses": {"200": {"description": "Update routing config"}}}},
    |

E501 Line too long (124 > 88)
   --> tests/comprehensive_api_test.py:104:89
    |
102 |                 "/api/v1/monitoring/traces": {"get": {"responses": {"200": {"description": "Get traces"}}}},
103 |                 "/api/v1/management/system/status": {"get": {"responses": {"200": {"description": "System status"}}}},
104 |                 "/api/v1/management/routing/config": {"get": {"responses": {"200": {"description": "Get routing config"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
105 |                 "/api/v1/management/config/routing": {"put": {"responses": {"200": {"description": "Update routing config"}}}},
106 |                 "/api/v1/management/backends": {"get": {"responses": {"200": {"description": "List backends"}}}},
    |

E501 Line too long (127 > 88)
   --> tests/comprehensive_api_test.py:105:89
    |
103 |                 "/api/v1/management/system/status": {"get": {"responses": {"200": {"description": "System status"}}}},
104 |                 "/api/v1/management/routing/config": {"get": {"responses": {"200": {"description": "Get routing config"}}}},
105 |                 "/api/v1/management/config/routing": {"put": {"responses": {"200": {"description": "Update routing config"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
106 |                 "/api/v1/management/backends": {"get": {"responses": {"200": {"description": "List backends"}}}},
107 |                 "/api/v1/management/backends/{name}/test": {"post": {"responses": {"200": {"description": "Test backend"}}}},
    |

E501 Line too long (113 > 88)
   --> tests/comprehensive_api_test.py:106:89
    |
104 |                 "/api/v1/management/routing/config": {"get": {"responses": {"200": {"description": "Get routing config"}}}},
105 |                 "/api/v1/management/config/routing": {"put": {"responses": {"200": {"description": "Update routing config"}}}},
106 |                 "/api/v1/management/backends": {"get": {"responses": {"200": {"description": "List backends"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^
107 |                 "/api/v1/management/backends/{name}/test": {"post": {"responses": {"200": {"description": "Test backend"}}}},
108 |                 "/api/v1/management/context/config": {"get": {"responses": {"200": {"description": "Get context config"}}}},
    |

E501 Line too long (125 > 88)
   --> tests/comprehensive_api_test.py:107:89
    |
105 |                 "/api/v1/management/config/routing": {"put": {"responses": {"200": {"description": "Update routing config"}}}},
106 |                 "/api/v1/management/backends": {"get": {"responses": {"200": {"description": "List backends"}}}},
107 |                 "/api/v1/management/backends/{name}/test": {"post": {"responses": {"200": {"description": "Test backend"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
108 |                 "/api/v1/management/context/config": {"get": {"responses": {"200": {"description": "Get context config"}}}},
109 |                 "/api/v1/management/config/context": {"put": {"responses": {"200": {"description": "Update context config"}}}},
    |

E501 Line too long (124 > 88)
   --> tests/comprehensive_api_test.py:108:89
    |
106 |                 "/api/v1/management/backends": {"get": {"responses": {"200": {"description": "List backends"}}}},
107 |                 "/api/v1/management/backends/{name}/test": {"post": {"responses": {"200": {"description": "Test backend"}}}},
108 |                 "/api/v1/management/context/config": {"get": {"responses": {"200": {"description": "Get context config"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
109 |                 "/api/v1/management/config/context": {"put": {"responses": {"200": {"description": "Update context config"}}}},
110 |                 "/api/v1/management/security/status": {"get": {"responses": {"200": {"description": "Get security status"}}}},
    |

E501 Line too long (127 > 88)
   --> tests/comprehensive_api_test.py:109:89
    |
107 |                 "/api/v1/management/backends/{name}/test": {"post": {"responses": {"200": {"description": "Test backend"}}}},
108 |                 "/api/v1/management/context/config": {"get": {"responses": {"200": {"description": "Get context config"}}}},
109 |                 "/api/v1/management/config/context": {"put": {"responses": {"200": {"description": "Update context config"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
110 |                 "/api/v1/management/security/status": {"get": {"responses": {"200": {"description": "Get security status"}}}},
111 |                 "/api/v1/management/personas": {"post": {"responses": {"200": {"description": "Create persona"}}}},
    |

E501 Line too long (126 > 88)
   --> tests/comprehensive_api_test.py:110:89
    |
108 |                 "/api/v1/management/context/config": {"get": {"responses": {"200": {"description": "Get context config"}}}},
109 |                 "/api/v1/management/config/context": {"put": {"responses": {"200": {"description": "Update context config"}}}},
110 |                 "/api/v1/management/security/status": {"get": {"responses": {"200": {"description": "Get security status"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
111 |                 "/api/v1/management/personas": {"post": {"responses": {"200": {"description": "Create persona"}}}},
112 |                 "/api/v1/management/personas/{name}": {
    |

E501 Line too long (115 > 88)
   --> tests/comprehensive_api_test.py:111:89
    |
109 |                 "/api/v1/management/config/context": {"put": {"responses": {"200": {"description": "Update context config"}}}},
110 |                 "/api/v1/management/security/status": {"get": {"responses": {"200": {"description": "Get security status"}}}},
111 |                 "/api/v1/management/personas": {"post": {"responses": {"200": {"description": "Create persona"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
112 |                 "/api/v1/management/personas/{name}": {
113 |                     "put": {"responses": {"200": {"description": "Update persona"}}},
    |

E501 Line too long (115 > 88)
   --> tests/comprehensive_api_test.py:116:89
    |
114 |                     "delete": {"responses": {"200": {"description": "Delete persona"}}}
115 |                 },
116 |                 "/api/v1/management/config/save": {"post": {"responses": {"200": {"description": "Save config"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
117 |                 "/v1/chat/completions": {"post": {"responses": {"200": {"description": "OpenAI chat completions"}}}},
118 |                 "/v1/models": {"get": {"responses": {"200": {"description": "OpenAI models list"}}}}
    |

E501 Line too long (117 > 88)
   --> tests/comprehensive_api_test.py:117:89
    |
115 |                 },
116 |                 "/api/v1/management/config/save": {"post": {"responses": {"200": {"description": "Save config"}}}},
117 |                 "/v1/chat/completions": {"post": {"responses": {"200": {"description": "OpenAI chat completions"}}}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
118 |                 "/v1/models": {"get": {"responses": {"200": {"description": "OpenAI models list"}}}}
119 |             }
    |

E501 Line too long (100 > 88)
   --> tests/comprehensive_api_test.py:118:89
    |
116 |                 "/api/v1/management/config/save": {"post": {"responses": {"200": {"description": "Save config"}}}},
117 |                 "/v1/chat/completions": {"post": {"responses": {"200": {"description": "OpenAI chat completions"}}}},
118 |                 "/v1/models": {"get": {"responses": {"200": {"description": "OpenAI models list"}}}}
    |                                                                                         ^^^^^^^^^^^^
119 |             }
120 |         }
    |

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
   --> tests/comprehensive_api_test.py:154:17
    |
153 |                   # Try to read response
154 | /                 try:
155 | |                     await response.json()
156 | |                 except:
157 | |                     pass  # Response might not be JSON
    | |________________________^
158 |
159 |                   success = expected_status is None or response.status == expected_status
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
   --> tests/comprehensive_api_test.py:156:17
    |
154 |                 try:
155 |                     await response.json()
156 |                 except:
    |                 ^^^^^^
157 |                     pass  # Response might not be JSON
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> tests/comprehensive_api_test.py:156:17
    |
154 |                   try:
155 |                       await response.json()
156 | /                 except:
157 | |                     pass  # Response might not be JSON
    | |________________________^
158 |
159 |                   success = expected_status is None or response.status == expected_status
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/comprehensive_api_test.py:171:16
    |
169 |                 )
170 |
171 |         except Exception as e:
    |                ^^^^^^^^^
172 |             response_time = (time.time() - start_time) * 1000
173 |             return TestResult(
    |

E501 Line too long (101 > 88)
   --> tests/comprehensive_api_test.py:213:89
    |
211 |             "max_tokens": 100
212 |         }
213 |         result = await self.make_request("POST", "/api/v1/chat", data=chat_data, expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^
214 |         results.append(result)
    |

E501 Line too long (109 > 88)
   --> tests/comprehensive_api_test.py:223:89
    |
221 |             "max_tokens": 100
222 |         }
223 |         result = await self.make_request("POST", "/api/v1/chat", data=chat_data_invalid, expected_status=400)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^
224 |         results.append(result)
    |

E501 Line too long (98 > 88)
   --> tests/comprehensive_api_test.py:233:89
    |
232 |         # Test metrics endpoint
233 |         result = await self.make_request("GET", "/api/v1/monitoring/metrics", expected_status=200)
    |                                                                                         ^^^^^^^^^^
234 |         results.append(result)
    |

E501 Line too long (97 > 88)
   --> tests/comprehensive_api_test.py:237:89
    |
236 |         # Test traces endpoint
237 |         result = await self.make_request("GET", "/api/v1/monitoring/traces", expected_status=200)
    |                                                                                         ^^^^^^^^^
238 |         results.append(result)
    |

E501 Line too long (104 > 88)
   --> tests/comprehensive_api_test.py:247:89
    |
246 |         # System status
247 |         result = await self.make_request("GET", "/api/v1/management/system/status", expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^^
248 |         results.append(result)
    |

E501 Line too long (105 > 88)
   --> tests/comprehensive_api_test.py:251:89
    |
250 |         # Routing config
251 |         result = await self.make_request("GET", "/api/v1/management/routing/config", expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^^^
252 |         results.append(result)
    |

E501 Line too long (92 > 88)
   --> tests/comprehensive_api_test.py:255:89
    |
254 |         # Update routing config
255 |         routing_data = {"allowed_personas": ["generalist"], "enable_adaptive_routing": True}
    |                                                                                         ^^^^
256 |         result = await self.make_request("PUT", "/api/v1/management/config/routing", data=routing_data, expected_status=200)
257 |         results.append(result)
    |

E501 Line too long (124 > 88)
   --> tests/comprehensive_api_test.py:256:89
    |
254 |         # Update routing config
255 |         routing_data = {"allowed_personas": ["generalist"], "enable_adaptive_routing": True}
256 |         result = await self.make_request("PUT", "/api/v1/management/config/routing", data=routing_data, expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
257 |         results.append(result)
    |

E501 Line too long (99 > 88)
   --> tests/comprehensive_api_test.py:260:89
    |
259 |         # List backends
260 |         result = await self.make_request("GET", "/api/v1/management/backends", expected_status=200)
    |                                                                                         ^^^^^^^^^^^
261 |         results.append(result)
    |

E501 Line too long (112 > 88)
   --> tests/comprehensive_api_test.py:264:89
    |
263 |         # Test backend (will likely fail if backend doesn't exist, but test structure)
264 |         result = await self.make_request("POST", "/api/v1/management/backends/ollama/test", expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^
265 |         results.append(result)
    |

E501 Line too long (105 > 88)
   --> tests/comprehensive_api_test.py:268:89
    |
267 |         # Context config
268 |         result = await self.make_request("GET", "/api/v1/management/context/config", expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^^^
269 |         results.append(result)
    |

E501 Line too long (94 > 88)
   --> tests/comprehensive_api_test.py:272:89
    |
271 |         # Update context config
272 |         context_data = {"enable_semantic_chunking": True, "max_combined_context_tokens": 8192}
    |                                                                                         ^^^^^^
273 |         result = await self.make_request("PUT", "/api/v1/management/config/context", data=context_data, expected_status=200)
274 |         results.append(result)
    |

E501 Line too long (124 > 88)
   --> tests/comprehensive_api_test.py:273:89
    |
271 |         # Update context config
272 |         context_data = {"enable_semantic_chunking": True, "max_combined_context_tokens": 8192}
273 |         result = await self.make_request("PUT", "/api/v1/management/config/context", data=context_data, expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
274 |         results.append(result)
    |

E501 Line too long (106 > 88)
   --> tests/comprehensive_api_test.py:277:89
    |
276 |         # Security status
277 |         result = await self.make_request("GET", "/api/v1/management/security/status", expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^^^^
278 |         results.append(result)
    |

E501 Line too long (119 > 88)
   --> tests/comprehensive_api_test.py:288:89
    |
286 |             "routing_hint": "test"
287 |         }
288 |         result = await self.make_request("POST", "/api/v1/management/personas", data=persona_data, expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
289 |         results.append(result)
    |

E501 Line too long (130 > 88)
   --> tests/comprehensive_api_test.py:293:89
    |
291 |         # Update persona
292 |         update_data = {"description": "Updated test persona"}
293 |         result = await self.make_request("PUT", "/api/v1/management/personas/test-persona", data=update_data, expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
294 |         results.append(result)
    |

E501 Line too long (115 > 88)
   --> tests/comprehensive_api_test.py:297:89
    |
296 |         # Delete persona
297 |         result = await self.make_request("DELETE", "/api/v1/management/personas/test-persona", expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
298 |         results.append(result)
    |

E501 Line too long (103 > 88)
   --> tests/comprehensive_api_test.py:301:89
    |
300 |         # Save config
301 |         result = await self.make_request("POST", "/api/v1/management/config/save", expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^
302 |         results.append(result)
    |

E501 Line too long (111 > 88)
   --> tests/comprehensive_api_test.py:317:89
    |
315 |             "max_tokens": 100
316 |         }
317 |         result = await self.make_request("POST", "/v1/chat/completions", data=openai_data, expected_status=200)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
318 |         results.append(result)
    |

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
   --> tests/comprehensive_api_test.py:333:13
    |
331 |           if self.api_key:
332 |               # Test with invalid API key
333 | /             async with aiohttp.ClientSession() as session:
334 | |                 async with session.get(f"{self.base_url}/api/v1/personas") as response:
    | |_______________________________________________________________________________________^
335 |                       if response.status == 401:
336 |                           results.append(TestResult(
    |
help: Combine `with` statements

E501 Line too long (109 > 88)
   --> tests/comprehensive_api_test.py:353:89
    |
351 |             "max_tokens": -1     # Invalid max_tokens
352 |         }
353 |         result = await self.make_request("POST", "/api/v1/chat", data=invalid_chat_data, expected_status=422)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^
354 |         results.append(result)
    |

E501 Line too long (93 > 88)
   --> tests/comprehensive_api_test.py:363:89
    |
362 |         # Test invalid endpoint
363 |         result = await self.make_request("GET", "/nonexistent/endpoint", expected_status=404)
    |                                                                                         ^^^^^
364 |         results.append(result)
    |

E501 Line too long (90 > 88)
   --> tests/comprehensive_api_test.py:367:89
    |
366 |         # Test invalid HTTP method
367 |         result = await self.make_request("PATCH", "/api/v1/personas", expected_status=405)
    |                                                                                         ^^
368 |         results.append(result)
    |

E501 Line too long (97 > 88)
   --> tests/comprehensive_api_test.py:374:89
    |
372 |             async with self.session.post(f"{self.base_url}/api/v1/chat",
373 |                                        data="invalid json",
374 |                                        headers={"Content-Type": "application/json"}) as response:
    |                                                                                         ^^^^^^^^^
375 |                 response_time = 100  # Mock response time
376 |                 results.append(TestResult(
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/comprehensive_api_test.py:385:16
    |
383 |                     expected_status=400
384 |                 ))
385 |         except Exception as e:
    |                ^^^^^^^^^
386 |             results.append(TestResult(
387 |                 test_name="Error: Malformed JSON",
    |

E501 Line too long (92 > 88)
   --> tests/comprehensive_api_test.py:398:89
    |
396 |         return results
397 |
398 |     async def test_performance_concurrent(self, num_requests: int = 10) -> list[TestResult]:
    |                                                                                         ^^^^
399 |         """Test performance with concurrent requests."""
400 |         results = []
    |

E501 Line too long (91 > 88)
   --> tests/comprehensive_api_test.py:406:89
    |
404 |         for i in range(num_requests):
405 |             chat_data = {
406 |                 "messages": [{"role": "user", "content": f"Performance test message {i}"}],
    |                                                                                         ^^^
407 |                 "persona": "generalist",
408 |                 "temperature": 0.7,
    |

E501 Line too long (97 > 88)
   --> tests/comprehensive_api_test.py:411:89
    |
409 |                 "max_tokens": 50
410 |             }
411 |             task = self.make_request("POST", "/api/v1/chat", data=chat_data, expected_status=200)
    |                                                                                         ^^^^^^^^^
412 |             tasks.append(task)
    |

E501 Line too long (105 > 88)
   --> tests/comprehensive_api_test.py:429:89
    |
427 |                 avg_response_time=statistics.mean(response_times),
428 |                 median_response_time=statistics.median(response_times),
429 |                 success_rate=len([r for r in concurrent_results if r.success]) / len(concurrent_results),
    |                                                                                         ^^^^^^^^^^^^^^^^^
430 |                 total_requests=len(concurrent_results),
431 |                 successful_requests=len([r for r in concurrent_results if r.success])
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> tests/comprehensive_api_test.py:463:13
    |
461 |                   len(suite_results)
462 |
463 | /             except Exception:
464 | |                 pass
    | |____________________^
465 |
466 |           return self.generate_test_report()
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/comprehensive_api_test.py:463:20
    |
461 |                 len(suite_results)
462 |
463 |             except Exception:
    |                    ^^^^^^^^^
464 |                 pass
    |

E501 Line too long (89 > 88)
   --> tests/comprehensive_api_test.py:482:89
    |
480 |                 "successful_tests": successful_tests,
481 |                 "failed_tests": failed_tests,
482 |                 "success_rate": successful_tests / total_tests if total_tests > 0 else 0,
    |                                                                                         ^
483 |                 "total_response_time_ms": sum(response_times),
484 |                 "avg_response_time_ms": statistics.mean(response_times) if response_times else 0
    |

E501 Line too long (96 > 88)
   --> tests/comprehensive_api_test.py:484:89
    |
482 |                 "success_rate": successful_tests / total_tests if total_tests > 0 else 0,
483 |                 "total_response_time_ms": sum(response_times),
484 |                 "avg_response_time_ms": statistics.mean(response_times) if response_times else 0
    |                                                                                         ^^^^^^^^
485 |             },
486 |             "test_results": [asdict(r) for r in self.test_results],
    |

E501 Line too long (93 > 88)
   --> tests/comprehensive_api_test.py:505:89
    |
503 | async def main():
504 |     """Main testing function."""
505 |     parser = argparse.ArgumentParser(description="Comprehensive AdaptiveMind AI API Testing")
    |                                                                                         ^^^^^
506 |     parser.add_argument("--server-url", default="http://127.0.0.1:8000", help="Server URL")
507 |     parser.add_argument("--api-key", help="API key for authentication")
    |

E501 Line too long (91 > 88)
   --> tests/comprehensive_api_test.py:506:89
    |
504 |     """Main testing function."""
505 |     parser = argparse.ArgumentParser(description="Comprehensive AdaptiveMind AI API Testing")
506 |     parser.add_argument("--server-url", default="http://127.0.0.1:8000", help="Server URL")
    |                                                                                         ^^^
507 |     parser.add_argument("--api-key", help="API key for authentication")
508 |     parser.add_argument("--output", default="test_report.json", help="Output file for test report")
    |

E501 Line too long (99 > 88)
   --> tests/comprehensive_api_test.py:508:89
    |
506 |     parser.add_argument("--server-url", default="http://127.0.0.1:8000", help="Server URL")
507 |     parser.add_argument("--api-key", help="API key for authentication")
508 |     parser.add_argument("--output", default="test_report.json", help="Output file for test report")
    |                                                                                         ^^^^^^^^^^^
509 |
510 |     args = parser.parse_args()
    |

E501 Line too long (89 > 88)
   --> tests/comprehensive_api_test.py:512:89
    |
510 |     args = parser.parse_args()
511 |
512 |     async with JarvisAPITester(base_url=args.server_url, api_key=args.api_key) as tester:
    |                                                                                         ^
513 |         report = await tester.run_all_tests()
514 |         tester.save_report(report, args.output)
    |

E501 Line too long (123 > 88)
  --> tests/comprehensive_endpoint_test.py:19:89
   |
17 |         self.results = {}
18 |
19 |     def test_endpoint(self, method: str, endpoint: str, data: dict | None = None, description: str = "") -> dict[str, Any]:
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
20 |         """Test a single endpoint and capture response"""
21 |         url = f"{self.base_url}{endpoint}"
   |

S113 Probable use of `requests` call without timeout
  --> tests/comprehensive_endpoint_test.py:25:28
   |
23 |         try:
24 |             if method.upper() == "GET":
25 |                 response = requests.get(url)
   |                            ^^^^^^^^^^^^
26 |             elif method.upper() == "POST":
27 |                 response = requests.post(url, json=data)
   |

S113 Probable use of `requests` call without timeout
  --> tests/comprehensive_endpoint_test.py:27:28
   |
25 |                 response = requests.get(url)
26 |             elif method.upper() == "POST":
27 |                 response = requests.post(url, json=data)
   |                            ^^^^^^^^^^^^^
28 |             elif method.upper() == "PUT":
29 |                 response = requests.put(url, json=data)
   |

S113 Probable use of `requests` call without timeout
  --> tests/comprehensive_endpoint_test.py:29:28
   |
27 |                 response = requests.post(url, json=data)
28 |             elif method.upper() == "PUT":
29 |                 response = requests.put(url, json=data)
   |                            ^^^^^^^^^^^^
30 |             elif method.upper() == "DELETE":
31 |                 response = requests.delete(url)
   |

S113 Probable use of `requests` call without timeout
  --> tests/comprehensive_endpoint_test.py:31:28
   |
29 |                 response = requests.put(url, json=data)
30 |             elif method.upper() == "DELETE":
31 |                 response = requests.delete(url)
   |                            ^^^^^^^^^^^^^^^
32 |             else:
33 |                 raise ValueError(f"Unsupported method: {method}")
   |

E501 Line too long (138 > 88)
  --> tests/comprehensive_endpoint_test.py:38:89
   |
36 | â€¦     "status_code": response.status_code,
37 | â€¦     "success": response.status_code < 400,
38 | â€¦     "response": response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text,
   |                                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
39 | â€¦     "headers": dict(response.headers),
40 | â€¦     "description": description,
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/comprehensive_endpoint_test.py:46:16
   |
44 |             return result
45 |
46 |         except Exception as e:
   |                ^^^^^^^^^
47 |             result = {
48 |                 "status_code": 0,
   |

E501 Line too long (106 > 88)
  --> tests/comprehensive_endpoint_test.py:60:89
   |
59 |         # 1. Health & Status
60 |         self.results["health"] = self.test_endpoint("GET", "/health", description="Health check endpoint")
   |                                                                                         ^^^^^^^^^^^^^^^^^^
61 |
62 |         # 2. Core API - Models
   |

E501 Line too long (113 > 88)
  --> tests/comprehensive_endpoint_test.py:63:89
   |
62 |         # 2. Core API - Models
63 |         self.results["models"] = self.test_endpoint("GET", "/api/v1/models", description="List available models")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^
64 |
65 |         # 3. Core API - Personas
   |

E501 Line too long (120 > 88)
  --> tests/comprehensive_endpoint_test.py:66:89
   |
65 |         # 3. Core API - Personas
66 |         self.results["personas"] = self.test_endpoint("GET", "/api/v1/personas", description="List configured personas")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
67 |
68 |         # 4. Core API - Chat (Test 1)
   |

E501 Line too long (127 > 88)
  --> tests/comprehensive_endpoint_test.py:75:89
   |
73 |             "max_tokens": 100
74 |         }
75 |         self.results["chat_basic"] = self.test_endpoint("POST", "/api/v1/chat", chat_data, description="Basic chat completion")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
76 |
77 |         # 5. Core API - Chat (Test 2 - Complex)
   |

E501 Line too long (136 > 88)
  --> tests/comprehensive_endpoint_test.py:90:89
   |
88 | â€¦wn as the City of Light"]
89 | â€¦
90 | â€¦st_endpoint("POST", "/api/v1/chat", chat_complex, description="Complex chat with context")
   |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
91 | â€¦
92 | â€¦y implements a subset of endpoints
   |

E501 Line too long (91 > 88)
   --> tests/comprehensive_endpoint_test.py:110:89
    |
108 | â€¦     # Summary
109 | â€¦     total_tests = len(self.results)
110 | â€¦     successful_tests = sum(1 for r in self.results.values() if r.get('success', False))
    |                                                                                       ^^^
111 | â€¦     report += f"## Summary\n- **Total Tests**: {total_tests}\n- **Successful**: {successful_tests}\n- **Failed**: {total_tests - suâ€¦
    |

E501 Line too long (218 > 88)
   --> tests/comprehensive_endpoint_test.py:111:89
    |
109 | â€¦
110 | â€¦ False))
111 | â€¦ {successful_tests}\n- **Failed**: {total_tests - successful_tests}\n- **Success Rate**: {(successful_tests/total_tests)*100:.1f}%\n\n"
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
112 | â€¦
113 | â€¦
    |

E501 Line too long (97 > 88)
   --> tests/comprehensive_endpoint_test.py:118:87
    |
116 |         for endpoint_name, result in self.results.items():
117 |             report += f"### {endpoint_name.replace('_', ' ').title()}\n"
118 |             report += f"- **Status**: {'âœ… Success' if result.get('success') else 'âŒ Failed'}\n"
    |                                                                                         ^^^^^^^^^
119 |             if result.get('status_code'):
120 |                 report += f"- **HTTP Status**: {result['status_code']}\n"
    |

E501 Line too long (105 > 88)
   --> tests/comprehensive_endpoint_test.py:125:89
    |
124 |             if result.get('response'):
125 |                 report += f"- **Response**: \n```json\n{json.dumps(result['response'], indent=2)}\n```\n"
    |                                                                                         ^^^^^^^^^^^^^^^^^
126 |
127 |             if result.get('error'):
    |

N818 Exception name `ServiceUnavailable` should be named with an Error suffix
  --> tests/conftest.py:39:7
   |
39 | class ServiceUnavailable(Exception):
   |       ^^^^^^^^^^^^^^^^^^
40 |     pass
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/conftest.py:97:8
   |
95 | try:
96 |     pass  # type: ignore
97 | except Exception:
   |        ^^^^^^^^^
98 |     # Minimal fallback when pydantic is not available in the test
99 |     # environment (keeps tests fast and avoids hard dependency in some dev setups).
   |

N802 Function name `Field` should be lowercase
   --> tests/conftest.py:107:9
    |
107 |     def Field(*args, **kwargs):
    |         ^^^^^
108 |         return None
    |

E501 Line too long (91 > 88)
   --> tests/conftest.py:122:89
    |
120 |     sys.modules.setdefault("pydantic", pydantic_module)
121 |
122 |     # Minimal config loader shim for legacy imports (e.g. config.config_loader.load_config)
    |                                                                                         ^^^
123 |     config_module = types.ModuleType("config")
124 |     config_loader_module = types.ModuleType("config.config_loader")
    |

FBT002 Boolean default positional argument in function definition
   --> tests/conftest.py:165:21
    |
163 |         self._edges.setdefault(s, []).append((t, attrs))
164 |
165 |     def nodes(self, data=False):
    |                     ^^^^
166 |         return list(self._nodes.items()) if data else list(self._nodes.keys())
    |

FBT002 Boolean default positional argument in function definition
   --> tests/conftest.py:168:21
    |
166 |         return list(self._nodes.items()) if data else list(self._nodes.keys())
167 |
168 |     def edges(self, data=False):
    |                     ^^^^
169 |         edges = []
170 |         for s, lst in self._edges.items():
    |

FBT002 Boolean default positional argument in function definition
   --> tests/conftest.py:175:31
    |
173 |         return edges
174 |
175 |     def out_edges(self, node, data=False):
    |                               ^^^^
176 |         lst = self._edges.get(node, [])
177 |         return [(node, t, attrs) if data else (node, t) for t, attrs in lst]
    |

N818 Exception name `RequestException` should be named with an Error suffix
   --> tests/conftest.py:210:7
    |
208 | exceptions_module = types.ModuleType("requests.exceptions")
209 |
210 | class RequestException(Exception):
    |       ^^^^^^^^^^^^^^^^
211 |     pass
    |

S310 Audit URL open for permitted schemes. Allowing use of `file:` or custom schemes is often unexpected.
   --> tests/conftest.py:513:19
    |
511 |     def _is_up(url: str) -> bool:
512 |         try:
513 |             req = urllib.request.Request(url.rstrip("/") + "/")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
514 |             with urllib.request.urlopen(req, timeout=1) as resp:
515 |                 return resp.status == 200
    |

S310 Audit URL open for permitted schemes. Allowing use of `file:` or custom schemes is often unexpected.
   --> tests/conftest.py:514:18
    |
512 |         try:
513 |             req = urllib.request.Request(url.rstrip("/") + "/")
514 |             with urllib.request.urlopen(req, timeout=1) as resp:
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
515 |                 return resp.status == 200
516 |         except Exception:
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/conftest.py:516:16
    |
514 |             with urllib.request.urlopen(req, timeout=1) as resp:
515 |                 return resp.status == 200
516 |         except Exception:
    |                ^^^^^^^^^
517 |             return False
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/conftest.py:540:16
    |
538 |         try:
539 |             proc.wait(timeout=3)
540 |         except Exception:
    |                ^^^^^^^^^
541 |             proc.kill()
    |

E501 Line too long (93 > 88)
   --> tests/contract_tests/conftest.py:189:89
    |
187 |     """Define severity levels for contract violations."""
188 |     return {
189 |         'CRITICAL': ['Missing required fields', 'Invalid data types', 'Security violations'],
    |                                                                                         ^^^^^
190 |         'HIGH': ['Performance threshold exceeded', 'Response format changes'],
191 |         'MEDIUM': ['Optional field missing', 'Response time degradation'],
    |

E501 Line too long (92 > 88)
  --> tests/contract_tests/test_api_contracts.py:32:89
   |
30 |     """Main class for API contract testing and validation."""
31 |
32 |     def __init__(self, base_url: str = "http://127.0.0.1:8000", api_key: str | None = None):
   |                                                                                         ^^^^
33 |         self.base_url = base_url.rstrip('/')
34 |         self.api_key = api_key
   |

E501 Line too long (97 > 88)
  --> tests/contract_tests/test_api_contracts.py:65:89
   |
63 |             path_item = self.openapi_spec['paths'].get(endpoint)
64 |             if not path_item:
65 |                 violations.append(f"No OpenAPI definition found for {method.upper()} {endpoint}")
   |                                                                                         ^^^^^^^^^
66 |                 return {'valid': False, 'violations': violations}
   |

E501 Line too long (91 > 88)
  --> tests/contract_tests/test_api_contracts.py:71:89
   |
69 |             method_def = path_item.get(method.lower())
70 |             if not method_def:
71 |                 violations.append(f"No OpenAPI definition for {method.upper()} {endpoint}")
   |                                                                                         ^^^
72 |                 return {'valid': False, 'violations': violations}
   |

E501 Line too long (89 > 88)
  --> tests/contract_tests/test_api_contracts.py:77:89
   |
75 |             responses_def = method_def.get('responses', {})
76 |             if str(status_code) not in responses_def and status_code >= 400:
77 |                 # 4xx/5xx responses are generally acceptable without specific definitions
   |                                                                                         ^
78 |                 pass
79 |             elif str(status_code) not in responses_def:
   |

E501 Line too long (108 > 88)
  --> tests/contract_tests/test_api_contracts.py:80:89
   |
78 |                 pass
79 |             elif str(status_code) not in responses_def:
80 |                 violations.append(f"Undocumented status code {status_code} for {method.upper()} {endpoint}")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^
81 |
82 |             # Validate response schema
   |

E501 Line too long (96 > 88)
  --> tests/contract_tests/test_api_contracts.py:84:89
   |
82 |             # Validate response schema
83 |             if 'content' in responses_def.get(str(status_code), {}):
84 |                 content_def = responses_def[str(status_code)]['content'].get('application/json')
   |                                                                                         ^^^^^^^^
85 |                 if content_def and 'schema' in content_def:
86 |                     try:
   |

E501 Line too long (96 > 88)
  --> tests/contract_tests/test_api_contracts.py:97:89
   |
96 |             # Validate business rules
97 |             business_violations = self._validate_business_rules(endpoint, method, response_data)
   |                                                                                         ^^^^^^^^
98 |             violations.extend(business_violations)
   |

BLE001 Do not catch blind exception: `Exception`
   --> tests/contract_tests/test_api_contracts.py:100:16
    |
 98 |             violations.extend(business_violations)
 99 |
100 |         except Exception as e:
    |                ^^^^^^^^^
101 |             violations.append(f"Contract validation error: {e!s}")
    |

E501 Line too long (111 > 88)
   --> tests/contract_tests/test_api_contracts.py:115:89
    |
113 |         return {}
114 |
115 |     def _validate_business_rules(self, endpoint: str, method: str, response_data: dict[str, Any]) -> list[str]:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
116 |         """Validate business rules specific to each endpoint."""
117 |         violations = []
    |

E501 Line too long (136 > 88)
   --> tests/contract_tests/test_api_contracts.py:241:89
    |
240 | â€¦
241 | â€¦d'], f"Contract violations for {test_case['endpoint']}: {validation_result['violations']}"
    |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
242 | â€¦
243 | â€¦
    |

E501 Line too long (150 > 88)
   --> tests/contract_tests/test_api_contracts.py:291:89
    |
290 | â€¦ range
291 | â€¦ed_status'] if isinstance(test_case['expected_status'], list) else [test_case['expected_status']]
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
292 | â€¦ed_statuses, f"Unexpected status {response.status_code} for {test_case['name']}"
    |

E501 Line too long (133 > 88)
   --> tests/contract_tests/test_api_contracts.py:292:89
    |
290 | â€¦     # Check if status code is in expected range
291 | â€¦     expected_statuses = test_case['expected_status'] if isinstance(test_case['expected_status'], list) else [test_case['expected_stâ€¦
292 | â€¦     assert response.status_code in expected_statuses, f"Unexpected status {response.status_code} for {test_case['name']}"
    |                                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |

E501 Line too long (98 > 88)
  --> tests/contract_tests/test_integration_contracts.py:15:89
   |
14 | This module implements comprehensive integration testing for API endpoints,
15 | including database state validation, external dependency mocking, and end-to-end contract testing.
   |                                                                                         ^^^^^^^^^^
16 | """
   |

E501 Line too long (92 > 88)
  --> tests/contract_tests/test_integration_contracts.py:28:89
   |
26 |     """Integration contract testing and validation."""
27 |
28 |     def __init__(self, base_url: str = "http://127.0.0.1:8000", api_key: str | None = None):
   |                                                                                         ^^^^
29 |         self.base_url = base_url.rstrip('/')
30 |         self.api_key = api_key
   |

E501 Line too long (131 > 88)
  --> tests/contract_tests/test_integration_contracts.py:35:89
   |
33 |         self.external_mocks = {}
34 |
35 |     async def mock_external_service(self, service_name: str, endpoint: str, response_data: dict[str, Any], status_code: int = 200):
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
36 |         """Mock external service for testing."""
37 |         self.external_mocks[service_name] = {
   |

E501 Line too long (128 > 88)
  --> tests/contract_tests/test_integration_contracts.py:43:89
   |
41 |         }
42 |
43 |     async def validate_database_state_after_chat(self, chat_request: dict[str, Any], expected_changes: list[str] | None = None):
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
44 |         """Validate database state changes after chat operation."""
   |

E501 Line too long (92 > 88)
  --> tests/contract_tests/test_integration_contracts.py:64:89
   |
63 |         for check in expected_checks:
64 |             # Simulate validation - in real implementation, this would query actual database
   |                                                                                         ^^^^
65 |             validation_results['validations'].append({
66 |                 'check': check,
   |

E501 Line too long (97 > 88)
  --> tests/contract_tests/test_integration_contracts.py:74:89
   |
72 |         return validation_results
73 |
74 |     async def validate_workflow_state_after_agent_execution(self, agent_request: dict[str, Any]):
   |                                                                                         ^^^^^^^^^
75 |         """Validate workflow and state changes after agent execution."""
   |

E501 Line too long (94 > 88)
   --> tests/contract_tests/test_integration_contracts.py:132:89
    |
131 |             # Validate response
132 |             assert response.status_code == 200, f"Chat request failed: {response.status_code}"
    |                                                                                         ^^^^^^
133 |
134 |             step_result = {
    |

E501 Line too long (103 > 88)
   --> tests/contract_tests/test_integration_contracts.py:147:89
    |
145 |                 'step': 'database_state_validation',
146 |                 'status': 'passed',
147 |                 'details': f"Database validation completed: {len(db_validation['validations'])} checks"
    |                                                                                         ^^^^^^^^^^^^^^^
148 |             })
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/contract_tests/test_integration_contracts.py:161:16
    |
159 |             })
160 |
161 |         except Exception as e:
    |                ^^^^^^^^^
162 |             results['success'] = False
163 |             results['error'] = str(e)
    |

E501 Line too long (92 > 88)
   --> tests/contract_tests/test_integration_contracts.py:178:89
    |
176 |             '/v1/chat/completions',
177 |             {
178 |                 'choices': [{'message': {'content': 'Test response', 'role': 'assistant'}}],
    |                                                                                         ^^^^
179 |                 'model': 'test-model',
180 |                 'usage': {'total_tokens': 10}
    |

E501 Line too long (101 > 88)
   --> tests/contract_tests/test_integration_contracts.py:216:89
    |
214 |         }
215 |
216 |     async def test_concurrent_request_handling(self, concurrent_requests: int = 5) -> dict[str, Any]:
    |                                                                                         ^^^^^^^^^^^^^
217 |         """Test system behavior under concurrent requests."""
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/contract_tests/test_integration_contracts.py:240:20
    |
238 |                     'success': response.status_code == 200
239 |                 }
240 |             except Exception as e:
    |                    ^^^^^^^^^
241 |                 return {
242 |                     'request_id': request_id,
    |

E501 Line too long (101 > 88)
   --> tests/contract_tests/test_integration_contracts.py:252:89
    |
251 |         # Analyze results
252 |         successful_requests = [r for r in results if isinstance(r, dict) and r.get('success', False)]
    |                                                                                         ^^^^^^^^^^^^^
253 |         failed_requests = [r for r in results if not isinstance(r, dict) or not r.get('success', False)]
    |

E501 Line too long (104 > 88)
   --> tests/contract_tests/test_integration_contracts.py:253:89
    |
251 |         # Analyze results
252 |         successful_requests = [r for r in results if isinstance(r, dict) and r.get('success', False)]
253 |         failed_requests = [r for r in results if not isinstance(r, dict) or not r.get('success', False)]
    |                                                                                         ^^^^^^^^^^^^^^^^
254 |
255 |         response_times = [r['duration_ms'] for r in successful_requests if 'duration_ms' in r]
    |

E501 Line too long (94 > 88)
   --> tests/contract_tests/test_integration_contracts.py:255:89
    |
253 |         failed_requests = [r for r in results if not isinstance(r, dict) or not r.get('success', False)]
254 |
255 |         response_times = [r['duration_ms'] for r in successful_requests if 'duration_ms' in r]
    |                                                                                         ^^^^^^
256 |
257 |         return {
    |

E501 Line too long (91 > 88)
   --> tests/contract_tests/test_integration_contracts.py:263:89
    |
261 |             'success_rate': len(successful_requests) / concurrent_requests,
262 |             'response_times': {
263 |                 'mean': sum(response_times) / len(response_times) if response_times else 0,
    |                                                                                         ^^^
264 |                 'min': min(response_times) if response_times else 0,
265 |                 'max': max(response_times) if response_times else 0
    |

E501 Line too long (90 > 88)
   --> tests/contract_tests/test_integration_contracts.py:293:89
    |
291 |                 'endpoint': '/chat',
292 |                 'method': 'POST',
293 |                 'payload': {'messages': [{'content': 'x' * 10000}]},  # Very large payload
    |                                                                                         ^^
294 |                 'expected_behavior': 'request_size_limit'
295 |             }
    |

E501 Line too long (108 > 88)
   --> tests/contract_tests/test_integration_contracts.py:322:89
    |
320 |                     'status_code': response.status_code,
321 |                     'response_time_ms': (end_time - start_time) * 1000,
322 |                     'error_handling': self._analyze_error_handling(response, scenario['expected_behavior']),
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^
323 |                     'recovery_success': response.status_code in [400, 401, 413, 422]  # Expected error codes
324 |                 }
    |

E501 Line too long (108 > 88)
   --> tests/contract_tests/test_integration_contracts.py:323:89
    |
321 |                     'response_time_ms': (end_time - start_time) * 1000,
322 |                     'error_handling': self._analyze_error_handling(response, scenario['expected_behavior']),
323 |                     'recovery_success': response.status_code in [400, 401, 413, 422]  # Expected error codes
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^
324 |                 }
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/contract_tests/test_integration_contracts.py:328:20
    |
326 |                 error_test_results.append(result)
327 |
328 |             except Exception as e:
    |                    ^^^^^^^^^
329 |                 error_test_results.append({
330 |                     'scenario': scenario['name'],
    |

E501 Line too long (130 > 88)
   --> tests/contract_tests/test_integration_contracts.py:338:89
    |
336 |             'total_scenarios': len(error_scenarios),
337 |             'scenarios': error_test_results,
338 |             'overall_recovery_rate': sum(1 for r in error_test_results if r.get('recovery_success', False)) / len(error_scenarios)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
339 |         }
    |

E501 Line too long (110 > 88)
   --> tests/contract_tests/test_integration_contracts.py:344:89
    |
342 |         """Analyze if error handling meets expected behavior."""
343 |         if expected_behavior == 'graceful_error_response':
344 |             if response.status_code >= 400 and 'application/json' in response.headers.get('content-type', ''):
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^
345 |                 return 'proper_error_format'
346 |             else:
    |

E501 Line too long (98 > 88)
   --> tests/contract_tests/test_integration_contracts.py:369:89
    |
367 |             'external_mocks': self.external_mocks,
368 |             'summary': {
369 |                 'database_validations': len([r for r in self.test_results if 'validations' in r]),
    |                                                                                         ^^^^^^^^^^
370 |                 'workflow_validations': len([r for r in self.test_results if 'workflow_validations' in r])
371 |             }
    |

E501 Line too long (106 > 88)
   --> tests/contract_tests/test_integration_contracts.py:370:89
    |
368 |             'summary': {
369 |                 'database_validations': len([r for r in self.test_results if 'validations' in r]),
370 |                 'workflow_validations': len([r for r in self.test_results if 'workflow_validations' in r])
    |                                                                                         ^^^^^^^^^^^^^^^^^^
371 |             }
372 |         }
    |

E501 Line too long (99 > 88)
   --> tests/contract_tests/test_integration_contracts.py:386:89
    |
384 |         return IntegrationContractTester()
385 |
386 |     async def test_complete_integration_suite(self, integration_tester: IntegrationContractTester):
    |                                                                                         ^^^^^^^^^^^
387 |         """Run complete integration test suite."""
    |

E501 Line too long (111 > 88)
   --> tests/contract_tests/test_integration_contracts.py:391:89
    |
389 |         # Test end-to-end workflows
390 |         chat_workflow = await integration_tester.test_end_to_end_chat_workflow()
391 |         assert chat_workflow['success'], f"Chat workflow failed: {chat_workflow.get('error', 'Unknown error')}"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^
392 |
393 |         # Test external dependencies
    |

E501 Line too long (90 > 88)
   --> tests/contract_tests/test_integration_contracts.py:395:89
    |
393 |         # Test external dependencies
394 |         external_deps = await integration_tester.test_external_dependency_contracts()
395 |         assert external_deps['overall_compliance'], "External dependency contracts failed"
    |                                                                                         ^^
396 |
397 |         # Test concurrent handling
    |

E501 Line too long (109 > 88)
   --> tests/contract_tests/test_integration_contracts.py:398:89
    |
397 | â€¦     # Test concurrent handling
398 | â€¦     concurrent_results = await integration_tester.test_concurrent_request_handling(concurrent_requests=3)
    |                                                                                       ^^^^^^^^^^^^^^^^^^^^^
399 | â€¦     assert concurrent_results['success_rate'] >= 0.95, f"Low success rate in concurrent testing: {concurrent_results['success_rate'â€¦
    |

E501 Line too long (138 > 88)
   --> tests/contract_tests/test_integration_contracts.py:399:89
    |
397 | â€¦
398 | â€¦tester.test_concurrent_request_handling(concurrent_requests=3)
399 | â€¦'] >= 0.95, f"Low success rate in concurrent testing: {concurrent_results['success_rate']}"
    |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
400 | â€¦
401 | â€¦
    |

E501 Line too long (133 > 88)
   --> tests/contract_tests/test_integration_contracts.py:403:89
    |
401 |         # Test error handling
402 |         error_handling = await integration_tester.test_error_handling_and_recovery()
403 |         assert error_handling['overall_recovery_rate'] >= 0.8, f"Poor error recovery rate: {error_handling['overall_recovery_rate']}"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
404 |
405 |         # Generate report
    |

E501 Line too long (92 > 88)
  --> tests/contract_tests/test_performance_contracts.py:55:89
   |
53 |     """Performance contract testing and validation."""
54 |
55 |     def __init__(self, base_url: str = "http://127.0.0.1:8000", api_key: str | None = None):
   |                                                                                         ^^^^
56 |         self.base_url = base_url.rstrip('/')
57 |         self.api_key = api_key
   |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> tests/contract_tests/test_performance_contracts.py:100:13
    |
 98 |   â€¦     # Check performance thresholds
 99 |   â€¦     threshold = self._get_threshold_for_endpoint(endpoint)
100 | / â€¦     if threshold:
101 | | â€¦         if response_time_ms > threshold.max_response_time_ms:
    | |_______________________________________________________________^
102 |   â€¦             violations.append(f"Response time {response_time_ms:.2f}ms exceeds max threshold {threshold.max_response_time_ms}ms")
    |
help: Combine `if` statements using `and`

E501 Line too long (137 > 88)
   --> tests/contract_tests/test_performance_contracts.py:102:89
    |
100 | â€¦
101 | â€¦.max_response_time_ms:
102 | â€¦e time {response_time_ms:.2f}ms exceeds max threshold {threshold.max_response_time_ms}ms")
    |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
103 | â€¦
104 | â€¦
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/contract_tests/test_performance_contracts.py:116:16
    |
114 |             return result
115 |
116 |         except Exception as e:
    |                ^^^^^^^^^
117 |             end_time = time.time()
118 |             response_time_ms = (end_time - start_time) * 1000
    |

E501 Line too long (151 > 88)
   --> tests/contract_tests/test_performance_contracts.py:181:89
    |
179 | â€¦
180 | â€¦hold.max_response_time_ms:
181 | â€¦response time {stats['response_times']['mean']:.2f}ms exceeds {threshold.max_response_time_ms}ms"
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
182 | â€¦old.max_p95_response_time_ms:
183 | â€¦e time {stats['response_times']['p95']:.2f}ms exceeds {threshold.max_p95_response_time_ms}ms"
    |

E501 Line too long (147 > 88)
   --> tests/contract_tests/test_performance_contracts.py:183:89
    |
181 | â€¦n response time {stats['response_times']['mean']:.2f}ms exceeds {threshold.max_response_time_ms}ms"
182 | â€¦shold.max_p95_response_time_ms:
183 | â€¦nse time {stats['response_times']['p95']:.2f}ms exceeds {threshold.max_p95_response_time_ms}ms"
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
184 | â€¦
185 | â€¦
    |

E501 Line too long (128 > 88)
   --> tests/contract_tests/test_performance_contracts.py:193:89
    |
191 |         return sorted_data[min(index, len(sorted_data) - 1)]
192 |
193 |     async def test_load_performance(self, endpoint: str, method: str, concurrent_requests: int = 5, duration_seconds: int = 10):
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
194 |         """Test endpoint under concurrent load."""
    |

E501 Line too long (98 > 88)
   --> tests/contract_tests/test_performance_contracts.py:239:89
    |
237 |         return load_stats
238 |
239 |     async def test_performance_regression(self, baseline_file: str = "performance_baseline.json"):
    |                                                                                         ^^^^^^^^^^
240 |         """Test for performance regression against baseline."""
241 |         baseline_path = Path(__file__).parent / baseline_file
    |

E501 Line too long (90 > 88)
   --> tests/contract_tests/test_performance_contracts.py:244:89
    |
243 |         if not baseline_path.exists():
244 |             return {'regression_detected': False, 'message': 'No baseline for comparison'}
    |                                                                                         ^^
245 |
246 |         try:
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/contract_tests/test_performance_contracts.py:249:16
    |
247 |             with open(baseline_path) as f:
248 |                 baseline = json.load(f)
249 |         except Exception as e:
    |                ^^^^^^^^^
250 |             return {'regression_detected': False, 'message': f'Error loading baseline: {e}'}
    |

E501 Line too long (92 > 88)
   --> tests/contract_tests/test_performance_contracts.py:250:89
    |
248 |                 baseline = json.load(f)
249 |         except Exception as e:
250 |             return {'regression_detected': False, 'message': f'Error loading baseline: {e}'}
    |                                                                                         ^^^^
251 |
252 |         regression_results = []
    |

E501 Line too long (98 > 88)
   --> tests/contract_tests/test_performance_contracts.py:267:89
    |
266 |             # Check response time regression
267 |             if 'response_time_ms' in baseline_stats and 'mean' in current_stats['response_times']:
    |                                                                                         ^^^^^^^^^^
268 |                 baseline_mean = baseline_stats['response_time_ms']['mean']
269 |                 current_mean = current_stats['response_times']['mean']
    |

E501 Line too long (122 > 88)
   --> tests/contract_tests/test_performance_contracts.py:274:89
    |
272 |                 if current_mean > baseline_mean * 1.2:
273 |                     regression_detected = True
274 |                     violations.append(f"Response time regression: {current_mean:.2f}ms vs baseline {baseline_mean:.2f}ms")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
275 |
276 |             regression_results.append({
    |

E501 Line too long (93 > 88)
   --> tests/contract_tests/test_performance_contracts.py:285:89
    |
284 |         return {
285 |             'regression_detected': any(r['regression_detected'] for r in regression_results),
    |                                                                                         ^^^^^
286 |             'results': regression_results
287 |         }
    |

E501 Line too long (124 > 88)
   --> tests/contract_tests/test_performance_contracts.py:307:89
    |
305 |                 'total_requests': len(self.performance_results),
306 |                 'total_endpoints': len(results_by_endpoint),
307 |                 'overall_success_rate': sum(1 for r in self.performance_results if r.passed) / len(self.performance_results)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
308 |             },
309 |             'endpoints': {}
    |

E501 Line too long (91 > 88)
   --> tests/contract_tests/test_performance_contracts.py:332:89
    |
330 |         return report
331 |
332 |     async def save_performance_baseline(self, filename: str = "performance_baseline.json"):
    |                                                                                         ^^^
333 |         """Save current performance as baseline for regression testing."""
334 |         report = await self.generate_performance_report()
    |

E501 Line too long (91 > 88)
   --> tests/contract_tests/test_performance_contracts.py:361:89
    |
359 |         return PerformanceContractTester()
360 |
361 |     async def test_all_endpoints_performance(self, perf_tester: PerformanceContractTester):
    |                                                                                         ^^^
362 |         """Test performance for all API endpoints."""
363 |         test_endpoints = [
    |

E501 Line too long (117 > 88)
   --> tests/contract_tests/test_performance_contracts.py:368:89
    |
366 |             {'endpoint': '/agents', 'method': 'GET'},
367 |             {'endpoint': '/monitoring/metrics', 'method': 'GET'},
368 |             {'endpoint': '/chat', 'method': 'POST', 'payload': {'messages': [{'role': 'user', 'content': 'Hello'}]}},
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
369 |         ]
    |

E501 Line too long (98 > 88)
   --> tests/contract_tests/test_performance_contracts.py:384:89
    |
383 |                 # Assert performance requirements
384 |                 assert stats['all_passed'], f"Performance test failed for {test_case['endpoint']}"
    |                                                                                         ^^^^^^^^^^
385 |                 assert stats['success_rate'] >= 0.95, f"Success rate below 95% for {test_case['endpoint']}"
    |

E501 Line too long (107 > 88)
   --> tests/contract_tests/test_performance_contracts.py:385:89
    |
383 |                 # Assert performance requirements
384 |                 assert stats['all_passed'], f"Performance test failed for {test_case['endpoint']}"
385 |                 assert stats['success_rate'] >= 0.95, f"Success rate below 95% for {test_case['endpoint']}"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
    |

E501 Line too long (107 > 88)
   --> tests/contract_tests/test_performance_contracts.py:413:89
    |
412 |                 # Assert load test requirements
413 |                 assert stats['throughput_rps'] > 1.0, f"Throughput below 1 RPS for {test_case['endpoint']}"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
414 |                 assert stats['failed_requests'] == 0, f"Failed requests in load test for {test_case['endpoint']}"
    |

E501 Line too long (113 > 88)
   --> tests/contract_tests/test_performance_contracts.py:414:89
    |
412 |                 # Assert load test requirements
413 |                 assert stats['throughput_rps'] > 1.0, f"Throughput below 1 RPS for {test_case['endpoint']}"
414 |                 assert stats['failed_requests'] == 0, f"Failed requests in load test for {test_case['endpoint']}"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^
    |

E501 Line too long (152 > 88)
  --> tests/full_endpoint_test.py:19:89
   |
17 | â€¦
18 | â€¦
19 | â€¦, data: dict | None = None, description: str = "", headers: dict | None = None) -> dict[str, Any]:
   |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
20 | â€¦"""
21 | â€¦
   |

S113 Probable use of `requests` call without timeout
  --> tests/full_endpoint_test.py:26:28
   |
24 |         try:
25 |             if method.upper() == "GET":
26 |                 response = requests.get(url, headers=request_headers)
   |                            ^^^^^^^^^^^^
27 |             elif method.upper() == "POST":
28 |                 response = requests.post(url, json=data, headers=request_headers)
   |

S113 Probable use of `requests` call without timeout
  --> tests/full_endpoint_test.py:28:28
   |
26 |                 response = requests.get(url, headers=request_headers)
27 |             elif method.upper() == "POST":
28 |                 response = requests.post(url, json=data, headers=request_headers)
   |                            ^^^^^^^^^^^^^
29 |             elif method.upper() == "PUT":
30 |                 response = requests.put(url, json=data, headers=request_headers)
   |

S113 Probable use of `requests` call without timeout
  --> tests/full_endpoint_test.py:30:28
   |
28 |                 response = requests.post(url, json=data, headers=request_headers)
29 |             elif method.upper() == "PUT":
30 |                 response = requests.put(url, json=data, headers=request_headers)
   |                            ^^^^^^^^^^^^
31 |             elif method.upper() == "DELETE":
32 |                 response = requests.delete(url, headers=request_headers)
   |

S113 Probable use of `requests` call without timeout
  --> tests/full_endpoint_test.py:32:28
   |
30 |                 response = requests.put(url, json=data, headers=request_headers)
31 |             elif method.upper() == "DELETE":
32 |                 response = requests.delete(url, headers=request_headers)
   |                            ^^^^^^^^^^^^^^^
33 |             else:
34 |                 raise ValueError(f"Unsupported method: {method}")
   |

E722 Do not use bare `except`
  --> tests/full_endpoint_test.py:39:13
   |
37 |             try:
38 |                 response_data = response.json()
39 |             except:
   |             ^^^^^^
40 |                 response_data = response.text
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/full_endpoint_test.py:55:16
   |
53 |             return result
54 |
55 |         except Exception as e:
   |                ^^^^^^^^^
56 |             result = {
57 |                 "status_code": 0,
   |

E501 Line too long (106 > 88)
  --> tests/full_endpoint_test.py:71:89
   |
70 |         # 1. Health & Status Endpoints
71 |         self.results["health"] = self.test_endpoint("GET", "/health", description="Health check endpoint")
   |                                                                                         ^^^^^^^^^^^^^^^^^^
72 |
73 |         # 2. Core API - Models
   |

E501 Line too long (113 > 88)
  --> tests/full_endpoint_test.py:74:89
   |
73 |         # 2. Core API - Models
74 |         self.results["models"] = self.test_endpoint("GET", "/api/v1/models", description="List available models")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^
75 |
76 |         # 3. Core API - Personas
   |

E501 Line too long (120 > 88)
  --> tests/full_endpoint_test.py:77:89
   |
76 |         # 3. Core API - Personas
77 |         self.results["personas"] = self.test_endpoint("GET", "/api/v1/personas", description="List configured personas")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
78 |
79 |         # 4. Core API - Chat (Basic)
   |

E501 Line too long (127 > 88)
  --> tests/full_endpoint_test.py:86:89
   |
84 |             "max_tokens": 100
85 |         }
86 |         self.results["chat_basic"] = self.test_endpoint("POST", "/api/v1/chat", chat_data, description="Basic chat completion")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
87 |
88 |         # 5. Core API - Chat (Complex)
   |

E501 Line too long (136 > 88)
   --> tests/full_endpoint_test.py:101:89
    |
 99 | â€¦wn as the City of Light"]
100 | â€¦
101 | â€¦st_endpoint("POST", "/api/v1/chat", chat_complex, description="Complex chat with context")
    |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
102 | â€¦
103 | â€¦
    |

E501 Line too long (135 > 88)
   --> tests/full_endpoint_test.py:104:89
    |
103 | â€¦
104 | â€¦elf.test_endpoint("GET", "/api/v1/monitoring/metrics", description="Get metrics history")
    |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
105 | â€¦lf.test_endpoint("GET", "/api/v1/monitoring/traces", description="Get request traces")
    |

E501 Line too long (132 > 88)
   --> tests/full_endpoint_test.py:105:89
    |
103 | â€¦
104 | â€¦ self.test_endpoint("GET", "/api/v1/monitoring/metrics", description="Get metrics history")
105 | â€¦self.test_endpoint("GET", "/api/v1/monitoring/traces", description="Get request traces")
    |                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
106 | â€¦
107 | â€¦
    |

E501 Line too long (134 > 88)
   --> tests/full_endpoint_test.py:108:89
    |
107 |         # 7. Management API - System
108 |         self.results["system_status"] = self.test_endpoint("GET", "/api/v1/management/system/status", description="Get system status")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
109 |
110 |         # 8. Management API - Routing
    |

E501 Line too long (148 > 88)
   --> tests/full_endpoint_test.py:111:89
    |
110 | â€¦
111 | â€¦st_endpoint("GET", "/api/v1/management/routing/config", description="Get routing configuration")
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
112 | â€¦
113 | â€¦
    |

E501 Line too long (172 > 88)
   --> tests/full_endpoint_test.py:118:89
    |
116 | â€¦
117 | â€¦
118 | â€¦"PUT", "/api/v1/management/config/routing", routing_update_data, description="Update routing configuration")
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
119 | â€¦
120 | â€¦
    |

E501 Line too long (125 > 88)
   --> tests/full_endpoint_test.py:121:89
    |
120 | â€¦     # 9. Management API - Backends
121 | â€¦     self.results["backends_list"] = self.test_endpoint("GET", "/api/v1/management/backends", description="List backends")
    |                                                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
122 | â€¦     self.results["backend_test"] = self.test_endpoint("POST", "/api/v1/management/backends/ollama/test", description="Test backend â€¦
    |

E501 Line too long (149 > 88)
   --> tests/full_endpoint_test.py:122:89
    |
120 | â€¦
121 | â€¦point("GET", "/api/v1/management/backends", description="List backends")
122 | â€¦oint("POST", "/api/v1/management/backends/ollama/test", description="Test backend connectivity")
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
123 | â€¦
124 | â€¦
    |

E501 Line too long (148 > 88)
   --> tests/full_endpoint_test.py:125:89
    |
124 | â€¦
125 | â€¦st_endpoint("GET", "/api/v1/management/context/config", description="Get context configuration")
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
126 | â€¦
127 | â€¦
    |

E501 Line too long (172 > 88)
   --> tests/full_endpoint_test.py:131:89
    |
129 | â€¦
130 | â€¦
131 | â€¦"PUT", "/api/v1/management/config/context", context_update_data, description="Update context configuration")
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
132 | â€¦
133 | â€¦
    |

E501 Line too long (140 > 88)
   --> tests/full_endpoint_test.py:134:89
    |
133 | â€¦
134 | â€¦est_endpoint("GET", "/api/v1/management/security/status", description="Get security status")
    |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
135 | â€¦
136 | â€¦
    |

E501 Line too long (153 > 88)
   --> tests/full_endpoint_test.py:146:89
    |
144 | â€¦
145 | â€¦
146 | â€¦oint("POST", "/api/v1/management/personas", persona_create_data, description="Create new persona")
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
147 | â€¦
148 | â€¦
    |

E501 Line too long (90 > 88)
   --> tests/full_endpoint_test.py:151:89
    |
149 | â€¦     persona_update_data = {
150 | â€¦         "description": "Updated test persona description",
151 | â€¦         "system_prompt": "You are a helpful test assistant with updated instructions."
    |                                                                                       ^^
152 | â€¦     }
153 | â€¦     self.results["persona_update"] = self.test_endpoint("PUT", "/api/v1/management/personas/test-persona", persona_update_data, desâ€¦
    |

E501 Line too long (161 > 88)
   --> tests/full_endpoint_test.py:153:89
    |
151 | â€¦ant with updated instructions."
152 | â€¦
153 | â€¦("PUT", "/api/v1/management/personas/test-persona", persona_update_data, description="Update persona")
    |                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
154 | â€¦
155 | â€¦
    |

E501 Line too long (91 > 88)
   --> tests/full_endpoint_test.py:158:89
    |
156 |         openai_chat_data = {
157 |             "model": "generalist",
158 |             "messages": [{"role": "user", "content": "Hello from OpenAI-compatible API!"}],
    |                                                                                         ^^^
159 |             "temperature": 0.7,
160 |             "max_tokens": 100
    |

E501 Line too long (156 > 88)
   --> tests/full_endpoint_test.py:162:89
    |
160 | â€¦
161 | â€¦
162 | â€¦("POST", "/v1/chat/completions", openai_chat_data, description="OpenAI-compatible chat completions")
    |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
163 | â€¦nt("GET", "/v1/models", description="OpenAI-compatible models list")
    |

E501 Line too long (124 > 88)
   --> tests/full_endpoint_test.py:163:89
    |
161 |         }
162 |         self.results["openai_chat"] = self.test_endpoint("POST", "/v1/chat/completions", openai_chat_data, description="OpenAI-compatâ€¦
163 |         self.results["openai_models"] = self.test_endpoint("GET", "/v1/models", description="OpenAI-compatible models list")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
164 |
165 |         # 14. Configuration Management
    |

E501 Line too long (132 > 88)
   --> tests/full_endpoint_test.py:166:89
    |
165 |         # 14. Configuration Management
166 |         self.results["config_save"] = self.test_endpoint("POST", "/api/v1/management/config/save", description="Save configuration")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
167 |
168 |         # 15. Persona Deletion (cleanup)
    |

E501 Line too long (148 > 88)
   --> tests/full_endpoint_test.py:169:89
    |
168 | â€¦
169 | â€¦ndpoint("DELETE", "/api/v1/management/personas/test-persona", description="Delete test persona")
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
170 | â€¦
171 | â€¦
    |

E501 Line too long (91 > 88)
   --> tests/full_endpoint_test.py:187:89
    |
185 | â€¦     # Summary
186 | â€¦     total_tests = len(self.results)
187 | â€¦     successful_tests = sum(1 for r in self.results.values() if r.get('success', False))
    |                                                                                       ^^^
188 | â€¦     report += f"## Summary\n- **Total Tests**: {total_tests}\n- **Successful**: {successful_tests}\n- **Failed**: {total_tests - suâ€¦
    |

E501 Line too long (218 > 88)
   --> tests/full_endpoint_test.py:188:89
    |
186 | â€¦
187 | â€¦ False))
188 | â€¦ {successful_tests}\n- **Failed**: {total_tests - successful_tests}\n- **Success Rate**: {(successful_tests/total_tests)*100:.1f}%\n\n"
    |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
189 | â€¦
190 | â€¦
    |

E501 Line too long (97 > 88)
   --> tests/full_endpoint_test.py:200:89
    |
198 |             "Management - Context": ["context_config_get", "context_config_put"],
199 |             "Management - Security": ["security_status"],
200 |             "Management - Personas CRUD": ["persona_create", "persona_update", "persona_delete"],
    |                                                                                         ^^^^^^^^^
201 |             "OpenAI-Compatible": ["openai_chat", "openai_models"],
202 |             "Configuration": ["config_save"]
    |

E501 Line too long (97 > 88)
   --> tests/full_endpoint_test.py:214:89
    |
212 |                     result = self.results[endpoint_name]
213 |                     status_icon = "âœ…" if result.get('success') else "âŒ"
214 |                     report += f"- **{endpoint_name.replace('_', ' ').title()}**: {status_icon}\n"
    |                                                                                         ^^^^^^^^^
215 |                     if result.get('success'):
216 |                         category_success += 1
    |

E501 Line too long (147 > 88)
   --> tests/full_endpoint_test.py:220:89
    |
218 | â€¦ssful requests
219 | â€¦ult.get('response'):
220 | â€¦view: `{str(result['response'])[:100]}{'...' if len(str(result['response'])) > 100 else ''}`\n"
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
221 | â€¦
222 | â€¦
    |

E501 Line too long (97 > 88)
   --> tests/full_endpoint_test.py:232:87
    |
230 |         for endpoint_name, result in self.results.items():
231 |             report += f"### {endpoint_name.replace('_', ' ').title()}\n"
232 |             report += f"- **Status**: {'âœ… Success' if result.get('success') else 'âŒ Failed'}\n"
    |                                                                                         ^^^^^^^^^
233 |             report += f"- **Method**: {result.get('method', 'N/A')}\n"
234 |             report += f"- **Endpoint**: {result.get('endpoint', 'N/A')}\n"
    |

E501 Line too long (118 > 88)
   --> tests/full_endpoint_test.py:241:89
    |
240 |             if result.get('response'):
241 |                 report += f"- **Response**: \n```json\n{json.dumps(result['response'], indent=2, default=str)}\n```\n"
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
242 |
243 |             if result.get('error'):
    |

E501 Line too long (107 > 88)
   --> tests/full_endpoint_test.py:250:89
    |
248 |         # Schema Analysis
249 |         report += "## Response Schema Analysis\n\n"
250 |         successful_responses = [r for r in self.results.values() if r.get('success') and r.get('response')]
    |                                                                                         ^^^^^^^^^^^^^^^^^^^
251 |
252 |         if successful_responses:
    |

E501 Line too long (96 > 88)
   --> tests/full_endpoint_test.py:259:89
    |
257 |                 report += f"#### {i}. {endpoint}\n"
258 |                 if isinstance(response, dict):
259 |                     report += f"```json\n{json.dumps(response, indent=2, default=str)}\n```\n\n"
    |                                                                                         ^^^^^^^^
260 |                 else:
261 |                     report += f"**Response**: {response}\n\n"
    |

E402 Module level import not at top of file
  --> tests/run_contract_tests.py:27:1
   |
25 | sys.path.insert(0, str(project_root))
26 |
27 | from tests.contract_tests.test_api_contracts import run_contract_tests
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
28 | from tests.contract_tests.test_integration_contracts import run_integration_tests
29 | from tests.contract_tests.test_performance_contracts import run_performance_tests
   |

E402 Module level import not at top of file
  --> tests/run_contract_tests.py:28:1
   |
27 | from tests.contract_tests.test_api_contracts import run_contract_tests
28 | from tests.contract_tests.test_integration_contracts import run_integration_tests
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
29 | from tests.contract_tests.test_performance_contracts import run_performance_tests
   |

E402 Module level import not at top of file
  --> tests/run_contract_tests.py:29:1
   |
27 | from tests.contract_tests.test_api_contracts import run_contract_tests
28 | from tests.contract_tests.test_integration_contracts import run_integration_tests
29 | from tests.contract_tests.test_performance_contracts import run_performance_tests
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/run_contract_tests.py:46:16
   |
44 |             await run_contract_tests()
45 |             test_results['api_contracts']['status'] = 'passed'
46 |         except Exception as e:
   |                ^^^^^^^^^
47 |             test_results['api_contracts']['status'] = 'failed'
48 |             test_results['api_contracts']['details']['error'] = str(e)
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/run_contract_tests.py:54:16
   |
52 |             await run_performance_tests()
53 |             test_results['performance_contracts']['status'] = 'passed'
54 |         except Exception as e:
   |                ^^^^^^^^^
55 |             test_results['performance_contracts']['status'] = 'failed'
56 |             test_results['performance_contracts']['details']['error'] = str(e)
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/run_contract_tests.py:62:16
   |
60 |             await run_integration_tests()
61 |             test_results['integration_contracts']['status'] = 'passed'
62 |         except Exception as e:
   |                ^^^^^^^^^
63 |             test_results['integration_contracts']['status'] = 'failed'
64 |             test_results['integration_contracts']['details']['error'] = str(e)
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/run_contract_tests.py:68:12
   |
66 |     except KeyboardInterrupt:
67 |         sys.exit(1)
68 |     except Exception:
   |            ^^^^^^^^^
69 |         sys.exit(1)
   |

E501 Line too long (93 > 88)
  --> tests/run_contract_tests.py:73:89
   |
71 |     # Generate final summary
72 |
73 |     passed_tests = sum(1 for result in test_results.values() if result['status'] == 'passed')
   |                                                                                         ^^^^^
74 |     total_tests = len(test_results)
75 |     overall_success_rate = passed_tests / total_tests
   |

BLE001 Do not catch blind exception: `Exception`
   --> tests/run_contract_tests.py:116:12
    |
114 |     except KeyboardInterrupt:
115 |         sys.exit(0)
116 |     except Exception:
    |            ^^^^^^^^^
117 |         sys.exit(1)
    |

BLE001 Do not catch blind exception: `Exception`
  --> tests/simple_audit_test.py:36:12
   |
35 |         return True
36 |     except Exception:
   |            ^^^^^^^^^
37 |         import traceback
38 |         traceback.print_exc()
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/simple_audit_test.py:69:12
   |
68 |         return True
69 |     except Exception:
   |            ^^^^^^^^^
70 |         import traceback
71 |         traceback.print_exc()
   |

BLE001 Do not catch blind exception: `Exception`
   --> tests/simple_audit_test.py:122:12
    |
121 |         return True
122 |     except Exception:
    |            ^^^^^^^^^
123 |         import traceback
124 |         traceback.print_exc()
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/simple_audit_test.py:143:12
    |
142 |         return True
143 |     except Exception:
    |            ^^^^^^^^^
144 |         import traceback
145 |         traceback.print_exc()
    |

B007 Loop control variable `test_name` not used within loop body
   --> tests/simple_audit_test.py:165:9
    |
165 |     for test_name, success in results:
    |         ^^^^^^^^^
166 |         status = "âœ… PASSED" if success else "âŒ FAILED"
    |
help: Rename unused `test_name` to `_test_name`

BLE001 Do not catch blind exception: `Exception`
  --> tests/simple_test.py:47:12
   |
45 |             "response_time_ms": response.elapsed.total_seconds() * 1000
46 |         })
47 |     except Exception as e:
   |            ^^^^^^^^^
48 |         test_results.append({
49 |             "test": "Health Check",
   |

E501 Line too long (131 > 88)
  --> tests/simple_test.py:61:89
   |
59 |         ("/api/v1/models", "GET", "List Models"),
60 |         ("/api/v1/personas", "GET", "List Personas"),
61 |         ("/api/v1/chat", "POST", "Chat Completion", {"messages": [{"role": "user", "content": "Hello"}], "persona": "generalist"}),
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
62 |         ("/api/v1/monitoring/metrics", "GET", "Get Metrics"),
63 |         ("/api/v1/monitoring/traces", "GET", "Get Traces"),
   |

E501 Line too long (127 > 88)
  --> tests/simple_test.py:69:89
   |
67 |         ("/api/v1/management/context/config", "GET", "Context Config"),
68 |         ("/api/v1/management/security/status", "GET", "Security Status"),
69 |         ("/v1/chat/completions", "POST", "OpenAI Chat", {"model": "test", "messages": [{"role": "user", "content": "Hello"}]}),
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
70 |         ("/v1/models", "GET", "OpenAI Models")
71 |     ]
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/simple_test.py:92:16
   |
90 |             })
91 |
92 |         except Exception as e:
   |                ^^^^^^^^^
93 |             test_results.append({
94 |                 "test": test_name,
   |

BLE001 Do not catch blind exception: `Exception`
   --> tests/simple_test.py:128:16
    |
126 |             })
127 |
128 |         except Exception as e:
    |                ^^^^^^^^^
129 |             test_results.append({
130 |                 "test": test_name,
    |

E501 Line too long (89 > 88)
   --> tests/simple_test.py:149:89
    |
147 |         "failed_tests": failed_tests,
148 |         "success_rate": successful_tests / total_tests if total_tests > 0 else 0,
149 |         "avg_response_time_ms": statistics.mean(response_times) if response_times else 0,
    |                                                                                         ^
150 |         "min_response_time_ms": min(response_times) if response_times else 0,
151 |         "max_response_time_ms": max(response_times) if response_times else 0
    |

E501 Line too long (117 > 88)
  --> tests/test_audit_system.py:69:85
   |
68 |                     for severity, _count in severity_counts.items():
69 |                         {"CRITICAL": "ðŸš¨", "HIGH": "ðŸ”´", "MEDIUM": "ðŸŸ¡", "LOW": "ðŸŸ¢", "INFO": "â„¹ï¸"}.get(severity, "â€¢")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
70 |
71 |         # Recommendations
   |

RUF001 String contains ambiguous `â„¹` (INFORMATION SOURCE). Did you mean `i` (LATIN SMALL LETTER I)?
  --> tests/test_audit_system.py:69:92
   |
68 |                     for severity, _count in severity_counts.items():
69 |                         {"CRITICAL": "ðŸš¨", "HIGH": "ðŸ”´", "MEDIUM": "ðŸŸ¡", "LOW": "ðŸŸ¢", "INFO": "â„¹ï¸"}.get(severity, "â€¢")
   |                                                                                                ^
70 |
71 |         # Recommendations
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/test_audit_system.py:79:12
   |
77 |         return True
78 |
79 |     except Exception:
   |            ^^^^^^^^^
80 |         import traceback
81 |         traceback.print_exc()
   |

E501 Line too long (90 > 88)
  --> tests/test_audit_system.py:94:89
   |
92 |     files_to_scan = []
93 |     for file_path in current_dir.rglob("*.py"):
94 |         if "test_audit_system.py" not in str(file_path) and "audit" not in str(file_path):
   |                                                                                         ^^
95 |             files_to_scan.append(file_path)
   |

BLE001 Do not catch blind exception: `Exception`
   --> tests/test_audit_system.py:116:12
    |
114 |         return True
115 |
116 |     except Exception:
    |            ^^^^^^^^^
117 |         import traceback
118 |         traceback.print_exc()
    |

E501 Line too long (89 > 88)
  --> tests/test_config_simple.py:19:89
   |
17 |     system_prompt: str
18 |     max_context_window: int = Field(4096, ge=512)
19 |     routing_hint: str = Field("general", description="Hint used by the routing pipeline")
   |                                                                                         ^
20 |
21 | def _default_personas() -> dict[str, PersonaConfig]:
   |

E501 Line too long (125 > 88)
  --> tests/test_config_simple.py:27:89
   |
25 |         description="Balanced assistant persona",
26 |         system_prompt=(
27 |             "You are AdaptiveMind, a local-first research assistant. Provide concise, factual answers and highlight sources."
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
28 |         ),
29 |         max_context_window=4096,
   |

E501 Line too long (99 > 88)
  --> tests/test_config_simple.py:40:89
   |
38 |     @field_validator("allowed_personas", mode="after")
39 |     @classmethod
40 |     def _default_allowed_personas(cls, value: list[str] | None, info: ValidationInfo) -> list[str]:
   |                                                                                         ^^^^^^^^^^^
41 |         """Set default allowed personas from configured personas if not explicitly set.
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/test_config_simple.py:66:12
   |
64 |         expected = ["generalist"]
65 |         return config.allowed_personas == expected
66 |     except Exception:
   |            ^^^^^^^^^
67 |         return False
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/test_config_simple.py:82:12
   |
80 |         expected = ["generalist"]
81 |         return config.allowed_personas == expected
82 |     except Exception:
   |            ^^^^^^^^^
83 |         return False
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/test_config_simple.py:98:12
   |
96 |         expected = ["custom_persona"]
97 |         return config.allowed_personas == expected
98 |     except Exception:
   |            ^^^^^^^^^
99 |         return False
   |

BLE001 Do not catch blind exception: `Exception`
   --> tests/test_config_simple.py:114:12
    |
112 |         expected = ["generalist"]
113 |         return config.allowed_personas == expected
114 |     except Exception:
    |            ^^^^^^^^^
115 |         return False
    |

E501 Line too long (91 > 88)
  --> tests/test_e2e_api.py:43:89
   |
41 |         },
42 |         allowed_personas=["generalist", "researcher"],
43 |         monitoring=MonitoringConfig(enable_metrics_harvest=False, harvest_interval_s=60.0),
   |                                                                                         ^^^
44 |     )
45 |     app = build_app(config=config)
   |

E501 Line too long (91 > 88)
   --> tests/test_e2e_api.py:104:89
    |
102 |         allowed_personas=["generalist"],
103 |         security=SecurityConfig(api_keys=["secret-key"]),
104 |         monitoring=MonitoringConfig(enable_metrics_harvest=False, harvest_interval_s=60.0),
    |                                                                                         ^^^
105 |     )
106 |     app = build_app(config=config)
    |

E501 Line too long (132 > 88)
  --> tests/test_jarvis_local_compat.py:33:89
   |
31 |         found_warning = False
32 |         for w in rec:
33 |             if issubclass(w.category, DeprecationWarning) and "`Jarvis_Local` moved to `apps.AdaptiveMind_Local`" in str(w.message):
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
34 |                 found_warning = True
35 |                 break
   |

E501 Line too long (103 > 88)
  --> tests/test_jarvis_local_compat.py:40:89
   |
39 |         # Basic sanity: ensure the module resolves to the apps package underneath
40 |         # Note: The shim might replace sys.modules entry, so we check if it behaves like the new module
   |                                                                                         ^^^^^^^^^^^^^^^
41 |         assert hasattr(Jarvis_Local, "__file__") or hasattr(Jarvis_Local, "__path__")
   |

E501 Line too long (113 > 88)
  --> tests/test_local_chat.py:21:89
   |
20 | # Skip this test if the legacy runtime isn't available (we archived it)
21 | legacy_app = pytest.importorskip("legacy.app", reason="legacy runtime archived; enable if you need legacy tests")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^
22 | legacy_main = getattr(legacy_app, "main", None)
23 | if legacy_main is None:
   |

E501 Line too long (101 > 88)
  --> tests/test_memory_workflows.py:16:89
   |
15 | BASE_URL = os.getenv("ADAPTIVEMIND_TEST_BASE_URL", "http://127.0.0.1:8000")
16 | REQUIRE_NEW_RUNTIME = os.getenv("REQUIRE_NEW_RUNTIME", "false").lower() in {"1", "true", "yes", "on"}
   |                                                                                         ^^^^^^^^^^^^^
   |

SIM108 Use ternary operator `abs_path = candidate if os.path.exists(candidate) else os.path.abspath(model_path)` instead of `if`-`else`-block
  --> tests/test_model.py:25:5
   |
23 |   else:
24 |       candidate = os.path.abspath(os.path.join("apps", "AdaptiveMind_Local", model_path))
25 | /     if os.path.exists(candidate):
26 | |         abs_path = candidate
27 | |     else:
28 | |         # Fallback to interpreting the value as-is (may be a model id, not a file path)
29 | |         abs_path = os.path.abspath(model_path)
   | |______________________________________________^
30 |
31 |   # Try loading model
   |
help: Replace `if`-`else`-block with `abs_path = candidate if os.path.exists(candidate) else os.path.abspath(model_path)`

S110 `try`-`except`-`pass` detected, consider logging the exception
  --> tests/test_model.py:45:1
   |
43 |       )
44 |       response = output["choices"][0]["text"]
45 | / except Exception:
46 | |     pass
   | |________^
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/test_model.py:45:8
   |
43 |     )
44 |     response = output["choices"][0]["text"]
45 | except Exception:
   |        ^^^^^^^^^
46 |     pass
   |

E501 Line too long (93 > 88)
  --> tests/test_openai_compatibility.py:62:89
   |
60 |             mock_app.models.return_value = ["llama3.2:latest", "codellama:7b"]
61 |             mock_app.chat.return_value = {
62 |                 "content": "Hello! I'm Jarvis, your AI assistant. How can I help you today?",
   |                                                                                         ^^^^^
63 |                 "model": "llama3.2:latest",
64 |                 "tokens": 42,
   |

E501 Line too long (91 > 88)
   --> tests/test_openai_compatibility.py:149:89
    |
147 |         assert "total_tokens" in usage
148 |         assert usage["completion_tokens"] == 42  # From mock
149 |         assert usage["total_tokens"] == usage["prompt_tokens"] + usage["completion_tokens"]
    |                                                                                         ^^^
150 |
151 |     def test_openai_chat_completions_with_persona_routing(self, client, mock_jarvis_app):
    |

E501 Line too long (89 > 88)
   --> tests/test_openai_compatibility.py:151:89
    |
149 |         assert usage["total_tokens"] == usage["prompt_tokens"] + usage["completion_tokens"]
150 |
151 |     def test_openai_chat_completions_with_persona_routing(self, client, mock_jarvis_app):
    |                                                                                         ^
152 |         """Test that model parameter routes to correct persona"""
153 |         request_data = {
    |

E501 Line too long (91 > 88)
   --> tests/test_openai_compatibility.py:173:89
    |
171 |         assert call_args[1]["persona"] == "coder"  # Should route to coder persona
172 |
173 |     def test_openai_chat_completions_fallback_to_generalist(self, client, mock_jarvis_app):
    |                                                                                         ^^^
174 |         """Test that unknown model falls back to generalist persona"""
175 |         request_data = {
    |

E501 Line too long (89 > 88)
   --> tests/test_openai_compatibility.py:208:89
    |
206 |             "model": "llama3.2:latest",
207 |             "messages": [
208 |                 {"role": "user", "content": "This is a test message with multiple words"}
    |                                                                                         ^
209 |             ]
210 |         }
    |

E501 Line too long (96 > 88)
   --> tests/test_openai_compatibility.py:238:89
    |
236 |             "model": "llama3.2:latest",
237 |             "messages": [
238 |                 {"role": "user", "content": "Hello world"}  # 2 words = ~8 chars / 4 = ~2 tokens
    |                                                                                         ^^^^^^^^
239 |             ]
240 |         }
    |

E501 Line too long (91 > 88)
   --> tests/test_openai_compatibility.py:493:89
    |
492 |         # Validate token math
493 |         assert usage["total_tokens"] == usage["prompt_tokens"] + usage["completion_tokens"]
    |                                                                                         ^^^
    |

BLE001 Do not catch blind exception: `Exception`
  --> tests/test_openrouter.py:53:12
   |
51 |         return False
52 |
53 |     except Exception:
   |            ^^^^^^^^^
54 |         return False
   |

E501 Line too long (89 > 88)
  --> tests/test_openrouter.py:71:89
   |
69 |         test_prompts = [
70 |             "Hello world",  # Should be low
71 |             "Write a Python function to calculate fibonacci numbers",  # Should be medium
   |                                                                                         ^
72 |             "Design a secure authentication system for a web application",  # Should be high
73 |         ]
   |

E501 Line too long (92 > 88)
  --> tests/test_openrouter.py:72:89
   |
70 |             "Hello world",  # Should be low
71 |             "Write a Python function to calculate fibonacci numbers",  # Should be medium
72 |             "Design a secure authentication system for a web application",  # Should be high
   |                                                                                         ^^^^
73 |         ]
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/test_openrouter.py:80:12
   |
78 |         return True
79 |
80 |     except Exception:
   |            ^^^^^^^^^
81 |         return False
   |

E501 Line too long (108 > 88)
  --> tests/test_openrouter_simple.py:34:89
   |
32 |         spec = importlib.util.spec_from_file_location(
33 |             "openrouter",
34 |             os.path.join(os.path.dirname(__file__), 'legacy', 'jarvis', 'mcp', 'providers', 'openrouter.py')
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^
35 |         )
36 |         openrouter_module = importlib.util.module_from_spec(spec)
   |

N806 Variable `OpenRouterClient` in function should be lowercase
  --> tests/test_openrouter_simple.py:38:9
   |
36 |         openrouter_module = importlib.util.module_from_spec(spec)
37 |         spec.loader.exec_module(openrouter_module)
38 |         OpenRouterClient = openrouter_module.OpenRouterClient
   |         ^^^^^^^^^^^^^^^^
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/test_openrouter_simple.py:77:12
   |
75 |         return False
76 |
77 |     except Exception:
   |            ^^^^^^^^^
78 |         return False
   |

E501 Line too long (101 > 88)
  --> tests/test_security_monitoring.py:16:89
   |
15 | BASE_URL = os.getenv("ADAPTIVEMIND_TEST_BASE_URL", "http://127.0.0.1:8000")
16 | REQUIRE_NEW_RUNTIME = os.getenv("REQUIRE_NEW_RUNTIME", "false").lower() in {"1", "true", "yes", "on"}
   |                                                                                         ^^^^^^^^^^^^^
   |

E501 Line too long (89 > 88)
  --> tests/test_security_monitoring.py:45:89
   |
44 | def test_security_validate_and_audit():
45 |     payload = {"agent_id": "research_agent", "action": "read", "context": {"test": True}}
   |                                                                                         ^
46 |     r = _post("/api/security/validate", payload)
47 |     _assert_status(r)
   |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> tests/test_server.py:36:16
   |
35 |       # In-memory storage for testing
36 |       personas = {
   |  ________________^
37 | |         "generalist": {
38 | |             "name": "generalist",
39 | |             "description": "Balanced assistant persona",
40 | |             "system_prompt": "You are a helpful assistant.",
41 | |             "max_context_window": 4096,
42 | |             "routing_hint": "general"
43 | |         },
44 | |         "researcher": {
45 | |             "name": "researcher",
46 | |             "description": "Deep research persona",
47 | |             "system_prompt": "Focus on sourcing and multi-step reasoning.",
48 | |             "max_context_window": 4096,
49 | |             "routing_hint": "research"
50 | |         }
51 | |     }
   | |_____^
52 |
53 |       allowed_personas = ["generalist", "researcher"]
   |

RUF012 Mutable class attributes should be annotated with `typing.ClassVar`
  --> tests/test_server.py:53:24
   |
51 |     }
52 |
53 |     allowed_personas = ["generalist", "researcher"]
   |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
54 |
55 |     def do_OPTIONS(self):
   |

E501 Line too long (91 > 88)
  --> tests/test_server.py:64:89
   |
62 |         """Send CORS headers."""
63 |         self.send_header('Access-Control-Allow-Origin', '*')
64 |         self.send_header('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS')
   |                                                                                         ^^^
65 |         self.send_header('Access-Control-Allow-Headers', 'Content-Type, X-API-Key')
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/test_server.py:97:16
   |
95 |             else:
96 |                 self.send_error(404, "Not Found")
97 |         except Exception as e:
   |                ^^^^^^^^^
98 |             self.send_error(500, f"Internal Server Error: {e!s}")
   |

BLE001 Do not catch blind exception: `Exception`
   --> tests/test_server.py:118:16
    |
116 |             else:
117 |                 self.send_error(404, "Not Found")
118 |         except Exception as e:
    |                ^^^^^^^^^
119 |             self.send_error(500, f"Internal Server Error: {e!s}")
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/test_server.py:136:16
    |
134 |             else:
135 |                 self.send_error(404, "Not Found")
136 |         except Exception as e:
    |                ^^^^^^^^^
137 |             self.send_error(500, f"Internal Server Error: {e!s}")
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/test_server.py:150:16
    |
148 |             else:
149 |                 self.send_error(404, "Not Found")
150 |         except Exception as e:
    |                ^^^^^^^^^
151 |             self.send_error(500, f"Internal Server Error: {e!s}")
    |

E501 Line too long (135 > 88)
   --> tests/test_server.py:188:89
    |
186 | â€¦
187 | â€¦
188 | â€¦m {data.get('persona', 'generalist')} persona. This is a mock response for API testing.",
    |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
189 | â€¦
190 | â€¦
    |

E501 Line too long (92 > 88)
   --> tests/test_server.py:311:89
    |
309 |                 "extra_documents_dir": data.get("extra_documents_dir"),
310 |                 "enable_semantic_chunking": data.get("enable_semantic_chunking", True),
311 |                 "max_combined_context_tokens": data.get("max_combined_context_tokens", 8192)
    |                                                                                         ^^^^
312 |             })
313 |         except json.JSONDecodeError:
    |

E501 Line too long (97 > 88)
   --> tests/test_server.py:367:89
    |
365 |             persona = self.personas[persona_name]
366 |             for key, value in data.items():
367 |                 if key in ["description", "system_prompt", "max_context_window", "routing_hint"]:
    |                                                                                         ^^^^^^^^^
368 |                     persona[key] = value
    |

E501 Line too long (94 > 88)
   --> tests/test_server.py:390:89
    |
388 |             self.allowed_personas.remove(persona_name)
389 |
390 |         self.send_json_response({"message": f"Persona '{persona_name}' deleted successfully"})
    |                                                                                         ^^^^^^
391 |
392 |     def handle_save_config(self):
    |

E501 Line too long (101 > 88)
   --> tests/test_server.py:419:89
    |
417 |                         "message": {
418 |                             "role": "assistant",
419 |                             "content": "This is a test response from the OpenAI-compatible endpoint."
    |                                                                                         ^^^^^^^^^^^^^
420 |                         },
421 |                         "finish_reason": "stop"
    |

E501 Line too long (101 > 88)
  --> tests/test_v1_feed_jobs.py:20:89
   |
18 | API_KEY = os.getenv("ADAPTIVEMIND_API_KEY", "test-key")
19 | HEADERS = {"X-API-Key": API_KEY, "Content-Type": "application/json"}
20 | REQUIRE_NEW_RUNTIME = os.getenv("REQUIRE_NEW_RUNTIME", "false").lower() in {"1", "true", "yes", "on"}
   |                                                                                         ^^^^^^^^^^^^^
   |

E501 Line too long (91 > 88)
  --> tests/test_v1_feed_jobs.py:25:89
   |
23 | def _assert_status(resp):
24 |     if REQUIRE_NEW_RUNTIME:
25 |         assert resp.status_code == 200, f"Expected 200 got {resp.status_code}: {resp.text}"
   |                                                                                         ^^^
26 |     else:
27 |         # For jobs, 200 expected on submission; feed is independent
   |

E501 Line too long (100 > 88)
  --> tests/test_v1_feed_jobs.py:28:89
   |
26 |     else:
27 |         # For jobs, 200 expected on submission; feed is independent
28 |         assert resp.status_code in (200,), f"Unexpected status code {resp.status_code}: {resp.text}"
   |                                                                                         ^^^^^^^^^^^^
   |

E501 Line too long (117 > 88)
  --> tests/test_v1_feed_jobs.py:33:89
   |
31 | def test_v1_feed_ingest():
32 |     url = f"{BASE_URL}/api/v1/feed/ingest"
33 |     payload = {"items": [{"source": "pytest", "content": "Feed content from test", "metadata": {"subject": "test"}}]}
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
34 |     r = requests.post(url, headers=HEADERS, data=json.dumps(payload), timeout=20)
35 |     _assert_status(r)
   |

E501 Line too long (103 > 88)
  --> tests/test_v1_feed_jobs.py:42:89
   |
40 | def test_v1_jobs_chat_and_status():
41 |     submit_url = f"{BASE_URL}/api/v1/jobs"
42 |     payload = {"mode": "chat", "payload": {"messages": [{"role": "user", "content": "Hello via job"}]}}
   |                                                                                         ^^^^^^^^^^^^^^^
43 |     r = requests.post(submit_url, headers=HEADERS, data=json.dumps(payload), timeout=20)
44 |     assert r.status_code == 200, f"Job submission failed: {r.status_code} {r.text}"
   |

E501 Line too long (97 > 88)
  --> tests/test_websocket_stream.py:17:89
   |
15 | import websocket
16 |
17 | BASE_URL = os.getenv("ADAPTIVEMIND_TEST_BASE_URL", "http://127.0.0.1:8000").replace("http", "ws")
   |                                                                                         ^^^^^^^^^
   |

E501 Line too long (100 > 88)
  --> tests/test_websocket_stream.py:23:89
   |
21 |     ws = websocket.WebSocket()
22 |     try:
23 |         ws.connect(f"{BASE_URL}/ws/pytest_client", header={"X-API-Key": "your-secret-api-key-here"})
   |                                                                                         ^^^^^^^^^^^^
24 |         ws.send(json.dumps({"type": "ping"}))
25 |         msg = ws.recv()
   |

E501 Line too long (90 > 88)
  --> tests/validate_api_contract.py:73:89
   |
71 |             components = spec.get('components', {})
72 |             if 'schemas' in components:
73 |                 self.log_success(f"Found {len(components['schemas'])} schema definitions")
   |                                                                                         ^^
74 |             else:
75 |                 self.log_warning("No schemas found in components")
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/validate_api_contract.py:79:16
   |
77 |             return True
78 |
79 |         except Exception as e:
   |                ^^^^^^^^^
80 |             self.log_error(f"Error loading OpenAPI spec: {e}")
81 |             return False
   |

E501 Line too long (118 > 88)
   --> tests/validate_api_contract.py:99:89
    |
 98 |                 if schemas:
 99 |                     self.log_success(f"Schema file '{schema_file.name}' loaded successfully ({len(schemas)} schemas)")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
100 |                 else:
101 |                     self.log_warning(f"Schema file '{schema_file.name}' is empty")
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/validate_api_contract.py:103:20
    |
101 |                     self.log_warning(f"Schema file '{schema_file.name}' is empty")
102 |
103 |             except Exception as e:
    |                    ^^^^^^^^^
104 |                 self.log_error(f"Error loading schema file {schema_file}: {e}")
105 |                 return False
    |

E501 Line too long (91 > 88)
   --> tests/validate_api_contract.py:117:89
    |
116 |             # Find all schema references
117 |             schema_refs = re.findall(r'\$ref: [\'"](\./api_schemas/[^\'"]+)[\'"]', content)
    |                                                                                         ^^^
118 |
119 |             if not schema_refs:
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/validate_api_contract.py:140:16
    |
138 |             return True
139 |
140 |         except Exception as e:
    |                ^^^^^^^^^
141 |             self.log_error(f"Error checking schema references: {e}")
142 |             return False
    |

E501 Line too long (101 > 88)
   --> tests/validate_api_contract.py:163:89
    |
161 |             for endpoint in endpoints:
162 |                 # Simple check - look for endpoint path in docs
163 |                 if endpoint.replace('/', '\\/') not in docs_content and endpoint not in docs_content:
    |                                                                                         ^^^^^^^^^^^^^
164 |                     undocumented.append(endpoint)
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/validate_api_contract.py:173:16
    |
171 |             return True
172 |
173 |         except Exception as e:
    |                ^^^^^^^^^
174 |             self.log_error(f"Error checking consistency: {e}")
175 |             return False
    |

E501 Line too long (115 > 88)
  --> tests/validate_contracts_simple.py:69:89
   |
67 |             total_endpoints = get_endpoints + post_endpoints
68 |
69 |             self.log_success(f"Found {total_endpoints} API endpoints ({get_endpoints} GET, {post_endpoints} POST)")
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
70 |
71 |             # Check for schemas
   |

BLE001 Do not catch blind exception: `Exception`
  --> tests/validate_contracts_simple.py:77:16
   |
75 |             return True
76 |
77 |         except Exception as e:
   |                ^^^^^^^^^
78 |             self.log_error(f"Error loading OpenAPI spec: {e}")
79 |             return False
   |

E501 Line too long (98 > 88)
  --> tests/validate_contracts_simple.py:98:89
   |
97 |                 # Count schema definitions (looking for model names followed by colon)
98 |                 schemas = len(re.findall(r'^([A-Za-z][A-Za-z0-9_]*):\s*$', content, re.MULTILINE))
   |                                                                                         ^^^^^^^^^^
99 |                 total_schemas += schemas
   |

E501 Line too long (100 > 88)
   --> tests/validate_contracts_simple.py:102:89
    |
101 |                 if schemas > 0:
102 |                     self.log_success(f"Schema file '{schema_file.name}' contains {schemas} schemas")
    |                                                                                         ^^^^^^^^^^^^
103 |                 else:
104 |                     self.log_warning(f"Schema file '{schema_file.name}' contains no schemas")
    |

E501 Line too long (93 > 88)
   --> tests/validate_contracts_simple.py:104:89
    |
102 |                     self.log_success(f"Schema file '{schema_file.name}' contains {schemas} schemas")
103 |                 else:
104 |                     self.log_warning(f"Schema file '{schema_file.name}' contains no schemas")
    |                                                                                         ^^^^^
105 |
106 |             except Exception as e:
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/validate_contracts_simple.py:106:20
    |
104 |                     self.log_warning(f"Schema file '{schema_file.name}' contains no schemas")
105 |
106 |             except Exception as e:
    |                    ^^^^^^^^^
107 |                 self.log_error(f"Error reading schema file {schema_file}: {e}")
108 |                 return False
    |

E501 Line too long (137 > 88)
   --> tests/validate_contracts_simple.py:159:89
    |
158 | â€¦ original API docs
159 | â€¦odels', 'chat', 'agents', 'memory', 'workflows', 'security', 'monitoring', 'feed', 'jobs']
    |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
160 | â€¦
    |

E501 Line too long (113 > 88)
   --> tests/validate_contracts_simple.py:166:89
    |
164 |                     found_categories.append(category)
165 |
166 |             self.log_success(f"Found {len(found_categories)}/{len(expected_categories)} expected API categories")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^
167 |
168 |             if len(found_categories) >= 8:  # Allow for some flexibility
    |

E501 Line too long (103 > 88)
   --> tests/validate_contracts_simple.py:171:89
    |
169 |                 self.log_success("API contract coverage appears comprehensive")
170 |             else:
171 |                 self.log_warning(f"Only {len(found_categories)} categories found, expected at least 8")
    |                                                                                         ^^^^^^^^^^^^^^^
172 |
173 |             return True
    |

BLE001 Do not catch blind exception: `Exception`
   --> tests/validate_contracts_simple.py:175:16
    |
173 |             return True
174 |
175 |         except Exception as e:
    |                ^^^^^^^^^
176 |             self.log_error(f"Error checking completeness: {e}")
177 |             return False
    |

Found 5612 errors (4321 fixed, 1291 remaining).
